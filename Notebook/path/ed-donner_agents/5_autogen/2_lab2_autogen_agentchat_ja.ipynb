{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5週目2日\n",
        "\n",
        "### autogen agentchat-より深く行く..\n",
        "\n",
        "1。マルチモーダル会話\n",
        "2。構造化された出力\n",
        "3。Langchainツールの使用\n",
        "4。チーム\n",
        "\n",
        "...そして特別なサプライズエクストラピース"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "import requests\n",
        "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
        "from autogen_core import Image as AGImage\n",
        "from PIL import Image\n",
        "from dotenv import load_dotenv\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_core import CancellationToken\n",
        "from IPython.display import display, Markdown\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "load_dotenv(override=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### マルチモーダルの会話"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"https://edwarddonner.com/wp-content/uploads/2024/10/from-software-engineer-to-AI-DS.jpeg\"\n",
        "\n",
        "pil_image = Image.open(BytesIO(requests.get(url).content))\n",
        "img = AGImage(pil_image)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_modal_message = MultiModalMessage(content=[\"Describe the content of this image in detail\", img], source=\"User\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
        "\n",
        "describer = AssistantAgent(\n",
        "    name=\"description_agent\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"You are good at describing images\",\n",
        ")\n",
        "\n",
        "response = await describer.on_messages([multi_modal_message], cancellation_token=CancellationToken())\n",
        "reply = response.chat_message.content\n",
        "display(Markdown(reply))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 構造化された出力！\n",
        "\n",
        "Autogen AgentChatはそれを簡単にします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class ImageDescription(BaseModel):\n",
        "    scene: str = Field(description=\"Briefly, the overall scene of the image\")\n",
        "    message: str = Field(description=\"The point that the image is trying to convey\")\n",
        "    style: str = Field(description=\"The artistic style of the image\")\n",
        "    orientation: Literal[\"portrait\", \"landscape\", \"square\"] = Field(description=\"The orientation of the image\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
        "\n",
        "describer = AssistantAgent(\n",
        "    name=\"description_agent\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"You are good at describing images in detail\",\n",
        "    output_content_type=ImageDescription,\n",
        ")\n",
        "\n",
        "response = await describer.on_messages([multi_modal_message], cancellation_token=CancellationToken())\n",
        "reply = response.chat_message.content\n",
        "reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textwrap\n",
        "print(f\"Scene:\\n{textwrap.fill(reply.scene)}\\n\\n\")\n",
        "print(f\"Message:\\n{textwrap.fill(reply.message)}\\n\\n\")\n",
        "print(f\"Style:\\n{textwrap.fill(reply.style)}\\n\\n\")\n",
        "print(f\"Orientation:\\n{textwrap.fill(reply.orientation)}\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AutogenのLangchainツールを使用します"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Autogenのラッパー：\n",
        "\n",
        "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
        "\n",
        "# Langchainツール：\n",
        "\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_community.agent_toolkits import FileManagementToolkit\n",
        "from langchain.agents import Tool\n",
        "\n",
        "\n",
        "prompt = \"\"\"Your task is to find a one-way non-stop flight from JFK to LHR in June 2025.\n",
        "First search online for promising deals.\n",
        "Next, write all the deals to a file called flights.md with full details.\n",
        "Finally, select the one you think is best and reply with a short summary.\n",
        "Reply with the selected flight only, and only after you have written the details to the file.\"\"\"\n",
        "\n",
        "\n",
        "serper = GoogleSerperAPIWrapper()\n",
        "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"useful for when you need to search the internet\")\n",
        "autogen_serper = LangChainToolAdapter(langchain_serper)\n",
        "autogen_tools = [autogen_serper]\n",
        "\n",
        "langchain_file_management_tools = FileManagementToolkit(root_dir=\"sandbox\").get_tools()\n",
        "for tool in langchain_file_management_tools:\n",
        "    autogen_tools.append(LangChainToolAdapter(tool))\n",
        "\n",
        "for tool in autogen_tools:\n",
        "    print(tool.name, tool.description)\n",
        "\n",
        "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
        "agent = AssistantAgent(name=\"searcher\", model_client=model_client, tools=autogen_tools, reflect_on_tool_use=True)\n",
        "message = TextMessage(content=prompt, source=\"user\")\n",
        "result = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
        "for message in result.inner_messages:\n",
        "    print(message.content)\n",
        "display(Markdown(result.chat_message.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 次に、ファイルを書くためにもう一度エージェントに電話する必要があります\n",
        "\n",
        "message = TextMessage(content=\"OK proceed\", source=\"user\")\n",
        "\n",
        "result = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
        "for message in result.inner_messages:\n",
        "    print(message.content)\n",
        "display(Markdown(result.chat_message.content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### チームの相互作用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.conditions import  TextMentionTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat\n",
        "\n",
        "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain.agents import Tool\n",
        "\n",
        "serper = GoogleSerperAPIWrapper()\n",
        "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"useful for when you need to search the internet\")\n",
        "autogen_serper = LangChainToolAdapter(langchain_serper)\n",
        "\n",
        "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
        "\n",
        "\n",
        "prompt = \"\"\"Find a one-way non-stop flight from JFK to LHR in June 2025.\"\"\"\n",
        "\n",
        "\n",
        "primary_agent = AssistantAgent(\n",
        "    \"primary\",\n",
        "    model_client=model_client,\n",
        "    tools=[autogen_serper],\n",
        "    system_message=\"You are a helpful AI research assistant who looks for promising deals on flights. Incorporate any feedback you receive.\",\n",
        ")\n",
        "\n",
        "evaluation_agent = AssistantAgent(\n",
        "    \"evaluator\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' when your feedback is addressed.\",\n",
        ")\n",
        "\n",
        "text_termination = TextMentionTermination(\"APPROVE\")\n",
        "\n",
        "# MAX_TURNSを追加してくれたPeter Aに感謝します - それ以外の場合、これはループに入ることができます。\n",
        "\n",
        "team = RoundRobinGroupChat([primary_agent, evaluation_agent], termination_condition=text_termination, max_turns=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = await team.run(task=prompt)\n",
        "for message in result.messages:\n",
        "    print(f\"{message.source}:\\n{message.content}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ドラムロール..\n",
        "\n",
        "## MCPの紹介！\n",
        "\n",
        "人類からのモデルコンテキストプロトコルを最初に見る - \n",
        "\n",
        "Autogenは、Langchainツールと同様に、MCPツールを簡単に使用できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<テーブルスタイル= \"マージン：0;テキストアライグ：左;幅：100％\">\n",
        "    <tr>\n",
        "        <td style = \"width：150px; height：150px; vertical-align：middle;\">\n",
        "            <img src = \"../ assets/stop.png\" width = \"150\" height = \"150\" style = \"display：block;\" />\n",
        "        </td>\n",
        "        <td>\n",
        "            <h2 style = \"color：＃ff7800;\">しかし、待ってください -  Windows PCの人々にとってはそれほど小さな問題</h2>\n",
        "            <Span style = \"color：＃ff7800;\">不快なニュースがあります。 Windows PCSでMCPサーバーを実行するのに問題があります。 MacとLinuxは問題ありません。これは、2025年5月4日の既知の問題です。私はO3に深い研究を依頼して、回避策を見つけようとしました。 <a href = \"https://chatgpt.com/share/6817bbc3-3d0c-8012-9b51-631842470628\">問題を確認し、ワークアラウンドを確認しました。<br/> <br/>\n",
        "            回避策は少し退屈です。これは、PCでLinuxを実行するためのMicrosoftアプローチである「WSL」を利用することです。より多くのセットアップ手順を実行する必要があります！しかし、それは迅速であり、数人の学生がこれが彼らのために完全に機能することを確認しました、そしてこのラボと週6のMCPラボが機能することを確認しました。さらに、WSLは実際にWindows PCにソフトウェアを構築する素晴らしい方法です。この最終セルをスキップすることもできますが、第6週を開始するときにこれに戻る必要があります。<br/>\n",
        "            WSLのセットアップ手順は、<a href = \"../ setup/setup-wsl.md\"> <a href = \"../ setup-wsl.mdと呼ばれるファイル</a>にあります。私はこれがあなたを簡単に抑えるだけであることを願っています - あなたはすぐに戻って走るべきです。ああ、出血エッジテクノロジーを扱う喜び！<br/> <br/>\n",
        "            学生のKaushik R.に感謝します。これはここと6週目です。Kaushikに感謝します。\n",
        "            </span>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\n",
        "\n",
        "# MCP-Server-Fetchからフェッチツールを入手します。\n",
        "fetch_mcp_server = StdioServerParams(command=\"uvx\", args=[\"mcp-server-fetch\"], read_timeout_seconds=30)\n",
        "fetcher = await mcp_server_tools(fetch_mcp_server)\n",
        "\n",
        "# フェッチツールを使用できるエージェントを作成します。\n",
        "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
        "agent = AssistantAgent(name=\"fetcher\", model_client=model_client, tools=fetcher, reflect_on_tool_use=True)  # タイプ：無視します\n",
        "\n",
        "# エージェントにURLのコンテンツを取得し、要約します。\n",
        "result = await agent.run(task=\"Review edwarddonner.com and summarize what you learn. Reply in Markdown.\")\n",
        "display(Markdown(result.messages[-1].content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}