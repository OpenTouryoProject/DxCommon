{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第5週の3日目、さて...\n",
    "\n",
    "### AutoGen Core\n",
    "\n",
    "コレは少し変わったものです。\n",
    "\n",
    "これは基盤となるエージェント・フレームワークに依存しません。\n",
    "\n",
    "AutoGen AgentChat を使用することも、他のものを使用することもできます。\n",
    "\n",
    "これはエージェント・インタラクション・フレームワークです。\n",
    "\n",
    "その観点から見ると、LangGraph と似た位置付けになります。\n",
    "\n",
    "### 基本原則\n",
    "\n",
    "Autogen Core は、エージェントのロジックとメッセージの配信方法を分離します。\n",
    "\n",
    "このフレームワークは通信インフラストラクチャとエージェントのライフサイクルを提供し、エージェントは自身の処理に責任を持ちます。\n",
    "\n",
    "この通信インフラストラクチャはランタイムと呼ばれ、**スタンドアロン** と **分散** の 2 つのタイプがあります。\n",
    "\n",
    "今日は、スタンドアロン・ランタイムである、ローカル埋め込みエージェント・ランタイム実装である **SingleThreadedAgentRuntime** を使用します。\n",
    "\n",
    "明日は分散ランタイムについて簡単に見ていきます。\n",
    "\n",
    "### 概要\n",
    "「AutoGen Core」というエージェント対話フレームワークの概要と基本的な使い方を説明する。\n",
    "\n",
    "主な内容は以下の通りだが、最終段階の目的をみると、ココでは、  \n",
    "`RoutedAgent`を使った階層型のマルチエージェントの構築を目標にしている模様。\n",
    "\n",
    "- AutoGen Coreの紹介\n",
    "  - AutoGen Coreはエージェントのロジックとメッセージ配信の仕組みを分離するフレームワーク\n",
    "  - ランタイムという通信基盤を提供し、エージェントは自身の仕事に集中できる。\n",
    "  - Standalone（単体）とDistributed（分散）の2種類のランタイムがある。\n",
    "  - 本NBではStandalone型（`SingleThreadedAgentRuntime`）を使う。\n",
    "\n",
    "- メッセージ・オブジェクトの定義  \n",
    "エージェント間でやりとりするメッセージ（`Message`クラス）をシンプルに定義\n",
    "\n",
    "- エージェントの実装例  \n",
    "`RoutedAgent`を継承した`SimpleAgent`を定義、特定のメッセージを受け取ると定型文で返答\n",
    "\n",
    "- Runtimeの起動とメッセージ送信  \n",
    "エージェントをRuntimeに登録し、メッセージ送信・応答を実行\n",
    "\n",
    "- LLM（大規模言語モデル）エージェントの導入  \n",
    "OpenAIやOllamaなどのLLM APIを利用するエージェント（`MyLLMAgent`など）を定義し、より高度な応答を生成。\n",
    "\n",
    "- 階層型のマルチエージェントの対話例\n",
    "  - 3体のエージェント（2人のプレイヤーと審判役）で「じゃんけん」を行う\n",
    "  - プレイヤー役はそれぞれ異なるLLMバックエンドを利用し、審判役が結果判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "#from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "# 初期化\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まず、Message オブジェクトを定義します。\n",
    "\n",
    "Agent フレームワークでメッセージに使用したい構造です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルなものにしましょう!\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エージェントを定義します\n",
    "\n",
    "RoutedAgent のサブクラスです。\n",
    "\n",
    "- すべてのエージェントには **Agent ID** があり、これは 2 つの要素から構成されます。\n",
    " - `agent.id.type` はエージェントの種類を表します。\n",
    " - `agent.id.key` はエージェントの一意の識別子です。\n",
    "\n",
    "- `@message_handler` でデコレートされたメソッドはすべて、メッセージを受信できます。\n",
    "\n",
    "...そもそも、RoutedAgentとは、ルーティング専用のエージェントで、  \n",
    "入力されたタスクやメッセージを解析し、適切なエージェントに 振り分ける（routeする） のが仕事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Simple\")\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        #return Message(content=f\"This is {self.id.type}-{self.id.key}. You said '{message.content}' and I disagree.\")\n",
    "        return Message(content=f\"これは {self.id.type}-{self.id.key} です。あなたは「{message.content}」と言いましたが、私は同意しません。\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スタンドアロン・ランタイムを作成し、エージェント・タイプを登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='simple_agent')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先の、スタンドアロン・ランタイムである、ローカル埋め込みエージェント・ランタイム実装\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### よし！ランタイムを起動してメッセージを送信しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開始\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> これは simple_agent-default です。あなたは「やあ、こんにちは！」と言いましたが、私は同意しません。\n"
     ]
    }
   ],
   "source": [
    "# simple_agent の id を取得、id を指定してメッセージを送信\n",
    "agent_id = AgentId(\"simple_agent\", \"default\")\n",
    "response = await runtime.send_message(Message(\"やあ、こんにちは！\"), agent_id)\n",
    "print(\">>>\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止\n",
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK では、もっと面白いことをしてみましょう。\n",
    "\n",
    "AgentChat アシスタントを使います！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本来のRoutedAgent（ルーティング専用のエージェント）はタスクを解析して他のエージェントへ振り分ける\n",
    "\n",
    "# RoutedAgentクラス定義\n",
    "class MyLLMAgent(RoutedAgent):\n",
    "\n",
    "    # 初期化\n",
    "    def __init__(self) -> None:\n",
    "        # エージェントの識別名\n",
    "        super().__init__(\"LLMAgent\")\n",
    "        \n",
    "        # 振り分け先のエージェント\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(\"LLMAgent\", model_client=model_client)\n",
    "\n",
    "    # メッセージハンドラの定義\n",
    "    @message_handler # メッセージ受信のデコレータ\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        \n",
    "        # 受け取ったメッセージをログに出力\n",
    "        print(f\"{self.id.type} received message: {message.content}\")\n",
    "        \n",
    "        # 受け取った Message を、LLM用の TextMessage に変換\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        \n",
    "        # on_messages: AssistantAgent に LLM 呼び出しを委譲\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "\n",
    "        # LLM から返ってきた応答を取り出し\n",
    "        reply = response.chat_message.content\n",
    "\n",
    "        # ログ出力\n",
    "        print(f\"{self.id.type} responded: {reply}\")\n",
    "\n",
    "        # Messageとして返却\n",
    "        return Message(content=reply) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='LLMAgent')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先の、スタンドアロン・ランタイムである、ローカル埋め込みエージェント・ランタイム実装\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "# 2つのRoutedAgent（ルーティング専用のエージェント）を登録\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())\n",
    "await MyLLMAgent.register(runtime, \"LLMAgent\", lambda: MyLLMAgent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMAgent received message: こんにちは！\n",
      "LLMAgent responded: こんにちは！今日はどんなことをお手伝いしましょうか？\n",
      "LLMAgent received message: これは simple_agent-default です。あなたは「こんにちは！今日はどんなことをお手伝いしましょうか？」と言いましたが、私は同意しません。\n",
      "LLMAgent responded: ご意見ありがとうございます。どのようにお手伝いできるか、具体的なリクエストがあれば教えてください。\n"
     ]
    }
   ],
   "source": [
    "# 開始\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> こんにちは！今日はどんなことをお手伝いしましょうか？\n",
      ">>> これは simple_agent-default です。あなたは「こんにちは！今日はどんなことをお手伝いしましょうか？」と言いましたが、私は同意しません。\n",
      ">>> ご意見ありがとうございます。どのようにお手伝いできるか、具体的なリクエストがあれば教えてください。\n"
     ]
    }
   ],
   "source": [
    "# ユーザー の prompt → LLMAgent\n",
    "response = await runtime.send_message(Message(\"こんにちは！\"), AgentId(\"LLMAgent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "\n",
    "# LLMAgent の response → simple_agent\n",
    "response =  await runtime.send_message(Message(response.content), AgentId(\"simple_agent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "\n",
    "# simple_agent → LLMAgent\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"LLMAgent\", \"default\"))\n",
    "print(\">>>\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止\n",
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### さて、実際にこれが動作するか見てみましょう\n",
    "3つのエージェントが対話するようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OllamaChatCompletionClient上げるのメンドイので...\n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0) # OllamaChatCompletionClient(model=\"llama3.2\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE = \"あなたはジャンケンの試合を判定しています。プレイヤーたちは以下の手を出しました。:\\n\"\n",
    "\n",
    "class RockPaperScissorsAgent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        \n",
    "        instruction = \"あなたはじゃんけんをしています。次のうちのいずれか一つの単語だけで答えてください：グー、パー、チョキ。\"\n",
    "\n",
    "        # ※ インスタンスを生成するのではなく取得する。\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")        \n",
    "        \n",
    "        # メッセージを２つのプレイヤーに送る\n",
    "        message = Message(content=instruction)\n",
    "        response1 = await self.send_message(message, inner_1)\n",
    "        response2 = await self.send_message(message, inner_2)\n",
    "\n",
    "        # 結果\n",
    "        result = f\"Player 1: {response1.content}\\nPlayer 2: {response2.content}\\n\"\n",
    "        \n",
    "        # 判定\n",
    "        judgement = f\"{JUDGE}{result} 誰が勝ちましたか？\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "\n",
    "        # 結果判定結果\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='rock_paper_scissors')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先の、スタンドアロン・ランタイムである、ローカル埋め込みエージェント・ランタイム実装\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "# 3つのRoutedAgent（ルーティング専用のエージェント）を登録\n",
    "await Player1Agent.register(runtime, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "await Player2Agent.register(runtime, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "await RockPaperScissorsAgent.register(runtime, \"rock_paper_scissors\", lambda: RockPaperScissorsAgent(\"rock_paper_scissors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開始\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1: グー\n",
      "Player 2: グー\n",
      "ジャンケンでは、同じ手を出した場合は引き分けとなります。したがって、Player 1とPlayer 2の双方がグーを出したため、勝者はありません。引き分けです。 \n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "# JUDGEに指示\n",
    "agent_id = AgentId(\"rock_paper_scissors\", \"default\")\n",
    "message = Message(content=\"go\")\n",
    "response = await runtime.send_message(message, agent_id)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止\n",
    "await runtime.stop()\n",
    "await runtime.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
