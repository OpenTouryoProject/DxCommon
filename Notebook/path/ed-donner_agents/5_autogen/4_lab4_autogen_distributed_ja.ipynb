{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第5週の4日目\n",
    "\n",
    "Autogen Core - （実験的）分散\n",
    "\n",
    "これについては（プロモーション/プレビューの意味で）ティーザーのみ公開します!!\n",
    "\n",
    "それがあなたにとってどれほど関連性があるかわからないからです。\n",
    "\n",
    "これのためにもっとコンテンツを追加してほしいなら、私に知らせてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 初期化\n",
    "load_dotenv(override=True)\n",
    "ALL_IN_ONE_WORKER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メッセージクラスから始め"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ツールを再導入して"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper =Tool(name=\"internet_search\", func=serper.run, description=\"Useful for when you need to search the internet\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### そして、いくつかのエージェント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しい AI エージェント プロジェクトで AutoGen を使用するかどうかの決定を支援するために、AutoGen を選択する理由 (AutoGen の利点) を調査し、簡単に回答してください。\n",
    "instruction1 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the pros of AutoGen.\"\n",
    "\n",
    "# 新しい AI エージェント プロジェクトで AutoGen を使用するかどうかの決定を支援するために、AutoGen を選択しない理由と Autogen の欠点を調査し、簡単に回答してください。\n",
    "instruction2 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons against choosing AutoGen; the cons of Autogen.\"\n",
    "\n",
    "# プロジェクトで AutoGen を使用するかどうかを決定する必要があります。\n",
    "# 研究チームは、以下の賛成理由と反対理由を挙げています。\n",
    "# チームの調査結果のみに基づいて、決定理由と簡単な根拠をお知らせください。\n",
    "judge = \"You must make a decision on whether to use AutoGen for a project. \\\n",
    "Your research team has come up with the following reasons for and against. \\\n",
    "Based purely on the research from your team, please respond with your decision and brief rationale.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Player1Agent、Player2Agentは全く同じ\n",
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "\n",
    "# Player1Agent、Player2Agentは全く同じ\n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "\n",
    "# PlayerAgentとの違いは、ツールを持たない点と階層構造\n",
    "class Judge(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "        \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "\n",
    "        # ※ インスタンスを生成するのではなく取得する。\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "\n",
    "        # メッセージを２つのプレイヤーに送る\n",
    "        message1 = Message(content=instruction1)\n",
    "        message2 = Message(content=instruction2)\n",
    "        response1 = await self.send_message(message1, inner_1)\n",
    "        response2 = await self.send_message(message2, inner_2)\n",
    "\n",
    "        # 結果\n",
    "        # f\"## AutoGen の利点:\\n{response1.content}\\n\\n## AutoGen の欠点:\\n{response2.content}\\n\\n\"\n",
    "        result = f\"## Pros of AutoGen:\\n{response1.content}\\n\\n## Cons of AutoGen:\\n{response2.content}\\n\\n\"\n",
    "        \n",
    "        # 判定\n",
    "        # f\"{judge}\\n{result}あなたの決定と簡単な説明を返信してください\"\n",
    "        judgement = f\"{judge}\\n{result}Respond with your decision and brief explanation\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "\n",
    "        # 結果判定結果\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + \"\\n\\n## Decision:\\n\\n\" + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### そして今 - 分散したランタイムのホスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Pros of AutoGen:\n",
       "Here are several reasons in favor of using AutoGen for your AI Agent project:\n",
       "\n",
       "1. **Ease of Use**: AutoGen provides a user-friendly framework that simplifies the creation of multi-agent applications. This can significantly reduce the learning curve for developers.\n",
       "\n",
       "2. **Customizability**: The platform allows developers to easily customize agents for specific tasks, enabling flexibility in tailoring functionalities to meet project requirements.\n",
       "\n",
       "3. **Collaboration**: AutoGen facilitates cooperation between agents through natural-language conversations, which can enhance creativity and improve problem-solving capabilities.\n",
       "\n",
       "4. **Scalability**: The framework supports the development of scalable multi-agent systems, making it suitable for projects that may expand in complexity over time.\n",
       "\n",
       "5. **Efficiency**: Users have reported substantial time savings, with up to a 75% reduction in specific task completion times, contributing to overall project efficiency.\n",
       "\n",
       "6. **Reduced Coordination Complexity**: AutoGen eliminates the need for custom inter-agent protocols by using natural-language handoffs, streamlining communication between agents.\n",
       "\n",
       "7. **Supports Autonomous and Human-in-the-Loop Operations**: The framework accommodates both fully autonomous agents and those that involve human oversight, providing versatility in operational control.\n",
       "\n",
       "These advantages make AutoGen a compelling choice for developing sophisticated AI agents in various applications.\n",
       "\n",
       "TERMINATE\n",
       "\n",
       "## Cons of AutoGen:\n",
       "Here are some cons of using AutoGen in your AI agent project:\n",
       "\n",
       "1. **Steep Learning Curve**: The graph-based approach and the requirement to understand Directed Acyclic Graphs (DAGs) and state management can make it challenging for developers, particularly those who are not tech-savvy.\n",
       "\n",
       "2. **Complicated Documentation**: Users often find the documentation hard to read, with insufficient examples, making it difficult to effectively utilize AutoGen's capabilities.\n",
       "\n",
       "3. **Performance with Less Powerful Models**: AutoGen performs optimally with the latest large language models, which may lead to subpar results if integrated with less powerful models.\n",
       "\n",
       "4. **Cost Concerns**: The usage-based pricing model can become expensive quickly, especially if workflows are not optimized. There is no pay-as-you-go option, necessitating a more costly upgrade even if only minimal use is required.\n",
       "\n",
       "5. **Limited Creativity**: AutoGen is more effective at generating content based on predefined templates and inputs, which may restrict its flexibility and creativity compared to other frameworks that allow more dynamic generation.\n",
       "\n",
       "These factors should be carefully considered when deciding whether to implement AutoGen in your project. \n",
       "\n",
       "TERMINATE\n",
       "\n",
       "\n",
       "\n",
       "## Decision:\n",
       "\n",
       "Based on the research presented by the team, I recommend using AutoGen for the project. \n",
       "\n",
       "Rationale: The significant advantages, including ease of use, customizability, collaboration, and scalability, outweigh the concerns about the learning curve and documentation. AutoGen offers substantial time savings and efficient communication between agents, which will enhance overall project execution. While cost and performance with lesser models are valid concerns, the framework's strengths in facilitating sophisticated AI agent capabilities make it a compelling choice for our needs. \n",
       "\n",
       "TERMINATE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GrpcWorkerAgentRuntimeには、Hostが必要らしい。\n",
    "host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
    "host.start()\n",
    "\n",
    "# SingleThreadedAgentRuntime -> GrpcWorkerAgentRuntime\n",
    "# コレは、gRPC で通信するエージェントワーカーを表すクラス\n",
    "# ランタイム ＝ ワーカー、ワーカープロセス的な意味合い。\n",
    "\n",
    "if ALL_IN_ONE_WORKER: # 全てのエージェントを１つのランタイムに入れる。\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "\n",
    "    await Player1Agent.register(worker, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "    await Player2Agent.register(worker, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "else: # エージェントごとに別々のランタイム実装を立てる\n",
    "\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker1.start()\n",
    "    await Player1Agent.register(worker1, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker2.start()\n",
    "    await Player2Agent.register(worker2, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "response = await worker.send_message(Message(content=\"Go!\"), agent_id)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停止\n",
    "await worker.stop()\n",
    "if not ALL_IN_ONE_WORKER:\n",
    "    await worker1.stop()\n",
    "    await worker2.stop()\n",
    "\n",
    "await host.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
