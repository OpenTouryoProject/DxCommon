{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe59fb7-e68d-4e4b-8901-5902d5343ed8",
   "metadata": {},
   "source": [
    "# TensorFlow・Kerasのトレーニング♨\n",
    "\n",
    "## CNN - 初歩編＋転移学習・ファインチューニング 編\n",
    "- 初歩編の10値分類を転移学習・ファインチューニングで試す。\n",
    "- このNotebookを実行するにはGPU搭載のPC上で実行する必要がある。\n",
    "\n",
    "## [目次](TableOfContents.ipynb)\n",
    "\n",
    "## 参考\n",
    "開発基盤部会 Wiki\n",
    "- データマイニング（DM）- Python - DL  \n",
    "https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?%E3%83%87%E3%83%BC%E3%82%BF%E3%83%9E%E3%82%A4%E3%83%8B%E3%83%B3%E3%82%B0%EF%BC%88DM%EF%BC%89-%20Python%20-%20DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48958bb-e085-40a2-a6e1-f00c80080d20",
   "metadata": {},
   "source": [
    "## [環境準備](TensorFlowAndKeras0.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33ff7c3-2f8c-4789-bc9a-7291f179a46d",
   "metadata": {},
   "source": [
    "### インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca4974-76d3-447b-a9a2-452bd5d5ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# モデル定義\n",
    "from keras.models import Model, Sequential, model_from_json, load_model\n",
    "from keras.layers import Dense, Input, Activation, Flatten, Dropout, LSTM\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "# その他\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285398c-8784-494b-818b-c9de28a049ed",
   "metadata": {},
   "source": [
    "### 共通関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e67325-8682-459e-9086-5725b9743c2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 画像の前処理（様々な変換処理）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ddcfcb-8ce1-457e-909c-11fb6fc4fb60",
   "metadata": {},
   "source": [
    "##### 変換処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a15913-d740-44cc-8e3b-3a03f2ab93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像比較\n",
    "def diff_image_info(img1, img2, cmap1=None, cmap2=None):\n",
    "    print(img1.shape)\n",
    "    print(img2.shape)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1, cmap1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2, cmap2)\n",
    "\n",
    "# 画像回転\n",
    "def opencv_rotate(img, angle=30):\n",
    "    size = (img.shape[0], img.shape[1])\n",
    "    center = (int(size[0]/2), int(size[1]/2))\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(img, rotation_matrix, size)\n",
    "\n",
    "# 画像並進\n",
    "def opencv_move(img, h=100, v=50):\n",
    "    rows, cols, channnels = img.shape\n",
    "    M = np.float32([[1,0,h],[0,1,v]])\n",
    "    return cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "# 画像拡大\n",
    "def opencv_zoomin(img, h=2.0, v=2.0):\n",
    "    zoomed = cv2.resize(img, None, fx=h, fy=v)\n",
    "    height_1, width_1, channel_1 = img.shape\n",
    "    height_2, width_2, channel_2 = zoomed.shape\n",
    "    x =  int((width_2 - width_1) / 2)\n",
    "    y =  int((height_2 - height_1) / 2)\n",
    "    return zoomed[y:y+height_1, x:x+width_1]\n",
    "\n",
    "# ヒストグラム平坦化\n",
    "def opencv_clahe(img, clipLimit=2.0, tileGridSize=(8,8)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img)\n",
    "\n",
    "# Mean Subtraction\n",
    "def img_meansubtraction(img):\n",
    "    img2 = img.astype('f')\n",
    "    \n",
    "    # スケーリング処理\n",
    "    img2 /= 255 # 0～1正規化\n",
    "    img2 -= np.mean(img2) # Mean Subtraction\n",
    "    return img2\n",
    "\n",
    "# 画像のピクセル値の正規化\n",
    "def img_min_max(img):\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    return (img - img_min) / (img_max - img_min)\n",
    "\n",
    "# ガンマ変換\n",
    "def opencv_gamma(img, gamma=0.5):\n",
    "    look_up_table = np.zeros((256, 1), dtype='uint8')\n",
    "    for i in range(256):\n",
    "        look_up_table[i][0] = 255 * pow(float(i) / 255, 1.0 / gamma)\n",
    "    return cv2.LUT(img, look_up_table)\n",
    "\n",
    "# ガウシアンノイズ\n",
    "def img_gaussian_noise(img, loc=0.0, scale=5.0):\n",
    "    row, col, ch = img.shape\n",
    "    noise = np.random.normal(loc,scale,(row,col,ch))\n",
    "    noise = noise.reshape(row,col,ch)\n",
    "    noised = img + noise\n",
    "    noised /= 255\n",
    "    return noised\n",
    "\n",
    "# リサイズ\n",
    "def opencv_resize(img, h, w):\n",
    "    return cv2.resize(img, (h, w))\n",
    "\n",
    "# クロップ\n",
    "def img_cropping(img, h, w):\n",
    "    return img[h[0]:h[1], w[0]:w[1], :]\n",
    "\n",
    "# クロップ（％\n",
    "def img_cropping_p(img, hp, wp):\n",
    "    h, w, c = img.shape\n",
    "    return img[int(h * hp[0]): int(h * hp[1]):, int(w * wp[0]): int(w * wp[1]), :]\n",
    "\n",
    "# bgr -> rgb\n",
    "def opencv_bgr2rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# グレースケール化\n",
    "def opencv_rgb2gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# 2値化\n",
    "def opencv_binary(img, threshold=125):\n",
    "    # 二値化(閾値を超えた画素を255にする。)\n",
    "    return cv2.threshold(grayed, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# 左右反転\n",
    "def opencv_flip_horizontal(img):\n",
    "    return cv2.flip(img, 1)\n",
    "\n",
    "# 上下反転\n",
    "def opencv_flip_vertical(img):\n",
    "    return cv2.flip(img, 0)\n",
    "\n",
    "# 平滑化\n",
    "def opencv_gaussian_blur(img, ksize=(13, 13), sigma=0):\n",
    "    return cv2.GaussianBlur(img, ksize, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2584bec-ea52-49c2-b2c0-6f375a8aca08",
   "metadata": {},
   "source": [
    "##### バッチ変換とバッチ拡張\n",
    "- get_changedとget_augmentedは別々に定義する。\n",
    "- get_augmentedはtrainに対してのみ実行してtestに対しては実行しないので。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0dcd5-576e-42c0-afd6-a9554b1531ce",
   "metadata": {},
   "source": [
    "###### バッチ変換\n",
    "get_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc476e-8697-444e-86f2-c2c4069de429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_changed(img):\n",
    "    # グレースケール化\n",
    "    img = opencv_rgb2gray(img)\n",
    "    \n",
    "    # ヒストグラム平坦化\n",
    "    img = opencv_clahe(img, tileGridSize=(4,4))\n",
    "    \n",
    "    # 平滑化\n",
    "    img = opencv_gaussian_blur(img, ksize=(3, 3))\n",
    "    \n",
    "    # カラーでなくなっている場合、\n",
    "    # チャンネルの次元が減っているので、元に戻す。\n",
    "    return img # img[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfddb0a-6078-4181-8b3b-58fc1f4e9707",
   "metadata": {},
   "source": [
    "###### バッチ拡張\n",
    "get_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167df13-ca3c-435a-a439-fc6f367f5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented(img):\n",
    "    \n",
    "    # 左右反転\n",
    "    if np.random.rand() > 0.5:\n",
    "        img = opencv_flip_horizontal(img)\n",
    "        \n",
    "    # 左右度回転\n",
    "    if np.random.rand() > 0.5:\n",
    "         # -45 ～ +45 の範囲で\n",
    "        angle = np.random.randint(-45, 45)\n",
    "        rotation_matrix = opencv_rotate(img, angle)\n",
    "        img = cv2.warpAffine(img, rotation_matrix, size)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125ce7d-3b9f-42e7-9702-93600fbc1a07",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 画像確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286af17c-82eb-4981-8268-06b0c89b8d49",
   "metadata": {},
   "source": [
    "##### 画像とラベルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c77732-87e7-45ed-8920-ed62d076b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_info(x, y, label, index):\n",
    "    print(\"label: \", label[y[index]])\n",
    "    print(\"Image: \")\n",
    "    plt.imshow(x[index].astype(np.uint8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf06a6-45b1-423e-bee5-5fce4e6e9b78",
   "metadata": {},
   "source": [
    "##### ランダムな画像一覧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6396924-d2da-4c66-a6f7-5f4db37098c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_list(x, y, numOfCls=10, numOfImgInCls=10):\n",
    "    pos = 1\n",
    "    plt.figure(figsize=(numOfCls, numOfImgInCls))\n",
    "\n",
    "    # クラス毎に以下の処理を繰り返す。\n",
    "    for targetClass in range(numOfCls):\n",
    "        targetIdx = []\n",
    "        \n",
    "        # 当該クラスの画像のインデックスリストを取得\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == targetClass:\n",
    "                targetIdx.append(i)\n",
    "        \n",
    "        # 当該クラスのインデックスリストからランダムに選んだ最初のn個の画像を描画\n",
    "        np.random.shuffle(targetIdx)\n",
    "        for idx in targetIdx[:numOfImgInCls]:\n",
    "            plt.subplot(numOfCls, numOfImgInCls, pos)\n",
    "            plt.imshow(x[idx])\n",
    "            plt.axis('off')\n",
    "            pos += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3cbfa0-6ab9-485a-a8ac-8960f37e3d0e",
   "metadata": {},
   "source": [
    "##### 誤った推論の画像を表示する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893a3e6-31ab-4ab0-bab1-5cff44d2903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_incorrect_image_list(x, y, y_pred, label, numOfImg=10):\n",
    "    index = (y != y_pred)\n",
    "    for i, val in enumerate(index):\n",
    "        if val == True:\n",
    "            print('predict: ', label[y_pred[i]])\n",
    "            print('answer : ', label[y[i]])\n",
    "            show_image_info(x, y, label, i)\n",
    "            numOfImg -= 1\n",
    "            if numOfImg <= 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2ad93-101e-4b05-b07f-a43a50b2f663",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 分類問題関連"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cbf91e-c445-494e-96b6-1512b36b69a3",
   "metadata": {},
   "source": [
    "##### [分類問題のメトリック表示関数](ScikitLearnTraining5.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2506d7-196b-4de1-9cb4-c00094a52685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(label, pred):\n",
    "    print('accuracy: %.3f' % metrics.accuracy_score(label, pred)) # 正答率\n",
    "    \n",
    "    print('\\nmicro') # ミクロ平均\n",
    "    print('recall: %.3f' % metrics.recall_score(label, pred, average='micro')) # 再現率\n",
    "    print('precision: %.3f' % metrics.precision_score(label, pred, average='micro')) # 適合率\n",
    "    print('f1_score: %.3f' % metrics.f1_score(label, pred, average='micro')) # f値\n",
    "    \n",
    "    print('\\nmacro') # マクロ平均\n",
    "    print('recall: %.3f' % metrics.recall_score(label, pred, average='macro')) # 再現率\n",
    "    print('precision: %.3f' % metrics.precision_score(label, pred, average='macro')) # 適合率\n",
    "    print('f1_score: %.3f' % metrics.f1_score(label, pred, average='macro')) # f値"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b796a58b-fe66-471f-8759-521b38c1780c",
   "metadata": {},
   "source": [
    "##### 混同行列のグラフ化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf2fc7-5bc9-4f1f-bf41-573167312b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(confmat, label):\n",
    "    numOfCls = len(label)\n",
    "    fig, ax = plt.subplots(figsize=(numOfCls, numOfCls))\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "            \n",
    "    # 軸目盛を打つ場所を決める\n",
    "    ax.set_xticks(np.arange(len(label)))\n",
    "    ax.set_yticks(np.arange(len(label)))\n",
    "    # 軸目盛を設定\n",
    "    ax.set_xticklabels(label)\n",
    "    ax.set_yticklabels(label)\n",
    "    #plt.xticks(np.array(label)) # x軸の目盛りを指定\n",
    "    #plt.yticks(np.array(label)) # y軸の目盛りを指定\n",
    "    \n",
    "    plt.xlabel('y_pred label')\n",
    "    plt.ylabel('y label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f442172-6fbc-4bf8-b64c-1c20a2cb5862",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 学習履歴表示関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef95260-cf25-4929-8a44-3e4b0c81d106",
   "metadata": {},
   "source": [
    "##### 損失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e879f3-8b28-4f29-95a3-9b2b193b7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_loss(hist):\n",
    "    plt.plot(hist.history['loss'],label=\"loss for training\")\n",
    "    plt.plot(hist.history['val_loss'],label=\"loss for validation\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c84704-d277-4ace-80e4-b2f090e9c0dd",
   "metadata": {},
   "source": [
    "##### 正解率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91d6cce-ed46-4560-90ef-6767bfa08aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_acc(hist):\n",
    "    plt.plot(hist.history['accuracy'],label=\"accuracy for training\")\n",
    "    plt.plot(hist.history['val_accuracy'],label=\"accuracy for validation\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cfd585-563a-44ec-8773-ab0348048afc",
   "metadata": {},
   "source": [
    "## 転移学習・ファインチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3188d4-3d83-4a63-973e-3a1ab5dcb71f",
   "metadata": {},
   "source": [
    "### データ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0884fa-39cb-40df-8225-c27afd7d18c1",
   "metadata": {},
   "source": [
    "#### 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e65b3a-79bf-4748-b2f3-4e4c379c2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train_org, y_train_org), (x_test_org, y_test_org) = cifar10.load_data()\n",
    "print(x_train_org.shape, x_test_org.shape)\n",
    "print(y_train_org.shape, y_test_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d171e1-f380-495e-ae63-9a5ecd4dd5dc",
   "metadata": {},
   "source": [
    "##### 加工\n",
    "一旦、結合します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed03cfd-6c14-4f42-b710-c1507b4f73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_org = np.vstack([x_train_org, x_test_org])\n",
    "y_org = np.concatenate([y_train_org, y_test_org])\n",
    "print(x_org.shape, y_org.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc92ec-e891-466e-a6bb-01c376580c8a",
   "metadata": {},
   "source": [
    "##### 理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c8c76-0822-4bbd-b71c-347f91491bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_info(x_org, y_org.flatten(), [0,1,2,3,4,5,6,7,8,9], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500f6e8-3819-474f-9027-87a57c952157",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_list(x_org, y_org.flatten(), 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851a4d7-df73-46fa-910d-b1caeb2a329e",
   "metadata": {},
   "source": [
    "##### 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa461a-edb4-4f91-95aa-cef4f8865a08",
   "metadata": {},
   "source": [
    "###### 前処理関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69267766-7fe0-4a13-a588-09217a7be551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vgg16(img, size=(32, 32)):\n",
    "    \n",
    "    # リサイズ\n",
    "    img= cv2.resize(img, size)\n",
    "    \n",
    "    # RGBチャネルからそれぞれvgg指定の値を引く\n",
    "    # (mean-subtractionに相当)\n",
    "    img[:, :, 0] -= 103.939\n",
    "    img[:, :, 1] -= 116.779\n",
    "    img[:, :, 2] -= 123.68\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c0fad-8af9-48c5-b2f8-54fde70f86a2",
   "metadata": {},
   "source": [
    "###### XのKeras入力用型変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed13f4-922f-484f-bf87-1fd46c233992",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_org = x_org.astype('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a4fe8-cfef-4d36-a5c7-6e4257b8d269",
   "metadata": {},
   "source": [
    "###### 正解ラベルのOne-Hotエンコーディング\n",
    "Kerasでは正解ラベルはOne-Hotベクトル化が必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2ae8b-011b-44c3-94a8-0cded79718cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンコーディング\n",
    "y_encded = to_categorical(y_org.flatten(), num_classes=10).astype('i') \n",
    "# デコーディング\n",
    "print((y_encded.argmax(axis=1) == y_org.flatten()).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a8bb9-c6d7-4cf5-a2be-7dd437ded039",
   "metadata": {},
   "source": [
    "###### 学習・テストデータの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b2c4a-66dd-4326-99ac-8b4373e80ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_org[:50000]\n",
    "x_test = x_org[50000:]\n",
    "y_train = y_encded[:50000]\n",
    "y_test = y_encded[50000:]\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e51471-c35b-4d40-b651-1a1282c97777",
   "metadata": {},
   "source": [
    "###### 画像の前処理（様々な変換処理）\n",
    "leakageの防止（データ分割後にデータ変換・拡張等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19a42d-4e3c-4dc7-b75c-a03bb0f1f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じて、\n",
    "# get_changed(img)でデータ変換し、\n",
    "# get_augmented(img)でデータ拡張する。\n",
    "\n",
    "x_train_list = []\n",
    "for img in x_train:\n",
    "    x_train_list.append(preprocess_vgg16(img))\n",
    "x_train_aug = np.array(x_train_list)\n",
    "\n",
    "x_test_list = []\n",
    "for img in x_test:\n",
    "    x_test_list.append(preprocess_vgg16(img))\n",
    "x_test_aug = np.array(x_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba205785-f2f5-418a-ad77-98f5a4976b78",
   "metadata": {},
   "source": [
    "### モデリング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cec94-b439-4ff6-93c8-0ea35676a262",
   "metadata": {},
   "source": [
    "#### CNNの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209ebc5-c318-4b58-9e63-22b13a580599",
   "metadata": {},
   "source": [
    "##### inputs\n",
    "全結合層部分を含まない学習済みモデルの読込\n",
    "- weights ：重みの初期値（'random': ランダム, 'imagenet': 学習済みの重み）\n",
    "- include_top ：全結合層のダウンロード（True: する, False: しない）\n",
    "- input_tensor：入力テンソルの型（縦, 横, チャンネル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca958dc5-020a-472b-b524-86e8b36212e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3)))\n",
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876eefc1-74a1-490c-b62e-818dd4ceab69",
   "metadata": {},
   "source": [
    "##### output\n",
    "追加する全結合層部分を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cf737-36ed-4aef-9afc-ceba9e744711",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 10\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256))\n",
    "top_model.add(Activation('relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(n_class))\n",
    "top_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb17d0-b2fa-48c5-9734-ea3bd3f366a1",
   "metadata": {},
   "source": [
    "##### 追加結合\n",
    "全結合層部分を含まない学習済みモデルに全結合層部分を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1b1cc-95eb-4aca-b833-a166ba995831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3203e-75ae-421b-8faf-cfd7e9ded4b1",
   "metadata": {},
   "source": [
    "##### コンパイル\n",
    "畳み込み層のパラメタを固定してコンパイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6a38a-01ac-4013-b076-3dc3dc7bd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee318f-b92e-4063-9bc3-52c08dfcce0f",
   "metadata": {},
   "source": [
    "#### 確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e66d75-966f-473c-acaa-55dc92b77641",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078562c6-f6cb-40b3-a780-3bfb09edb682",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4365c-1616-4c3c-9b41-bbd7206923ad",
   "metadata": {},
   "source": [
    "#### 学習\n",
    "- VGG16はCPUで扱うには大規模過ぎる。\n",
    "- CPUで扱う場合は、epoch数を1に設定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af7e1a4-d1a9-440d-afe9-47ced40e51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_epoch = 1 #30 # 3000 # 試用なので回数を減らす\n",
    "hist = model.fit(x_train_aug, y_train,\n",
    "                 validation_data=(x_test_aug, y_test),\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=n_epoch,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51361ae9-0863-4e13-8ad5-9d6a75189414",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test_aug, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe55f9b-c4c4-4916-9077-fa3c7b008aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_loss(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e6a87-0746-4a37-ba1d-36e4f3d6e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_acc(hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
