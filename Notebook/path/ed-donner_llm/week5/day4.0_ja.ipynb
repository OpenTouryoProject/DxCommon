{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "## 専門知識労働者\n",
    "- 保険テクノロジー企業である Insurellm の従業員が使用する、専門知識を持つナレッジ ワーカーである質問応答エージェント。エージェントは正確である必要があり、ソリューションは低コストである必要があります。\n",
    "- このプロジェクトでは、RAG（検索拡張生成）を使用して、質問/回答アシスタントが高い精度を確保します。ココ、4つめの実装では、RAGをChatインターフェイスから試行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802137aa-8a74-45e0-a487-d1974927d7ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# langchain、Chroma のインポート\n",
    "\n",
    "# langchain\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# VDBサポート (langchain_chroma)\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c85082-e417-4708-9efe-81a5d55d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 価格は重要な要素（と言う建付け）なので、低コストモデルを採用\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# コレはVDBのChromaのDB名\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee78efcb-60fe-449e-a944-40bab26261af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envファイルから環境変数をロード\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730711a9-6ffe-4eee-8f48-d6cfb7314905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langChain のローダーを使用してKBのすべてのサブフォルダ内のすべてのドキュメントを読み取りリスト化\n",
    "# 余談：メタデータは、DirectoryLoader および TextLoader によって生成され、そこにカスタムの属性、doc_typeを追加している。\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "# 一部のユーザーに必要な修正を提供してくれた、コース受講生のCGとJon Rに感謝します。\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# それでもうまくいかない場合は、Windowsユーザーの中には次の行のコメントを解除する必要があるかもしれません。\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7310c9c8-03c1-4efc-a104-5e89aec6db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# テキストを200文字の重複部分を持たせた1000文字ごとのチャンク（かたまり）に分割\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# document も chunk も LangChain の Document クラス\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78998399-ac17-4e28-b15f-0b5f51e6ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 123 documents\n"
     ]
    }
   ],
   "source": [
    "# 各チャンクに埋込ベクトルを関連付けるVDBに格納\n",
    "# Chroma は SQLite ベースの人気のOSS VDB\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Huggingfaceのフリーのベクトル埋め込みを使用したい場合\n",
    "# 次と、embeddings = OpenAIEmbeddings() を交換します：\n",
    "\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Chroma DataStoreがすでに存在するかどうかを確認してください - もしそうなら、コレクションを削除してゼロから始める\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Chroma VectorStoreを作成してください！\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c94e91-a6b6-400d-a16d-a66a1d0ca3a4",
   "metadata": {},
   "source": [
    "## ベクトルストアの可視化\n",
    "コードや表示される内容に変更はないので割愛"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9468860b-86a2-41df-af01-b2400cc985be",
   "metadata": {},
   "source": [
    "# LangChainを使用してすべてをまとめる時間です"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8a5e7-965d-4770-a12d-532aff50c4b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">必ずお読みください！非推奨警告を無視してください</h2>\n",
    "            <span style=\"color:#900;\">次のセルを実行すると、LangChainメモリのシンプルな使用方法に関するLangChainDeprecationWarningが表示されます。LangChainは、メモリに関する新しいアプローチへの移行を求めています。私はこれにかなり抵抗を感じています。新しいアプローチでは、LangGraphに移行し、そのエコシステムを深く理解する必要があります。LangGraphにはかなりの学習とコーディングが必要ですが、正直なところ、私たちのケースではあまりメリットがありません。<br/><br/>\n",
    "                コースに組み込むかどうか、またどのように組み込むかについては検討中ですが、今のところは非推奨警告を無視してコードをそのまま使用してください。LangChainがConversationBufferMemoryをすぐに削除する予定はありません。\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129c7d1e-0094-4479-9459-f9360b95f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30499/831555549.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# OpenAIとの新しいチャットを作成します\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# チャットの会話メモリを設定します\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# RAGに使用されるベクターストアの抽象化\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# それをまとめる：GPT 4o-Mini LLM、ベクトルストア、メモリで会話チェーンをセットアップ\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "968e7bf2-e862-4679-a11f-6c1efb6ec8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insurellm is an insurance tech startup founded in 2015 by Avery Lancaster, aimed at disrupting the insurance industry with innovative products. The company has grown to 200 employees and operates 12 offices across the US, offering four main software products: Carllm for auto insurance, Homellm for home insurance, Rellm for the reinsurance sector, and Marketllm, a marketplace connecting consumers with insurance providers. With over 300 clients worldwide, Insurellm is focused on transforming the insurance landscape through technology and innovation.\n"
     ]
    }
   ],
   "source": [
    "# 簡単な質問をしましょう\n",
    "query = \"Can you describe Insurellm in a few sentences\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcb659-13ce-47ab-8a5e-01b930494964",
   "metadata": {},
   "source": [
    "## GradioのChatインターフェイスを使用して、これを紹介します。\n",
    "- LLMとのRAGチャットをプロトタイプする迅速かつ簡単な方法\n",
    "- `Hi there.`, `What is Insurellm?`, `What did avery do before?`, `Does insurellm offer any products in the auto insurance space?` とでも聞いてみる。\n",
    "- ポイントは、前回のソリューションはディクショナリのキー名に一致する文字列が質問文に含まれる必要があったが、ベクトル化とその格納によって、その制限が無くなった点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3536590-85c7-4155-bd87-ae78a1467670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数のラッピング - 履歴の記憶はconversation_chainにあるため、Gradioのhistoryは使用されていない。\n",
    "\n",
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b252d8c1-61a8-406d-b57a-8f708a62b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# そしてGradioで：\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
