{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2",
      "metadata": {},
      "source": [
        "# 3日目 - 会話ai -aka chatbot！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 輸入\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231605aa-fccb-447e-89cf-8b187444536a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# .envというファイルに環境変数をロードします\n",
        "# キープレフィックスを印刷して、デバッグに役立ちます\n",
        "\n",
        "load_dotenv(override=True)\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"Openai APIキーが設定されていません\")\n",
        "    \n",
        "if anthropic_api_key:\n",
        "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
        "else:\n",
        "    print(\"人為的APIキーが設定されていません\")\n",
        "\n",
        "if google_api_key:\n",
        "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"Google APIキーが設定されていません\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6541d58e-2297-4de1-b1f7-77da1b98b8bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初期化\n",
        "\n",
        "openai = OpenAI()\n",
        "MODEL = 'gpt-4o-mini'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16839b5-c03b-4d9d-add6-87a0f6f37575",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e97227-f162-4d1a-a0b2-345ff248cbe7",
      "metadata": {},
      "source": [
        "# これを読んでください！ビデオからの変更：\n",
        "\n",
        "ビデオでは、次のような関数を書く必要がある方法を説明します。\n",
        "\n",
        "`チャット（メッセージ、歴史）`\n",
        "\n",
        "これは、特定の形式で「歴史」を受け取ることを期待しています。これは、Openaiを呼び出す前にOpenai形式にマッピングする必要があります。\n",
        "\n",
        "```\n",
        "[\n",
        "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
        "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
        "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
        "]\n",
        "```\n",
        "\n",
        "しかし、Gradioはアップグレードされました！これで、「歴史」で正確にOpenai形式で渡され、Openaiに直接送信するのに最適です。\n",
        "\n",
        "だから私たちの仕事は簡単になりました！\n",
        "\n",
        "関数「チャット、履歴）を書きます。  \n",
        "**メッセージ**は使用するプロンプトです  \n",
        "**歴史**は、過去の会話であり、Openai形式です  \n",
        "\n",
        "システムメッセージ、履歴、最新のメッセージを組み合わせて、Openaiに電話します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eacc8a4-4b48-4358-9e06-ce0020041bc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 私のビデオよりもシンプル -  Openaiを呼び出すこの関数を簡単に作成できます\n",
        "# Openaiへの入力を準備するためのコードが1行になりました！\n",
        "\n",
        "# 学生のOctavio O.は、これはクロードにとってそれほど簡単ではないことを指摘しました -\n",
        "# Claudeを処理するコミュニティ委員会「Gradio_issue_with_claude」における優れた貢献を参照してください。\n",
        "\n",
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    print(\"歴史は次のとおりです。\")\n",
        "    print(history)\n",
        "    print(\"とメッセージは次のとおりです。\")\n",
        "    print(messages)\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1334422a-808f-4147-9c4c-57d63d9780d0",
      "metadata": {},
      "source": [
        "## そして、Gradio's Magicを入力してください！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0866ca56-100a-44ab-8bd0-1568feaf6bf2",
      "metadata": {},
      "outputs": [],
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f91b414-8bab-472d-b9c9-3fa51259bdfe",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
        "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
        "For example, if the customer says 'I'm looking to buy a hat', \\\n",
        "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
        "Encourage the customer to buy hats if they are unsure what to get.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e5be3ec-c26c-42bc-ac16-c39d369883f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
      "metadata": {},
      "outputs": [],
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75f0ffa-55c8-4152-b451-945021676837",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
        "but remind the customer to look at hats!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c602a8dd-2df7-4eb7-b539-4e01865a6351",
      "metadata": {},
      "outputs": [],
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a987a66-1061-46d6-a83a-a30859dc88bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学生Gabor M.によって見事に識別されたこの関数のバグを修正しました！\n",
        "# また、この機能の構造も改善しました\n",
        "\n",
        "def chat(message, history):\n",
        "\n",
        "    relevant_system_message = system_message\n",
        "    if 'belt' in message:\n",
        "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
        "    \n",
        "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "\n",
        "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        response += chunk.choices[0].delta.content or ''\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20570de2-eaad-42cc-a92c-c779d71b48b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82a57ee0-b945-48a7-a024-01b56a5d4b3e",
      "metadata": {},
      "source": [
        "<テーブルスタイル= \"マージン：0;テキストアライグ：左;\">\n",
        "    <tr>\n",
        "        <td style = \"width：150px; height：150px; vertical-align：middle;\">\n",
        "            <img src = \"../ business.jpg\" width = \"150\" height = \"150\" style = \"display：block;\" />\n",
        "        </td>\n",
        "        <td>\n",
        "            <h2 style = \"color：＃181;\">ビジネスアプリケーション</h2>\n",
        "            <Span style = \"color：＃181;\">会話アシスタントはもちろん、Gen AIの非常に一般的なユースケースであり、最新のフロンティアモデルは微妙な会話に非常に優れています。 Gradioは、ユーザーインターフェイスを簡単に使用できます。私たちが取り上げたもう1つの重要なスキルは、プロンプトを使用してコンテキスト、情報、例を提供する方法です。\n",
        "<br/> <br/>\n",
        "AIアシスタントをビジネスに適用する方法を検討し、自分自身をプロトタイプにすることができます。システムプロンプトを使用して、ビジネスのコンテキストを提供し、LLMのトーンを設定します。</span>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dfb9e21-df67-4c2b-b952-5e7e7961b03d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}