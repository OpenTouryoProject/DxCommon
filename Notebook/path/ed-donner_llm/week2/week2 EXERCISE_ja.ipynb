{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# 追加の週末運動 - 第2週\n",
    "\n",
    "2週目から学んだことすべてを使用して、1週目のエクササイズで作成した技術的な質問/回答者の完全なプロトタイプを作成します。\n",
    "\n",
    "これには、Gradio UI、ストリーミング、専門知識を追加するためのシステムプロンプトの使用、およびモデル間を切り替える機能が含まれます。ツールの使用を実証できる場合は、ボーナスポイント！\n",
    "\n",
    "大胆だと感じた場合は、オーディオ入力を追加できるかどうかを確認して、それに相談して、オーディオで応答してもらいます。 ChatGptまたはClaudeはあなたを助けることができます。\n",
    "\n",
    "私はすぐにここに完全なソリューションを公開します - 誰かが私をそれにbeatっていない限り...\n",
    "\n",
    "言語の家庭教師から、会社のオンボーディングソリューション、コンパニオンAIまで、これには非常に多くの商用アプリケーションがあります（このようなもの！）私はあなたの結果を見るのを待ちきれません。\n",
    "\n",
    "---\n",
    "\n",
    "このノートブックは「航空会社AIアシスタント」のプロトタイプを作成する演習です。主な処理内容は以下の通りです。\n",
    "\n",
    "https://github.com/ed-donner/llm_engineering/blob/main/week2/community-contributions/week2-EXERCISE-booking-translation-audio_input-history_audio.ipynb\n",
    "\n",
    "### 機能概要\n",
    "- チャットUI（Gradio）を使ったAIアシスタントとの対話\n",
    "- 航空券の価格取得や予約ができるツール機能\n",
    "- ユーザーやAIの発話を音声合成（TTS）で再生\n",
    "- 入出力メッセージの自動翻訳（多言語対応）\n",
    "- マイクからの音声入力→文字起こし（Whisper利用）\n",
    "- チャット履歴や翻訳済み履歴の管理\n",
    "- モデルの切り替え、システムプロンプトによる応答制御\n",
    "\n",
    "### 技術要素\n",
    "- OpenAI API（GPT, TTS, Whisper）\n",
    "- deep_translator（Google翻訳API）\n",
    "- Gradio（Web UI構築）\n",
    "- 音声ファイル再生（pydub, IPython.display）\n",
    "\n",
    "### 具体的な処理の流れ\n",
    "1. 必要なライブラリのインストール（deep_translator, openai-whisper, soundfileなど）\n",
    "2. OpenAI APIキーの環境変数から取得\n",
    "3. 航空券の価格取得・予約を行う関数を定義し、ツールとして登録\n",
    "4. TTSでの音声応答、音声入力（Whisper）などのユーティリティ関数を実装\n",
    "5. deep_translatorで多言語翻訳機能を実装\n",
    "6. チャット履歴・翻訳履歴の管理＆UIのドロップダウンで再生メッセージ選択\n",
    "7. 音声入力された内容を文字起こししてチャット履歴に追加\n",
    "8. モデル推論結果やツール呼び出しに応じて処理を分岐\n",
    "9. Gradioにより、チャット、翻訳履歴、予約状況、音声再生、言語選択、音声入力を統合したUIを構築・起動\n",
    "\n",
    "まとめ：  \n",
    "このノートブックは「航空券の価格取得・予約ができる多言語対応のAIチャットボット」をGradioで構築し、音声入出力・翻訳・ツール連携も組み合わせた高度なプロトタイプを作成する内容です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep_translator in /home/seigi/.python3_venv/lib/python3.12/site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from deep_translator) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from deep_translator) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "# Library for language translation\n",
    "# Google翻訳を非公式API（ウェブスクレイピングベース）で利用するためAPIキーは不要\n",
    "!pip install deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd549c5-e300-4495-b326-1d327f4a81be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /home/seigi/.python3_venv/lib/python3.12/site-packages (20250625)\n",
      "Requirement already satisfied: more-itertools in /home/seigi/.python3_venv/lib/python3.12/site-packages (from openai-whisper) (10.7.0)\n",
      "Requirement already satisfied: numba in /home/seigi/.python3_venv/lib/python3.12/site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: numpy in /home/seigi/.python3_venv/lib/python3.12/site-packages (from openai-whisper) (2.2.6)\n",
      "Requirement already satisfied: tiktoken in /home/seigi/.python3_venv/lib/python3.12/site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: torch in /home/seigi/.python3_venv/lib/python3.12/site-packages (from openai-whisper) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /home/seigi/.python3_venv/lib/python3.12/site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from openai-whisper) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from triton>=2->openai-whisper) (80.9.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2.32.4)\n",
      "Requirement already satisfied: filelock in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from torch->openai-whisper) (1.11.1.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Library for speech-to-text conversion\n",
    "# make sure 'ffmpeg' is downloaded already\n",
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07453d5d-3d36-4105-b093-1d02b269ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in /home/seigi/.python3_venv/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/seigi/.python3_venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in /home/seigi/.python3_venv/lib/python3.12/site-packages (from soundfile) (2.2.6)\n",
      "Requirement already satisfied: pycparser in /home/seigi/.python3_venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\n"
     ]
    }
   ],
   "source": [
    "# Library for storing and loading audio file\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d05315-b68b-4e16-bb81-fa1610af8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import Audio, display\n",
    "import tempfile\n",
    "import whisper\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c990e3dc-8670-481b-a733-1e39321f6025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI APIキーが存在し、開始します sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# 初期化\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI APIキーが存在し、開始します {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Openai APIキーが設定されていません\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4953f080-5339-4ea5-a4a0-24a84ee16a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"あなたはFlightAIという航空会社の親切なアシスタントです。\\\n",
    "あなたの主な仕事は、お客様の疑問を解決し、航空券の価格を調べて予約することです。\\\n",
    "1文以内で、簡潔で丁寧な回答をしてください。常に正確に回答してください。\\\n",
    "わからない場合は、その旨を伝えてください。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf117fb2-014c-4671-a645-66c08c470cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "ticket_prices = {\n",
    "    \"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\", \"shanghai\": \"$799\", \"wuhan\": \"$899\",\n",
    "    \"ロンドン\": \"$799\", \"パリ\": \"$899\", \"東京\": \"$1400\", \"ベルリン\": \"$499\", \"上海\": \"$799\", \"武漢\": \"$899\",\n",
    "}\n",
    "\n",
    "# ticket_prices辞書から該当都市の価格を取得する関数\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"ツール get_ticket_price が {destination_city} に対して呼び出されました。\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")\n",
    "\n",
    "# 航空券の予約処理を行い、booked_citiesリストに追加、メッセージを返す関数\n",
    "def book_ticket(destination_city):\n",
    "    print(f\"ツール book_ticket は {destination_city} に対して呼び出されました。\")\n",
    "    city = destination_city.lower()\n",
    "    # global booked_cities\n",
    "    if city in ticket_prices:\n",
    "        price = ticket_prices.get(city, \"\")\n",
    "        label = f\"{city.title()} ({price})\"\n",
    "        i = booked_cities_choices.index(city.lower().capitalize())\n",
    "        booked_cities_choices[i] = label\n",
    "        booked_cities.append(label)\n",
    "        return f\"{city.title()} の予約が {ticket_prices[city]} で確定しました。\"\n",
    "    else:\n",
    "        return \"チケット価格に都市が見つかりません。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e35870-db35-4bc8-9216-ac37c08b0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数定義の辞書構造\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"目的地までの往復航空券の料金を取得します。例えば、顧客から「この都市までの航空券はいくらですか？」と尋ねられたときなど、航空券の料金を知りたいときはいつでもこのメソッドを呼び出します。\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"顧客が旅行したい都市\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "book_function = {\n",
    "    \"name\": \"book_ticket\",\n",
    "    \"description\": \"目的地の都市への往復航空券を予約します。ユーザーが「この都市への航空券を予約して」などと言った場合など、目的地の都市への航空券を予約したいときにいつでも呼び出します。\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"顧客が航空券を予約したい都市\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "# ツールのリストに含める\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": price_function},\n",
    "    {\"type\": \"function\", \"function\": book_function}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a681e485-f7e3-4f2d-9090-ac0c2510a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#talker と speak の違いは、音声の出力方法（再生方法）と保存の有無\n",
    "\n",
    "# 音声出力\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",    # Also, try replacing onyx with alloy\n",
    "        input=message)\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)\n",
    "\n",
    "def speak(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=message)\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    output_filename = \"output_audio.mp3\"\n",
    "    with open(output_filename, \"wb\") as f:\n",
    "        f.write(audio_stream.read())\n",
    "\n",
    "    # Play the generated audio\n",
    "    display(Audio(output_filename, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ddd525-489b-4a26-aa5e-e765c20a7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻訳処理\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Available translation language\n",
    "LANGUAGES = {\n",
    "    \"English\": \"en\",\n",
    "    \"Mandarin Chinese\": \"zh-CN\",\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Spanish\": \"es\",\n",
    "    \"Arabic\": \"ar\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Portuguese\": \"pt\",\n",
    "    \"Russian\": \"ru\",\n",
    "    \"Japanese\": \"ja\",\n",
    "    \"German\": \"de\"\n",
    "}\n",
    "\n",
    "def update_lang(choice):\n",
    "    global target_lang\n",
    "    target_lang = LANGUAGES.get(choice, \"zh-CN\") \n",
    "\n",
    "def translate_message(text, target_lang):\n",
    "    if target_lang == \"en\":\n",
    "        return text\n",
    "    try:\n",
    "        translator = GoogleTranslator(source='auto', target=target_lang)\n",
    "        return translator.translate(text)\n",
    "    except:\n",
    "        return f\"Translation error: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f5b950-f5de-4e86-9227-5a4a087383f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チャットボットの履歴からドロップダウンオプションを更新\n",
    "def update_options(history):\n",
    "    options = [f\"{msg['role']}: {msg['content']}\" for msg in history]\n",
    "    return gr.update(choices=options, value=options[-1] if options else \"\")\n",
    "\n",
    "# 選択したエントリからテキストコンテンツのみを抽出\n",
    "def extract_text(selected_option):\n",
    "    return selected_option.split(\": \", 1)[1] if \": \" in selected_option else selected_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c628cef-f0f3-4189-8708-05a82d0aa806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オーディオ入力を numpy 配列として処理し、更新されたチャット履歴を返す\n",
    "def speak_send(audio_np, history):\n",
    "    if audio_np is None:\n",
    "        return history\n",
    "\n",
    "    # NumPyオーディオをメモリ内の.wavファイルに変換する\n",
    "    sample_rate, audio_array = audio_np\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\") as f:\n",
    "        sf.write(f.name, audio_array, sample_rate)\n",
    "        result = model.transcribe(f.name)\n",
    "        text = result[\"text\"]\n",
    "        \n",
    "    history += [{\"role\":\"user\", \"content\":text}]\n",
    "\n",
    "    return None, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5b8e46-c3db-4868-b8ce-cdb0672f1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle_tool_call 関数を記述\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    tool_name = tool_call.function.name\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    if tool_name == \"get_ticket_price\":\n",
    "        city = arguments.get(\"destination_city\")\n",
    "        price = get_ticket_price(city)\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        }\n",
    "        return response, city\n",
    "\n",
    "    elif tool_name == \"book_ticket\":\n",
    "        city = arguments.get(\"destination_city\")\n",
    "        result = book_ticket(city)\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": result,\n",
    "            \"tool_call_id\": tool_call.id            \n",
    "        }\n",
    "        return response, city\n",
    "\n",
    "    else:\n",
    "        return {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"No tool handler for {tool_name}\",\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        }, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb289f2d-5290-4a0f-8b38-8b153e4aecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The advanced 'chat' function in 'day5'\n",
    "def interact(history, translated_history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    translated_message = translate_message(history[-1][\"content\"], target_lang)\n",
    "    translated_reply = translate_message(reply, target_lang)\n",
    "    \n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    translated_history += [{\"role\":\"user\", \"content\":translated_message}]\n",
    "    translated_history += [{\"role\":\"assistant\", \"content\":translated_reply}]\n",
    "    \n",
    "    # Comment out or delete the next line if you'd rather skip Audio for now..\n",
    "    talker(reply)\n",
    "\n",
    "    return history, update_options(history), history, translated_history, update_options(translated_history), translated_history, gr.update(choices=booked_cities_choices, value=booked_cities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5be5f0e-e8a2-41ea-8944-a1c4fb58bd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seigi/.python3_venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ツール get_ticket_price が ロンドン に対して呼び出されました。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/tmp/tmpd9xkyk8_.wav':   0KB sq=    0B f=0/0   \n",
      "  Duration: 00:00:05.86, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   5.72 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seigi/.python3_venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ツール book_ticket は ロンドン に対して呼び出されました。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/tmp/tmpbl639kfi.wav':   0KB sq=    0B f=0/0   \n",
      "  Duration: 00:00:07.54, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   7.47 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    target_lang = \"zh-CN\"\n",
    "    history_state = gr.State([]) \n",
    "    translated_history_state = gr.State([])\n",
    "    booked_cities_choices = [key.lower().capitalize() for key in ticket_prices.keys()]\n",
    "    booked_cities = []\n",
    "    model = whisper.load_model(\"base\")\n",
    "\n",
    "    with gr.Row():\n",
    "        city_checklist = gr.CheckboxGroup(\n",
    "            label=\"Booked Cities\",\n",
    "            choices=booked_cities_choices     \n",
    "        )\n",
    "            \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot(label=\"Chat History\", type=\"messages\")\n",
    "            selected_msg = gr.Dropdown(label=\"Select message to speak\", choices=[])\n",
    "            speak_btn = gr.Button(\"Speak\")\n",
    "\n",
    "        with gr.Column():\n",
    "            translated_chatbot = gr.Chatbot(label=\"Translated Chat History\", type=\"messages\")\n",
    "            translated_selected_msg = gr.Dropdown(label=\"Select message to speak\", choices=[], interactive=True)\n",
    "            translated_speak_btn = gr.Button(\"Speak\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        language_dropdown = gr.Dropdown(\n",
    "                choices=list(LANGUAGES.keys()),\n",
    "                value=\"Mandarin Chinese\",\n",
    "                label=\"Translation Language\",\n",
    "                interactive=True\n",
    "            )\n",
    "      \n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(sources=\"microphone\", type=\"numpy\", label=\"Speak with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        audio_submit = gr.Button(\"Send\")\n",
    "    \n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "        \n",
    "    language_dropdown.change(fn=update_lang, inputs=[language_dropdown])\n",
    "\n",
    "    speak_btn.click(\n",
    "        lambda selected: speak(extract_text(selected)),\n",
    "        inputs=selected_msg,\n",
    "        outputs=None\n",
    "    )\n",
    "\n",
    "    translated_speak_btn.click(\n",
    "        lambda selected: speak(extract_text(selected)),\n",
    "        inputs=translated_selected_msg,\n",
    "        outputs=None\n",
    "    )\n",
    "\n",
    "    entry.submit(do_entry, inputs=[entry, history_state], outputs=[entry, chatbot]).then(\n",
    "        interact, inputs=[chatbot, translated_chatbot], outputs=[chatbot, selected_msg, history_state, translated_chatbot, translated_selected_msg, translated_history_state, city_checklist]\n",
    "    )\n",
    "    \n",
    "    audio_submit.click(speak_send, inputs=[audio_input, history_state], outputs=[audio_input, chatbot]).then(\n",
    "        interact, inputs=[chatbot, translated_chatbot], outputs=[chatbot, selected_msg, history_state, translated_chatbot, translated_selected_msg, translated_history_state, city_checklist]\n",
    "    )\n",
    "    # clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a8b85-8d75-46ab-b7e1-d95dc88de60a",
   "metadata": {},
   "source": [
    "# 上記のUIの使い方\n",
    "\n",
    "- 録音して[SEND]を押下すると、話した内容がChatに入力される。\n",
    "- 行きたい都市の名前を行ってチケットの価格を確認する。\n",
    "- 予約しますか？に「ハイ」と答えると予約が行われる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
