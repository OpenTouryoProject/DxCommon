{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ddfa9ae6-69fe-444a-b994-8c4c5970a7ec",
      "metadata": {},
      "source": [
        "# プロジェクト - 航空会社AIアシスタント\n",
        "\n",
        "航空会社のAIカスタマーサポートアシスタントを作成するために学んだことをまとめます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b50bbe2-c0b1-49c3-9a5c-1ba7efa2bcb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 輸入\n",
        "\n",
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747e8786-9da8-4342-b6c9-f5f69c2e22ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初期化\n",
        "\n",
        "load_dotenv(override=True)\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
        "if openai_api_key:\n",
        "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"Openai APIキーが設定されていません\")\n",
        "    \n",
        "MODEL = \"gpt-4o-mini\"\n",
        "openai = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a521d84-d07c-49ab-a0df-d6451499ed97",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
        "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
        "system_message += \"Always be accurate. If you don't know the answer, say so.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a2a15d-b559-4844-b377-6bd5cb4949f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# この関数は、最新のグラデーションアップデートを利用しているため、私のビデオの機能よりもかなりシンプルに見えます。\n",
        "\n",
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36bedabf-a0a7-4985-ad8e-07ed6a55a3a4",
      "metadata": {},
      "source": [
        "## ツール\n",
        "\n",
        "ツールは、フロンティアLLMSが提供する非常に強力な機能です。\n",
        "\n",
        "ツールを使用すると、関数を記述し、LLMにその機能をその応答の一部として呼び出すことができます。\n",
        "\n",
        "ほとんど不気味に聞こえます。マシンでコードを実行する力を与えていますか？\n",
        "\n",
        "まあ、ちょっと。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0696acb1-0b05-4dc2-80d5-771be04f1fb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 役立つ機能を作成することから始めましょう\n",
        "\n",
        "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
        "\n",
        "def get_ticket_price(destination_city):\n",
        "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
        "    city = destination_city.lower()\n",
        "    return ticket_prices.get(city, \"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ca4e09-6287-4d3f-997d-fa6afbcf6c85",
      "metadata": {},
      "outputs": [],
      "source": [
        "get_ticket_price(\"London\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4afceded-7178-4c05-8fa6-9f2085e6a344",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 私たちの機能を説明するために必要な特定の辞書構造があります。\n",
        "\n",
        "price_function = {\n",
        "    \"name\": \"get_ticket_price\",\n",
        "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"destination_city\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The city that the customer wants to travel to\",\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"destination_city\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdca8679-935f-4e7f-97e6-e71a4d4f228c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# これはツールのリストに含まれています。\n",
        "\n",
        "tools = [{\"type\": \"function\", \"function\": price_function}]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3d3554f-b4e3-4ce7-af6f-68faa6dd2340",
      "metadata": {},
      "source": [
        "## Openaiを取得してツールを使用します\n",
        "\n",
        "Openaiが「私たちのツールを呼び出す」ことを許可するための厄介なものがいくつかあります\n",
        "\n",
        "私たちが実際に行っていることは、LLMにツールを実行することを望んでいることを知らせる機会を与えることです。\n",
        "\n",
        "新しいチャット関数がどのように見えるかは次のとおりです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce9b0744-9c78-408d-b9df-9f6fd9ed78cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
        "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
        "\n",
        "    if response.choices[0].finish_reason==\"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        response, city = handle_tool_call(message)\n",
        "        messages.append(message)\n",
        "        messages.append(response)\n",
        "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
        "    \n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0992986-ea09-4912-a076-8e5603ee631f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# その関数をhandle_tool_call：書く必要があります：\n",
        "\n",
        "def handle_tool_call(message):\n",
        "    tool_call = message.tool_calls[0]\n",
        "    arguments = json.loads(tool_call.function.arguments)\n",
        "    city = arguments.get('destination_city')\n",
        "    price = get_ticket_price(city)\n",
        "    response = {\n",
        "        \"role\": \"tool\",\n",
        "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
        "        \"tool_call_id\": tool_call.id\n",
        "    }\n",
        "    return response, city"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4be8a71-b19e-4c2f-80df-f59ff2661f14",
      "metadata": {},
      "outputs": [],
      "source": [
        "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "473e5b39-da8f-4db1-83ae-dbaca2e9531e",
      "metadata": {},
      "source": [
        "# マルチモーダルに行きましょう!!\n",
        "\n",
        "GPT-4oの背後にある画像生成モデルであるDall-E-3を使用して、画像を作成できます。\n",
        "\n",
        "これをアーティストと呼ばれる関数に入れましょう。\n",
        "\n",
        "###価格アラート：画像を生成するたびに約4セントかかります - 画像に夢中にならないでください！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c27c4ba-8ed5-492f-add1-02ce9c81d34c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 画像を処理するためのいくつかのインポート\n",
        "\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773a9f11-557e-43c9-ad50-56cbec3a0f8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def artist(city):\n",
        "    image_response = openai.images.generate(\n",
        "            model=\"dall-e-3\",\n",
        "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
        "            size=\"1024x1024\",\n",
        "            n=1,\n",
        "            response_format=\"b64_json\",\n",
        "        )\n",
        "    image_base64 = image_response.data[0].b64_json\n",
        "    image_data = base64.b64decode(image_base64)\n",
        "    return Image.open(BytesIO(image_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d877c453-e7fb-482a-88aa-1a03f976b9e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "image = artist(\"New York City\")\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728a12c5-adc3-415d-bb05-82beb73b079b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f4975b87-19e9-4ade-a232-9b809ec75c9a",
      "metadata": {},
      "source": [
        "## オーディオ（注 - このコースのオーディオはオプションです - 問題が発生した場合は、オーディオをスキップしてください！）\n",
        "\n",
        "そして、Openaiの音声モデルを使用してオーディオを生成する機能トーカーを作りましょう\n",
        "\n",
        "###トラブルシューティングオーディオの問題\n",
        "\n",
        "以下にこのコードを実行するのに問題がある場合（FilenotFoundエラーや欠落パッケージの警告など）、非常に人気のあるオーディオユーティリティであるFFMPEGをインストールする必要がある場合があります。\n",
        "\n",
        "** PCユーザー向け**\n",
        "\n",
        "詳細な指示は[here](https://chatgpt.com/share/6724efee-6b0c-8012-ac5e-72e2e3885905)と要約手順です。\n",
        "\n",
        "1.公式ウェブサイトからFFMPEGをダウンロード：https：//ffmpeg.org/download.html\n",
        "\n",
        "2.ダウンロードしたファイルをコンピューターの場所に抽出します（例： `c：\\ ffmpeg`）\n",
        "\n",
        "3. ffmpeg binフォルダーをシステムパスに追加します。\n",
        " - 「このPC」または「私のコンピュータ」を右クリックして、[プロパティ]を選択します\n",
        " - 「Advanced Systemstings」をクリックします\n",
        " - 「環境変数」をクリックします\n",
        " - 「システム変数」の下で、「パス」を見つけて編集します\n",
        "-FFMPEGビンフォルダーへのパスで新しいエントリを追加します（例： `c：\\ ffmpeg \\ bin`）\n",
        " - コマンドプロンプトを再起動し、Jupyter Lab内でカーネルを行います - >カーネルを再起動して、変更を受け取ります\n",
        "\n",
        "4.新しいコマンドプロンプトを開いて、これを実行して、それがインストールされていることを確認してください\n",
        "`ffmpeg -version`\n",
        "\n",
        "** Macユーザー向け**\n",
        "\n",
        "1.ターミナルウィンドウでこれを実行し、指示に従ってこれを実行していない場合は、Homebrewをインストールしてください。  \n",
        "`/bin/bash -c\" $（curl -fssl https://raw.githubusercontent.com/homebrew/install/head/install.sh） \"`\n",
        "\n",
        "2。「brewインストールffmpeg」でffmpegをインストールします\n",
        "\n",
        "3.「ffmpeg -version」でインストールを確認し、すべてが良い場合は、jupyter lab内でカーネルを行います - >カーネルを再起動して変更を受け取ります\n",
        "\n",
        "私にメッセージを送るか、ed@edwarddonner.comに私にメールしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc90e80-c96e-4dd4-b9d6-386fe2b7e797",
      "metadata": {},
      "source": [
        "## To check you now have ffmpeg and can access it here\n",
        "\n",
        "Excecute the next cell to see if you get a version number. (Putting an exclamation mark before something in Jupyter Lab tells it to run it as a terminal command rather than python code).\n",
        "\n",
        "これがうまくいかない場合は、Jupyterラボを実際に保存して閉じて、LLMS環境をアクティブにすることを覚えている新しいターミナルウィンドウ（MAC）またはAnacondaプロンプト（PC）から再度開始する必要がある場合があります。 This ensures you pick up ffmpeg.\n",
        "\n",
        "And if that doesn't work, please contact me!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3be0fb-1d34-4693-ab6f-dbff190afcd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "!ffmpeg -version\n",
        "!ffprobe -version\n",
        "!ffplay -version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d91d3f8f-e505-4e3c-a87c-9e42ed823db6",
      "metadata": {},
      "source": [
        "# Macユーザーの場合 - そしておそらく多くのPCユーザーも\n",
        "\n",
        "このバージョンはあなたのために正常に動作するはずです。 Windowsユーザーにも機能する可能性がありますが、Tempファイルへのアクセス許可エラー書き込みが表示される場合があります。もしそうなら、次のセクションをご覧ください！\n",
        "\n",
        "いつものように、問題がある場合は、私に連絡してください！ （オーディオ生成にあまり興味がない場合は、後のコードでAudio Talker（）にコメントすることもできます）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbfe93b-5e86-4e68-ba71-b301cd5230db",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "      model=\"tts-1\",\n",
        "      voice=\"onyx\",    # また、Onyxを合金に置き換えてみてください\n",
        "      input=message\n",
        "    )\n",
        "    \n",
        "    audio_stream = BytesIO(response.content)\n",
        "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
        "    play(audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b88d775d-d357-4292-a1ad-5dc5ed567281",
      "metadata": {},
      "outputs": [],
      "source": [
        "talker(\"Well, hi there\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad89a9bd-bb1e-4bbb-a49a-83af5f500c24",
      "metadata": {},
      "source": [
        "# Windowsユーザー（または上記の問題があるMacユーザー）の場合）\n",
        "\n",
        "##最初に上記のMacバージョンを試してくださいが、Tempファイルへのアクセス許可エラー書き込みが表示された場合は、代わりにこのコードが機能するはずです。\n",
        "\n",
        "学生のマーク・Mとパトリック・Hとクロードのコラボレーションは、これを解決しました！\n",
        "\n",
        "以下は4つのバリエーションです - うまくいけば、そのうちの1つがPCで動作します。そうでない場合は、私にメッセージを送ってください！\n",
        "\n",
        "そして、Macの人々のために - 以下の3つの作業も私のMacで作業します -  Macバージョンがあなたに問題を与えたなら、これらを試してください。\n",
        "\n",
        "## PCバリエーション1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d104b96a-02ca-4159-82fe-88e0452aa479",
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"onyx\",\n",
        "        input=message)\n",
        "\n",
        "    audio_stream = BytesIO(response.content)\n",
        "    output_filename = \"output_audio.mp3\"\n",
        "    with open(output_filename, \"wb\") as f:\n",
        "        f.write(audio_stream.read())\n",
        "\n",
        "    # 生成されたオーディオを再生します\n",
        "    display(Audio(output_filename, autoplay=True))\n",
        "\n",
        "talker(\"Well, hi there\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5d11f4-bbd3-43a1-904d-f684eb5f3e3a",
      "metadata": {},
      "source": [
        "## PCバリエーション2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d59c8ebd-79c5-498a-bdf2-3a1c50d91aa0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import subprocess\n",
        "from io import BytesIO\n",
        "from pydub import AudioSegment\n",
        "import time\n",
        "\n",
        "def play_audio(audio_segment):\n",
        "    temp_dir = tempfile.gettempdir()\n",
        "    temp_path = os.path.join(temp_dir, \"temp_audio.wav\")\n",
        "    try:\n",
        "        audio_segment.export(temp_path, format=\"wav\")\n",
        "        time.sleep(3) # 学生ドミニクは、これが必要であることを発見しました。また、PCで必要でないかどうかを確認するためにコメントしてみることもできます\n",
        "        subprocess.call([\n",
        "            \"ffplay\",\n",
        "            \"-nodisp\",\n",
        "            \"-autoexit\",\n",
        "            \"-hide_banner\",\n",
        "            temp_path\n",
        "        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    finally:\n",
        "        try:\n",
        "            os.remove(temp_path)\n",
        "        except Exception:\n",
        "            pass\n",
        " \n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"onyx\",  # また、Onyxを合金に置き換えてみてください\n",
        "        input=message\n",
        "    )\n",
        "    audio_stream = BytesIO(response.content)\n",
        "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
        "    play_audio(audio)\n",
        "\n",
        "talker(\"Well hi there\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96f90e35-f71e-468e-afea-07b98f74dbcf",
      "metadata": {},
      "source": [
        "## PCバリエーション3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8597c7f8-7b50-44ad-9b31-db12375cd57b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "from io import BytesIO\n",
        "\n",
        "def talker(message):\n",
        "    # Windows上の一時ファイルのカスタムディレクトリを設定します\n",
        "    custom_temp_dir = os.path.expanduser(\"~/Documents/temp_audio\")\n",
        "    os.environ['TEMP'] = custom_temp_dir  # 必要に応じて「TMP」を使用することもできます\n",
        "    \n",
        "    # フォルダーが存在しない場合は、フォルダーを作成します\n",
        "    if not os.path.exists(custom_temp_dir):\n",
        "        os.makedirs(custom_temp_dir)\n",
        "    \n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"onyx\",  # また、Onyxを合金に置き換えてみてください\n",
        "        input=message\n",
        "    )\n",
        "    \n",
        "    audio_stream = BytesIO(response.content)\n",
        "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
        "\n",
        "    play(audio)\n",
        "\n",
        "talker(\"Well hi there\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e821224c-b069-4f9b-9535-c15fdb0e411c",
      "metadata": {},
      "source": [
        "## PCバリエーション4\n",
        "\n",
        "###まったく異なるサウンドライブラリを試してみましょう\n",
        "\n",
        "最初に次のセルを実行して新しいライブラリをインストールしてから、その下のセルを試してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69d3c0d9-afcc-49e3-b829-9c9869d8b472",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install simpleaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f9cc99-36b7-4554-b3f4-f2012f614a13",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from io import BytesIO\n",
        "import tempfile\n",
        "import os\n",
        "import simpleaudio as sa\n",
        "\n",
        "def talker(message):\n",
        "    response = openai.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"onyx\",  # また、Onyxを合金に置き換えてみてください\n",
        "        input=message\n",
        "    )\n",
        "    \n",
        "    audio_stream = BytesIO(response.content)\n",
        "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
        "\n",
        "    # 書き込み許可があるフォルダーに一時ファイルを作成する\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False, dir=os.path.expanduser(\"~/Documents\")) as temp_audio_file:\n",
        "        temp_file_name = temp_audio_file.name\n",
        "        audio.export(temp_file_name, format=\"wav\")\n",
        "    \n",
        "    # Simpleaudioを使用してオーディオを読み込んで再生します\n",
        "    wave_obj = sa.WaveObject.from_wave_file(temp_file_name)\n",
        "    play_obj = wave_obj.play()\n",
        "    play_obj.wait_done()  # 再生が終了するのを待ちます\n",
        "\n",
        "    # その後、一時ファイルをクリーンアップします\n",
        "    os.remove(temp_file_name)\n",
        "    \n",
        "talker(\"Well hi there\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7986176b-cd04-495f-a47f-e057b0e462ed",
      "metadata": {},
      "source": [
        "## PCユーザー - これらの4つのバリエーションのいずれも機能しなかった場合！\n",
        "\n",
        "私に連絡してください。申し訳ありませんが、これが問題を引き起こしています！私たちはそれを理解します。\n",
        "\n",
        "または、PCからオーディオを再生することは、このコースでは非常に批判的ではありません。今のところ画像生成に集中してオーディオをスキップするか、後で戻ってくることができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d48876d-c4fa-46a8-a04f-f9fadf61fb0d",
      "metadata": {},
      "source": [
        "# エージェントフレームワーク\n",
        "\n",
        "「エージェントAI」という用語とエージェント化は、次のような多くの手法を指す傘の用語です。\n",
        "\n",
        "1.複数のLLMが特別なタスクを実行して、複雑な問題をより小さなステップに分割する\n",
        "2。LLMSがツールを使用して追加の機能を提供する能力\n",
        "3。エージェントが協力できる「エージェント環境」\n",
        "4. LLMはプランナーとして機能し、スペシャリストのために大きなタスクを小さなタスクに分割することができます\n",
        "5。自治 /代理店を持っているエージェントの概念、プロンプトに単に応答するだけで - メモリなど\n",
        "\n",
        "ここでは1と2を示していますが、それほどではありません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba820c95-02f5-499e-8f3c-8727ee0a6c0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(history):\n",
        "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
        "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
        "    image = None\n",
        "    \n",
        "    if response.choices[0].finish_reason==\"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        response, city = handle_tool_call(message)\n",
        "        messages.append(message)\n",
        "        messages.append(response)\n",
        "        image = artist(city)\n",
        "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
        "        \n",
        "    reply = response.choices[0].message.content\n",
        "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
        "\n",
        "    # 今のところオーディオをスキップしたい場合は、次の行をコメントまたは削除してください。\n",
        "    talker(reply)\n",
        "    \n",
        "    return history, image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38d0d27-33bf-4992-a2e5-5dbed973cde7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# プリセットチャットインターフェイスを使用していないため、より複雑なグラデーションコード！\n",
        "# inbrowserを渡す=最後の行でtrueを使用すると、グラデーションウィンドウがすぐにポップアップされます。\n",
        "\n",
        "with gr.Blocks() as ui:\n",
        "    with gr.Row():\n",
        "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
        "        image_output = gr.Image(height=500)\n",
        "    with gr.Row():\n",
        "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
        "    with gr.Row():\n",
        "        clear = gr.Button(\"Clear\")\n",
        "\n",
        "    def do_entry(message, history):\n",
        "        history += [{\"role\":\"user\", \"content\":message}]\n",
        "        return \"\", history\n",
        "\n",
        "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
        "        chat, inputs=chatbot, outputs=[chatbot, image_output]\n",
        "    )\n",
        "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
        "\n",
        "ui.launch(inbrowser=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226643d2-73e4-4252-935d-86b8019e278a",
      "metadata": {},
      "source": [
        "# 演習とビジネスアプリケーション\n",
        "\n",
        "より多くのツールを追加する - おそらく実際にフライトを予約するシミュレーション。学生がこれを行って、コミュニティの寄付フォルダーでその例を提供しました。\n",
        "\n",
        "次：これを取り、それをあなたのビジネスに適用してください。作業のアクティビティを実行できるツールを使用して、マルチモーダルAIアシスタントを作成します。カスタマーサポートアシスタント？新しい従業員のオンボーディングアシスタント？たくさんの可能性！また、別のノートブックの週の終わりのエクササイズを参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e795560-1867-42db-a256-a23b844e6fbe",
      "metadata": {},
      "source": [
        "<テーブルスタイル= \"マージン：0;テキストアライグ：左;\">\n",
        "    <tr>\n",
        "        <td style = \"width：150px; height：150px; vertical-align：middle;\">\n",
        "            <img src = \"../ありがとうyou.jpg\" width = \"150\" height = \"150\" style = \"display：block;\" />\n",
        "        </td>\n",
        "        <td>\n",
        "            <h2 style = \"color：＃090;\">特別なリクエストがあります</h2>\n",
        "            <Span style = \"color：＃090;\">\n",
        "                私の編集者は、学生がこのコースをUdemyで評価するときに大きな違いをもたらすと言っています。これは、Udemyが他の人に見せるかどうかを決定する主な方法の1つです。あなたがこれを評価するのに少し時間がかかるなら、私はとても感謝しています！とにかく - いつでも支援できる場合は、常にed@edwarddonner.comで私に連絡してください。\n",
        "            </span>\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}