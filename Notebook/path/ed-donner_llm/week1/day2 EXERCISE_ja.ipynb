{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# あなたの最初の課題へようこそ！\n",
    "\n",
    "指示は以下にあります。これを試してみてください、そしてあなたが行き詰まったらソリューションフォルダーを見てください（または私に聞いてください！）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">割り当てに到達する直前 --</h2>\n",
    "            <span style=\"color:#f71;\">コースの有用なリソースのこのページであなたを指すのに少し時間がかかると思いました。これには、すべてのスライドへのリンクが含まれます。<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            これをブックマークしておくと、時間の経過とともにもっと便利なリンクを追加し続けます。\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# 宿題の運動の割り当て\n",
    "\n",
    "Day 1プロジェクトをアップグレードして、Webページを要約して、OpenaiではなくOllamaを介してローカルに実行されるオープンソースモデルを使用します\n",
    "\n",
    "有料APIを使用したくない場合は、このテクニックをすべての後続のプロジェクトに使用できます。\n",
    "\n",
    "**利点：**\n",
    "1. API料金なし - オープンソース\n",
    "2. データは箱を離れません\n",
    "\n",
    "**短所：**\n",
    "1. フロンティアモデルよりも大幅に少ないパワー\n",
    "\n",
    "## Ollamaのインストールに関する要約\n",
    "\n",
    "[ollama.com](https://ollama.com)にアクセスしてインストールしてください！\n",
    "\n",
    "完了すると、Ollamaサーバーはすでにローカルで実行されているはずです。  \n",
    "訪問する場合：  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "「Ollamaが実行されている」というメッセージが表示されます。  \n",
    "\n",
    "そうでない場合は、新しいターミナル（MAC）またはPowerShell（Windows）を持ち上げて、`ollama serve`を入力します。  \n",
    "別の端末（MAC）またはPowerShell（Windows）で、`ollama pull llama3.2`を入力します。  \n",
    "次に、[http://localhost:11434/](http://localhost:11434/)をもう一度試してください。\n",
    "\n",
    "Ollamaがマシンで遅い場合は、代替として`llama3.2:1b`を使用してみてください。\n",
    "\n",
    "TerminalまたはPowerShellから`ollama pull llama3.2:1b`を実行し、以下のコードを`MODEL = \"llama3.2\"`から`MODEL = \"llama3.2:1b\"`に変更します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2:1b\" #\"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openaiに使用したのと同じ形式を使用してメッセージリストを作成する\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"生成AIのビジネス・アプリケーションのいくつかについて説明して下さい。\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 74701a8c35f6... 100% ▕████████████████▏ 1.3 GB                         \u001b[K\n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 4f659a1e86d7... 100% ▕████████████████▏  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# モデルがロードされていることを確認しましょう\n",
    "!ollama pull llama3.2:1b #llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI (Artificial Intelligence) は、機械学の分野における AI を指すことに関係なく、さまざまな状況で使用できる分野です。このようなアプリケーションは、人工知能を用いて解決策や処理を簡素化し、より効率的になるように設計されています。\n",
      "\n",
      "ここでは、AI を活用したビジネス アプリケーションのいくつかについて説明します。\n",
      "\n",
      "1. **マーケティング アップデート**: 企業は、コンサルタントに依頼して、市場 Trend の分析を AI により行うことができます。これにより、より効果的なマーケティング戦略を立てることができ、これにより顧客が増えるでしょう。\n",
      "\n",
      "2. **セール システム**: 企業は、AI を活用して、顧客を特定し、販売プロセスにアドバイスするシステムを作成できます。これにより、顧客のニーズに対応する可能性が高くなります。\n",
      "\n",
      "3. **データ analisis**: 企業は、さまざまなデータ形式から情報を抽出して、ビジネス戦略をより効果的に理解できるようになります。AI の分析ツールが使用されると、より効率的で優れた分析が可能になります。\n",
      "\n",
      "4. **自動化 コンストラクション**: 企業は、コンSTRUCTIONプロセスで、パイプラインやメンテナンスを自動化するシステムを作成できます。これにより、労働時間の削減とコストの削減につながります。\n",
      "\n",
      "5. **デジタル サポート システム**: 企業は、顧客に提供されたサービスに対して、AI を活用してサポートツールを設計できます。例えば、顧客の質問や疑問に対する回答を提供するために、AI を使用できます。\n",
      "\n",
      "6. **ストॉक マーケティング**: 企業は、トレード システムに AI を活用して、ストックの価格を予測し、より効率的にマネーを節約できます。\n",
      "\n",
      "7. **カスタム スポンサー**: 企業は、顧客のニーズに対応するために、AI を使用して、特定のコンテキストにアドバイスを提供できます。これにより、顧客がより関心を持つ可能性が高くなります。\n",
      "\n",
      "8. **ビジネス ルール推進**: 企業は、AI を活用して、ビジネス ルールと戦略に基づいて決定を下すことができます。これにより、より効率的で優れた意思決定が可能になります。\n",
      "\n",
      "9. **データ モデリング**: 企業は、さまざまなデータ形式から情報を抽出し、データ モデルを作成するためのツールを使用します。これにより、より効率的にビジネス戦略を立てることができます。\n",
      "\n",
      "10. **機械学的 ライフ Cypher**: 企業は、パーソナルाइザーの活用して、顧客のニーズに対応し、より効果的なマーケティング戦略を立てることができます。\n"
     ]
    }
   ],
   "source": [
    "# これが何らかの理由で機能しない場合は、次のセルの2つのバージョンを試してください\n",
    "# このラボの上部にある「オラマのインストールに関する要約」の指示を再確認してください\n",
    "# そして、それがうまくいかなければ - 私に連絡してください！\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Ollamaパッケージの紹介\n",
    "\n",
    "そして今、私たちは同じことをしますが、直接HTTP呼び出しの代わりにエレガントなOllama Pythonパッケージを使用します。\n",
    "\n",
    "ボンネットの下では、localhost:11434で実行されているOllamaサーバーに上記と同じ呼び出しを行っています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528e492-89d9-4d43-8a70-4401bec8fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI のビジネス アプリケーションを考えています。以下は幾らくの例です。\n",
      "\n",
      "1. **ビジネス・リースング** - このアプリケーションでは、顧客からさまざまな問題や要求を提示し、ビジネス パートナーにAI の解決策を提供します。\n",
      "2. **メンテナンス・サポート** - このアプリケーションでは、製品またはサービスでエラーが発生した場合に、専門家が対応して問題を解決するためにAI を使用します。\n",
      "3. **データベース・マネジメント** - このアプリケーションでは、顧客のデータベースを分析してビジネス パートナーに情報を提供し、機会を得るためにAI を活用します。\n",
      "4. **トレーニング・セッション** - このアプリケーションでは、AI のパラメトリック Learning を使用して顧客のニーズに基づいてトレーニング セッションを提供します。\n",
      "5. **リソース・プロバイダー** - このアプリケーションでは、製品またはサービスでエラーが発生した場合に、専門家が対応して問題を解決するためにAI を使用します。\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## 代替アプローチ - OpenAI Pythonライブラリを使用してOllamaに接続する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI のビジネス アプリケーションは、企業が製品やサービスを開発し、提供する際に AI を使用したさまざまなアプローチをサポートできるようになった。以下は 5 つの例です。\n",
      "\n",
      "1. **AI 生成コンテンツ**: 人気の作曲家などで AI でCreation of musical compositionsを作成したり、映画や劇を生成したりするコミュニティがあります。これらのアプリケーションでは、AI Powered の作曲机を使用して、音楽学者の仕事が簡素化したり、動画作成に基づくとより高品質の作品が producible になりました。\n",
      "\n",
      "2. **AI 買い物支援システム**: 買い物業態の中での顧客のニーズを AI で解釈し、情報が得られるさまざまな製品やサービスの推測と指示を提供するようなアプリケーションがある。これにより、企業は顧客に対してより効率的かいた販売戦略となります。\n",
      "\n",
      "3. **AI 対人間のトレーニング**: イベントやビジネスを改善するためにAIを用いたトレーニング支援システムが開発されました。例えば、スポーツチームは AI で対戦 opponent の動き、プレイを分析 करक、これをイベントに反映させ、優れた結果を出します。\n",
      "\n",
      "4. **AI から生成された知識**: さまざまな業界における新しいデータと Knowledge が提供されるようにするために、AI Powered の情報収集機構が開発されました。これにより、個々の製品やサービスもより適合した基礎となる情報源があります。\n",
      "\n",
      "5. **AI 対人間のサポートシステム**: スールングサプライヤーはAIの分析を使用して顧客にサプライヤーサポートを与えるために開発したり、AI Powered にたどり着いたサプライヤー情報サーチアプリケーションとなる例です。\n"
     ]
    }
   ],
   "source": [
    "# 実際には、一部の人々が好むかもしれない代替アプローチがあります\n",
    "# OpenAIクライアントPythonライブラリを使用して、Ollamaを呼び出すことができます。\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## なぜそれが機能するのか、よく分かりませんか？\n",
    "奇妙に思えますよね？OpenAIのコードを使ってOllamaを呼び出しているだけなのに？一体何が起こっているのでしょうか？\n",
    "\n",
    "要点は以下の通りです。：\n",
    "\n",
    "Pythonクラス `OpenAI` は、OpenAIのエンジニアが書いた、インターネット経由でエンドポイントを呼び出すコードです。\n",
    "\n",
    "`openai.chat.completions.create()`を呼び出すと、このPythonコードは次のURLにWebリクエストを送信します。: `https://api.openai.com/v1/chat/completions`\n",
    "\n",
    "このようなコードは「クライアントライブラリ」と呼ばれます。これは、Webリクエストを行うためにマシンで実行されるラッパーコードです。\n",
    "\n",
    "GPTの実際のパワーは、コンピューターではなく、このAPIの背後にあるOpenAIのクラウドで実行されています！\n",
    "\n",
    "OpenAIは非常に人気があったため、他の多くのAIプロバイダーが同一のWebエンドポイントを提供していたため、同じアプローチを使用できます。\n",
    "\n",
    "したがって、Ollamaには`http://localhost:11434/v1/chat/completions`のローカルボックスで実行されているエンドポイントがあります  \n",
    "そして、2週目には、ジェミニやディープシークなど、他の多くのプロバイダーもこれを行っていることがわかります。\n",
    "\n",
    "そして、OpenAIのチームは素晴らしいアイデアを持っていました。彼らはクライアントライブラリを拡張して、別の「ベースURL」を指定し、ライブラリを使用して互換性のあるAPIを呼び出すことができます。\n",
    "\n",
    "それでおしまい！\n",
    "\n",
    "あなたが言うとき: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "その後、これは同じエンドポイント呼び出しを行いますが、OpenAIの代わりにOllamaに。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## また、驚くべき推論モデルDeepseekを試してみてください\n",
    "\n",
    "ここでは、1.5Bに蒸留されているDeepSeek-Reasonerのバージョンを使用します。  \n",
    "これは実際には、deepseek R1によって生成された同期データを使用してファインチューニングされたQwenの1.5bバリアントです。\n",
    "\n",
    "DeepSeek の他のサイズは、[ココ](https://ollama.com/library/deepseek-r1)であり、671B パラメータのフル バージョンまで用意されていますが、これはドライブの 404GB を使用するため、ほとんどの人にとっては大きすぎます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# これには数分かかる場合があります！その後、<shink>タグ内に魅力的な「思考」トレースが表示され、その後にいくつかの適切な定義が表示されます\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"LLMの背後にあるいくつかのコア概念の定義をお願いします：ニューラルネットワーク、attention、transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# 今あなたのための運動\n",
    "Day1からコードを取り、ここに組み込んで、OpenAIの代わりにローカルで実行されているLlama 3.2を使用するWebサイトsummarizerを構築します。上記のアプローチのいずれかを使用します。\n",
    "\n",
    "https://github.com/ed-donner/llm_engineering/blob/main/week1/community-contributions/Day2-Solution-Ollama.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*   **Home**: A website about the creator, Ed Donner, and his work on LLMs (Large Language Models) and AI.\n",
       "*   **About**: Introduces the creator and provides a brief overview of their interests and background.\n",
       "*   **Posts**:\n",
       "    *   \"Well, hi there.\" - An introduction to the creator's online presence and interests.\n",
       "    *   [Nebula.io](https://www.nebularo.com/) - A company that applies AI to talent discovery and management. Co-founded by Ed Donner.\n",
       "*   **News/Announcements**:\n",
       "    *   May 28, 2025: A new course will be announced, titled \"Connecting my courses – become an LLM expert and leader.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports:-\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama\n",
    "\n",
    "# Constants:-\n",
    "MODEL = \"llama3.2:1b\"\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "                and provides a short summary, ignoring text that might be navigation related. \\\n",
    "                Respond in markdown.\"\n",
    "\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "                    please provide a short summary of this website in markdown. \\\n",
    "                    If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "\n",
    "def summary(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "        model = MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return display(Markdown(response['message']['content']))\n",
    "\n",
    "\n",
    "summary(\"https://edwarddonner.com\")\n",
    "# summary(\"https://cnn.com\")\n",
    "# summary(\"https://anthropic.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
