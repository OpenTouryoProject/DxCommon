{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# あなたの最初の課題へようこそ！\n",
    "\n",
    "指示は以下にあります。これを試してみてください、そしてあなたが行き詰まったらソリューションフォルダーを見てください（または私に聞いてください！）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">割り当てに到達する直前 --</h2>\n",
    "            <span style=\"color:#f71;\">コースの有用なリソースのこのページであなたを指すのに少し時間がかかると思いました。これには、すべてのスライドへのリンクが含まれます。<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            これをブックマークしておくと、時間の経過とともにもっと便利なリンクを追加し続けます。\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# 宿題の運動の割り当て\n",
    "\n",
    "Day 1プロジェクトをアップグレードして、Webページを要約して、OpenaiではなくOllamaを介してローカルに実行されるオープンソースモデルを使用します\n",
    "\n",
    "有料APIを使用したくない場合は、このテクニックをすべての後続のプロジェクトに使用できます。\n",
    "\n",
    "**利点：**\n",
    "1. API料金なし - オープンソース\n",
    "2。データは箱を離れません\n",
    "\n",
    "**短所：**\n",
    "1.フロンティアモデルよりも大幅に少ないパワー\n",
    "\n",
    "## オラマのインストールに関する要約\n",
    "\n",
    "[ollama.com](https://ollama.com)にアクセスしてインストールしてください！\n",
    "\n",
    "完了すると、Ollamaサーバーはすでにローカルで実行されているはずです。  \n",
    "訪問する場合：  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "「Ollamaが実行されている」というメッセージが表示されます。  \n",
    "\n",
    "そうでない場合は、新しいターミナル（MAC）またはPowerShell（Windows）を持ち上げて、「Ollama Serve」を入力します  \n",
    "別の端末（MAC）またはPowerShell（Windows）で、「Ollama Pull llama3.2」を入力します  \n",
    "次に、[http://localhost:11434/](http://localhost:11434/)をもう一度試してください。\n",
    "\n",
    "オラマがマシンで遅い場合は、代替として「llama3.2：1b」を使用してみてください。端子またはPowerShellからllama3.2：1b`を \"ollama pull llama3.2：1b`を実行し、以下のコードを` model = \"llama3.2\" `から` model = \"llama3.2：1b\" `から変更します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定数\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openaiに使用したのと同じ形式を使用してメッセージリストを作成する\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルがロードされていることを確認しましょう\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# これが何らかの理由で機能しない場合は、次のセルの2つのバージョンを試してください\n",
    "# このラボの上部にある「オラマのインストールに関する要約」の指示を再確認してください\n",
    "# そして、それがうまくいかなければ - 私に連絡してください！\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Ollamaパッケージの紹介\n",
    "\n",
    "そして今、私たちは同じことをしますが、直接HTTP呼び出しの代わりにエレガントなOllama Pythonパッケージを使用します。\n",
    "\n",
    "ボンネットの下では、localhost：11434で実行されているOllamaサーバーに上記と同じ呼び出しを行っています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## 代替アプローチ -  Openai Pythonライブラリを使用してOllamaに接続する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実際には、一部の人々が好むかもしれない代替アプローチがあります\n",
    "# OpenaiクライアントPythonライブラリを使用して、Ollamaを呼び出すことができます。\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## なぜそれが機能するのか混乱していますか？\n",
    "\n",
    "奇妙に思えますよね？ Openaiコードを使用してOllamaを呼び出しましたか？どうしたの？！\n",
    "\n",
    "これがスクープです：\n",
    "\n",
    "Pythonクラス「Openai」は、インターネットを介してエンドポイントに電話をかけるOpenaiエンジニアによって書かれた単純なコードです。  \n",
    "\n",
    "`openai.chat.completions.create（）`を呼び出すと、このPythonコードは次のURLにWeb要求を行うだけです。\n",
    "\n",
    "このようなコードは「クライアントライブラリ」と呼ばれます。これは、Webリクエストを行うためにマシンで実行されるラッパーコードです。 GPTの実際のパワーは、コンピューターではなく、このAPIの背後にあるOpenaiのクラウドで実行されています！\n",
    "\n",
    "Openaiは非常に人気があったため、他の多くのAIプロバイダーが同一のWebエンドポイントを提供していたため、同じアプローチを使用できます。\n",
    "\n",
    "したがって、Ollamaにはhttp：// localhost：11434/v1/chat/completionsのローカルボックスで実行されているエンドポイントがあります  \n",
    "そして、2週目には、ジェミニやディープシークなど、他の多くのプロバイダーもこれを行っていることがわかります。\n",
    "\n",
    "そして、OpenAIのチームは素晴らしいアイデアを持っていました。彼らはクライアントライブラリを拡張して、別の「ベースURL」を指定し、ライブラリを使用して互換性のあるAPIを呼び出すことができます。\n",
    "\n",
    "それでおしまい！\n",
    "\n",
    "あなたが言うとき： `ollama_via_openai = openai（base_url = 'http：// localhost：11434/v1'、api_key = 'ollama'）`  \n",
    "その後、これは同じエンドポイント呼び出しを行いますが、Openaiの代わりにOllamaに。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## また、驚くべき推論モデルDeepseekを試してみてください\n",
    "\n",
    "ここでは、1.5Bに蒸留されているDeepSeek-Reasonerのバージョンを使用します。  \n",
    "これは実際には、deepseek R1によって生成された同期データを使用して微調整されたQwenの1.5bバリアントです。\n",
    "\n",
    "DeepSeekのその他のサイズは、[here](https://ollama.com/library/deepseek-r1)であり、671bパラメーターバージョンの完全なバージョンまでです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# これには数分かかる場合があります！その後、<shink>タグ内に魅力的な「思考」トレースが表示され、その後にいくつかの適切な定義が表示されます\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# 今あなたのための運動\n",
    "\n",
    "Day1からコードを取り、ここに組み込んで、Openaiの代わりにローカルで実行されているLlama 3.2を使用するWebサイトsummarizerを構築します。上記のアプローチのいずれかを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
