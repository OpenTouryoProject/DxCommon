{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046fd8f8-ad14-4c7f-b759-fec52f5b5306",
   "metadata": {},
   "source": [
    "＃価格は正しいです\n",
    "\n",
    "今日、商品の価格を推定するためのより複雑なソリューションを構築しています。\n",
    "\n",
    "1.このノートブック：400,000のトレーニングデータを使用してRAGデータベースを作成します\n",
    "2。Day2.1ノートブック：2dで視覚化します\n",
    "3。2.2日目ノートブック：3Dで視覚化します\n",
    "4。Day2.3ノートブック：GPT-4O-MINIでRAGパイプラインを構築してテストする\n",
    "5。Day2.4ノートブック：（a）ランダムフォレストプライザー（b）すべての価格からの寄付を可能にするアンサンブルプライザーを作成する\n",
    "\n",
    "うーん！それは一日で乗り越えるのにたくさんのことです！\n",
    "\n",
    "＃＃ ご注意ください：\n",
    "\n",
    "私たちはすでに、独自のファインチューニングされたLLMを使用して非常に強力な製品推定器を持っています。ほとんどの人はそれに非常に満足するでしょう！これらの追加の手順を追加する主な理由は、RAGとエージェントワークフローで専門知識を深めることです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a2a24-1a58-42be-8034-6d116fb8d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2359ccc0-dbf2-4b1e-9473-e472b32f548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')\n",
    "DB = \"products_vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645167e6-cf0d-42d2-949f-1089a25a2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Faceにログインします\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8491f550-df4a-4c8f-a260-a7a419e8efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顔を抱き締めるためにログインした後の別の輸入品 - ありがとう、Trung N.！\n",
    "\n",
    "from items import Item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4995a4-f67f-4871-87df-8c6439b06366",
   "metadata": {},
   "source": [
    "## PKLファイルに戻ります\n",
    "\n",
    "6週目にデータキュレーションを楽しんだように、おそらくそのプロセス全体を再び経験したくないでしょう！\n",
    "\n",
    "次に作成したPKLファイルを再利用しましょう。ファイル「train.pkl」と「test.pkl」を今週の8フォルダーにコピーするか、ここからダウンロードすることもできます。\n",
    "\n",
    "https://drive.google.com/drive/folders/1f_izgybvs9o0j5sb3xmtteqb3bxllzrw?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bd995-ec3e-43cd-8179-7fe14b275877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# このフォルダーにtrain.pklを使用すると、これを実行できます。\n",
    "\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817eaf5-4302-4a18-9148-d1062e3b3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0].prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1ba16-7e80-4096-ac88-64ef8edcc80c",
   "metadata": {},
   "source": [
    "# 次に、Chroma DataStoreを作成します\n",
    "\n",
    "5週目に、架空の会社Insurellmのオブジェクトの塊を表す123のドキュメントを含むChroma Datastoreを作成しました。\n",
    "\n",
    "次に、トレーニングデータセットから400,000の製品を備えたChroma Datastoreを作成します！それは本物になっています！\n",
    "\n",
    "Langchainは使用していませんが、APIは非常に簡単で、以前と一致していることに注意してください。\n",
    "\n",
    "特別なメモ：Chromaがクラッシュし、Windowsユーザーの場合は、以前のバージョンのChromaライブラリに戻って次を試してみてください。  \n",
    "`！pipインストールChromadb == 0.5.0`  \n",
    "学生のKelly Zに感謝します。これを見つけて、github Issue [here](https://github.com/chroma-core/chroma/issues/2513)を指摘してくれました。 \n",
    "ただし、クロマを戻さずに最初に試してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aab95e-d719-4476-b6e7-e248120df25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95dafd-ab80-464e-ba8a-dec7a2424780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# コレクションが存在するかどうかを確認し、それが行われている場合は削除します\n",
    "collection_name = \"products\"\n",
    "\n",
    "# 古いバージョンのChromaの場合、後続のラインの代わりにこの行を使用します\n",
    "# 既存の_collection_names = [collection.name for collection in client.list_collections（）]\n",
    "existing_collection_names = client.list_collections()\n",
    "\n",
    "if collection_name in existing_collection_names:\n",
    "    client.delete_collection(collection_name)\n",
    "    print(f\"Deleted existing collection: {collection_name}\")\n",
    "\n",
    "collection = client.create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392ed28-203d-4e73-be87-ac1390bdf722",
   "metadata": {},
   "source": [
    "＃sentenceTransfomerの紹介\n",
    "\n",
    "All-Minilmは、文と段落を384次元密度のベクトル空間にマッピングするHugging Faceの非常に便利なモデルであり、セマンティック検索などのタスクに最適です。\n",
    "\n",
    "https://huggingface.co/sentence-transformers/all-minilm-l6-v2\n",
    "\n",
    "ローカルでかなり迅速に実行できます。\n",
    "\n",
    "前回、Openai埋め込みを使用してベクトル埋め込みを生成しました。 Openai Embeddingsと比較した利点：\n",
    "1。それは無料で速いです！\n",
    "3.ローカルで実行できるので、データが私たちの箱を離れることはありません - あなたが個人的なぼろきれを構築している場合に役立つかもしれません\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87db200-d19d-44bf-acbd-15c45c70f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23a025-4c35-4d3a-96ad-b956cad37b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストのリストを渡し、ベクターの数字を取り戻す\n",
    "\n",
    "vector = model.encode([\"Well hi there\"])[0]\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adde63f-e732-4f7c-bba9-f8b2a469f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クイックサイドバー - ビデオへの追加 - ベクターを比較する機能\n",
    "\n",
    "import numpy as np\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def how_similar(text1, text2):\n",
    "    vector1, vector2 = model.encode([text1, text2])\n",
    "    similarity = cosine_similarity(vector1, vector2)\n",
    "    print(f\"Similarity between {text1} and {text2} is {similarity*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c8d19-6993-42e7-afd6-4c61ffc19419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# そして、コンテキストにいくつかの単語を追加することで物事を変える方法を見てみましょう！\n",
    "\n",
    "how_similar(\"Java\", \"C++\")\n",
    "how_similar(\"Java\", \"mug\")\n",
    "how_similar(\"Cup of Java\", \"mug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de1bf8-c9b5-45b4-9f4b-86af93b3f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メインストーリーに戻りましょう - 私たちがベクトル化できるものを作ってみましょう\n",
    "\n",
    "def description(item):\n",
    "    text = item.prompt.replace(\"How much does this cost to the nearest dollar?\\n\\n\", \"\")\n",
    "    return text.split(\"\\n\\nPrice is $\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1205bd-4692-44ef-8ea4-69f255354537",
   "metadata": {},
   "outputs": [],
   "source": [
    "description(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4ef1f-c696-4a01-b011-00fbccbc1a56",
   "metadata": {},
   "source": [
    "## 今、私たちはぼろきれデータストアに入力します\n",
    "\n",
    "次のセルは、Chromaの400,000のアイテムに浸透します。\n",
    "\n",
    "これに時間がかかりすぎる場合は、ドキュメントの数をお気軽に削減してください！あなたは次のように変更できます：  \n",
    "`number_of_documents = 20000`  \n",
    "そして、それは完全に良いぼろきれのパイプラインのためにたくさんです。\n",
    "\n",
    "実行中に以下のセルを中断した場合、再び実行する前に、Chroma DataStore（コレクションを削除する以前のセルを再実行することにより）をクリアする必要があるかもしれないことに注意してください。それ以外の場合は、同じIDを持つ既存のドキュメントがあることに不満を言います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79e2fe-1f50-4ebf-9a93-34f3088f2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_DOCUMENTS = len(train)\n",
    "\n",
    "# 400,000全員を待たないであれば解除\n",
    "# number_of_documents = 20000\n",
    "\n",
    "for i in tqdm(range(0, NUMBER_OF_DOCUMENTS, 1000)):\n",
    "    documents = [description(item) for item in train[i: i+1000]]\n",
    "    vectors = model.encode(documents).astype(float).tolist()\n",
    "    metadatas = [{\"category\": item.category, \"price\": item.price} for item in train[i: i+1000]]\n",
    "    ids = [f\"doc_{j}\" for j in range(i, i+len(documents))]\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        documents=documents,\n",
    "        embeddings=vectors,\n",
    "        metadatas=metadatas\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f1b20-05ed-461d-b728-d7729125502a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
