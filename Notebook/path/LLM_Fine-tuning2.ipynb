{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6504fd44-1030-406c-973f-1ee8812fb291",
   "metadata": {},
   "source": [
    "# huggingface/trl SFTTrainerを使用したファインチューニング\n",
    "参考：https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?huggingface%2Ftrl%20SFTTrainer  \n",
    "※ ディスク領域が必要なので、このNBを実行する場合は、gitクローンする段階で/mnt/tmp（※ 一時領域）などに配置すると良い。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67090897-23ab-4961-9d9f-4ec0f61c4dbf",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a00cc-6f65-40b0-ae2d-e1e4ecc27f62",
   "metadata": {},
   "source": [
    "### 必要なパッケージをインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de79763-30a7-475e-b6e8-8c08df079bf0",
   "metadata": {},
   "source": [
    "#### サンドボックス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23c34f-ae60-4638-bafd-c038708c85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip cache purge\n",
    "# !pip install --upgrade XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321e59c-a60f-44b0-b6f7-61ccf877d9dd",
   "metadata": {},
   "source": [
    "#### 実際にインストールしたもの一覧"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9976ad88-4aef-4a40-a2ac-296f50b29098",
   "metadata": {},
   "source": [
    "- datasets : 自然言語処理のサンプルデータセットを簡単に取り扱えるライブラリ\n",
    "- transformers : Hugging Face の transformers ライブラリ\n",
    "- accelerate : Hugging Face の accelerate ライブラリは、TPU/GPU/CPUでの実行を同じコードで記述できる\n",
    "- trl : Hugging Face の trl (Transformer Reinforcement Learning) ライブラリ（SFT用）\n",
    "- peft : Hugging Face の peft (Parameter-Efficient Fine Tuning) ライブラリ（LoRA用）\n",
    "```bash\n",
    "!pip install --upgrade datasets\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade accelerate\n",
    "!pip install --upgrade trl\n",
    "!pip install --upgrade peft\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba7444-a8ac-4aa5-801b-a3745527351a",
   "metadata": {},
   "source": [
    "#### 以下のエラーが出るので、インストール後に一旦再起動\n",
    "```\n",
    "ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`\n",
    "```\n",
    "参考：https://github.com/huggingface/transformers/issues/24147"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128c437-1443-4c77-baff-f564373242ba",
   "metadata": {},
   "source": [
    "#### インストール結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7497174-fb78-442a-bb82-85525b72e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f345891-bb1f-432b-9030-323752eadbff",
   "metadata": {},
   "source": [
    "### インストールしたパッケージをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b27396-d9d6-4473-bd97-236b3331e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "\n",
    "import trl\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTTrainer\n",
    "\n",
    "import peft\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27e33b2-edee-4971-b957-e0de34fef2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.0 4.53.2 0.19.1\n"
     ]
    }
   ],
   "source": [
    "print(peft.__version__, transformers.__version__, trl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14e4cd-44cb-4b67-95ba-04253ed3ea1b",
   "metadata": {},
   "source": [
    "### 使用する変数を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f23ab9-1c58-4f53-996c-bf1eca9f8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "TEST_FILE_PATH = 'finetuning/data/test.jsonl'\n",
    "\n",
    "# MODEL\n",
    "MODEL_URI                        = 'meta-llama/Llama-3.2-1B-Instruct'\n",
    "MODEL_PATH      =           'finetuning/models/Llama-3.2-1B-Instruct'\n",
    "FTED_MODEL_PATH = 'finetuning/finetuned_models/Llama-3.2-1B-Instruct'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d9773-6ee5-4911-a714-8a0912fac4df",
   "metadata": {},
   "source": [
    "### モデル・トークナイザ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683ec57-ebcb-43f8-9839-205c9743dac8",
   "metadata": {},
   "source": [
    "#### NotebookからHugging Face Model Hubとやり取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f338b-cff2-43da-b8ec-00e07462c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6215c13-dafc-42dc-b122-b926145ee600",
   "metadata": {},
   "source": [
    "### モデルとトークナイザのダウンロードとセーブ\n",
    "初回のみなのでMarkdownにしておく。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5572e38-0798-44f1-9012-78aa5342be32",
   "metadata": {},
   "source": [
    "#### モデルとトークナイザのダウンロードと"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369ea8c-1acb-40c4-bee7-16213683ce7d",
   "metadata": {},
   "source": [
    "```python\n",
    "# model\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_URI,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    force_download=True\n",
    "  )\n",
    "model.save_pretrained(MODEL_PATH) \n",
    "\n",
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_URI)\n",
    "tokenizer.save_pretrained(MODEL_PATH) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6cb22-e7a1-4018-bf3d-5d0403c9ee32",
   "metadata": {},
   "source": [
    "#### モデルとトークナイザのセーブ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60496607-5696-4409-8507-1b837356b886",
   "metadata": {},
   "source": [
    "```python\n",
    "# model\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_URI,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    force_download=True\n",
    "  )\n",
    "model.save_pretrained(MODEL_PATH) \n",
    "\n",
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_URI)\n",
    "tokenizer.save_pretrained(MODEL_PATH)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47c01c-d6d9-4ee3-bebc-bb18c3d2c6b6",
   "metadata": {},
   "source": [
    "## ファインチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1affb2-c35f-4ad8-99a9-cbb7094700b5",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17850ffa-7413-4e8a-9936-dc2dd2c21265",
   "metadata": {},
   "source": [
    "#### 間違った方法\n",
    "- なお、以下で表示される結果の「Datasetのtrain」と「DatasetDictのtrain」は対応している訳ではない。\n",
    "- これは、`datasets.DatasetDict({'train': dataset})`のtrain → xxxxx に変えて実行すると解る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5f5e6b-547f-4fa8-9731-0c00811c425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['answer', 'question', 'context'],\n",
       "            num_rows: 11\n",
       "        })\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"json\", data_files=TEST_FILE_PATH)\n",
    "dataset = datasets.DatasetDict({'train': dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0eab54-9073-40a4-bbf2-e459d4079d69",
   "metadata": {},
   "source": [
    "#### 正しい方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53a8285-5771-4ec5-b0f3-f87d01298cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 11\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"json\", data_files=TEST_FILE_PATH, split=\"train\")\n",
    "dataset = datasets.DatasetDict({'train': dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d38632-b40e-4268-b5af-740f176bb026",
   "metadata": {},
   "source": [
    "### SFTTrainerの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e3b2c-d7de-4451-8f20-86841b8091f4",
   "metadata": {},
   "source": [
    "#### model, tokenizer\n",
    "モデルとトークナイザのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b285cc20-0485-4002-9e1c-871846aa769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247e91cb-ccd8-4a0c-99b9-4621c0284d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474fc80-e8ab-437a-9a8f-f635202b53f3",
   "metadata": {},
   "source": [
    "#### training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee02efd-9a89-4f71-90b4-75266111469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_args = TrainingArguments('test_trainer') # output_dirの指定になる。\n",
    "\n",
    "# 「OutOfMemoryError: CUDA out of memory.」への対応\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='test_trainer',\n",
    "    per_device_train_batch_size=2, # 8, 4, 2\n",
    "    num_train_epochs=1000,         # ← ここを増やす\n",
    "    gradient_checkpointing=True,\n",
    "    bf16=True, #fp16=True          # NVIDIA Ampere 以降の GPU なら bf16=True も検討\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554c19b-db38-4730-a892-9568a6b1ca47",
   "metadata": {},
   "source": [
    "#### formatting_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d10c83cb-6141-418e-8ce2-1074cb069c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['question'])):\n",
    "        text = f\"Please answer the question.\\n\\n### question\\n{example['question'][i]}\\n\\n### answer\\n{example['answer'][i]}<|eot_id|>\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c2904-70a8-4db6-bb8b-7897f641e067",
   "metadata": {},
   "source": [
    "#### data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "734e0488-cd55-440a-8eee-0599e0e67160",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template = '### answer\\n'\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e62da-26b4-4c15-8009-1a68832e2757",
   "metadata": {},
   "source": [
    "#### peft_config\n",
    "LoRAでないとLlama-3.2-1B-Instruct@A10はメモリ不足でトレーナーを動作させることができなかった（環境の問題？）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fefb2ac5-c217-42a9-ba22-894f1ae60502",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2d87b-5c2c-4809-a923-a07cf557d4c3",
   "metadata": {},
   "source": [
    "#### SFTTrainerの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c5efb9-480d-4f77-ac10-a5406c0f25b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cd5c88648b496bbd146f697c60fd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'], \n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97396b-9d17-4aca-a122-4103daafa301",
   "metadata": {},
   "source": [
    "#### SFTTrainer.train_datasetを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb17576-58dc-4005-b46e-e9ab7ccdac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['answer', 'question', 'context', 'text', 'input_ids'],\n",
      "    num_rows: 11\n",
      "})\n",
      "<|begin_of_text|>Please answer the question.\n",
      "\n",
      "### question\n",
      "ゼノリア星の気候はどうですか？\n",
      "\n",
      "### answer\n",
      "ゼノリア星は温暖な地域と氷結地帯が混在し、季節によって光の強度が大きく変化します。<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(trainer.train_dataset)\n",
    "# SFTTrainerの出力が途中で止まることがあるので4件目を確認\n",
    "print(tokenizer.decode(trainer.train_dataset[3]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184dd04-f91b-4672-bf86-10f39ae6fde0",
   "metadata": {},
   "source": [
    "### SFTTrainer.trainで実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5d36a-ff7d-4c15-9e3f-5b0337257f1a",
   "metadata": {},
   "source": [
    "#### OutOfMemoryError: CUDA out of memory. 対策\n",
    "要るか要らないか解らないので、取り敢えずMarkdownで。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd486c-cf77-43f7-ada0-4b397196b0f7",
   "metadata": {},
   "source": [
    "##### 設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c777b-96bd-4244-ae04-d1f73108f61d",
   "metadata": {},
   "source": [
    "```python\n",
    "#`use_cache=True`は勾配チェックポイントと互換性が無いので併用できない。\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66f6b9-07c7-4868-8b4e-752060a5107d",
   "metadata": {},
   "source": [
    "##### 確認1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4983325-72f9-443e-ae5e-ec4168915093",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.cuda.memory_summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99a1b9-4275-42a9-842e-d8499e199102",
   "metadata": {},
   "source": [
    "##### 確認2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff7a11-3661-48e5-a5dd-bed72bd67c4b",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.cuda.memory_allocated()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8644a-6401-470f-9983-df6aa6a917e6",
   "metadata": {},
   "source": [
    "#### 実際にSFTを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73acb5d9-27d1-4cda-ac35-1a66528af723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb286c3-0613-48bf-989d-ffc6a8d25bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6000/6000 08:44, Epoch 1000/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6000, training_loss=0.02937101301861306, metrics={'train_runtime': 524.8493, 'train_samples_per_second': 20.958, 'train_steps_per_second': 11.432, 'total_flos': 3828437761167360.0, 'train_loss': 0.02937101301861306})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f36ce-a95e-4381-9500-223484b99c0c",
   "metadata": {},
   "source": [
    "#### SFTされたモデルとトークナイザのセーブ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e930c9b1-ea4c-488f-bc55-ef0316f21352",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(FTED_MODEL_PATH) # ,device_map=\"auto\", torch_dtype=torch.float16)\n",
    "trainer.save_model(FTED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82fa6ee-a979-4676-a736-aae1b36e2da2",
   "metadata": {},
   "source": [
    "## SFTされたモデルで推論を実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4de53-c389-4ee3-9435-10c1406be5c9",
   "metadata": {},
   "source": [
    "### SFTされたモデルとトークナイザのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374a01b-b359-479f-8c06-d15f24c6be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.from_pretrained(FTED_MODEL_PATH)\n",
    "trainer.from_pretrained(FTED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c43f05c-1d36-4fb7-88c3-ab3d22adac22",
   "metadata": {},
   "source": [
    "### プロンプトをトークン化\n",
    "`pt`は、PyTorch テンソル（torch.Tensor）の意味"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa1ffca8-6e96-432b-8288-1b2c0507e386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 108270, 101335, 104612,  78519,  20230, 101987, 104004,  36668,\n",
      "          26854, 104091,  71869,  15682,  99849, 112130,  11571]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('ゼノリア星に住む主な種族は何ですか？', return_tensors='pt').to(model.device)\n",
    "print(inputs) # テンソルのディクショナリになっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebc2e1-5fcc-4436-b07c-4f408bc58f36",
   "metadata": {},
   "source": [
    "### 推論を実行\n",
    "- 推論時なので勾配計算しない`no_grad`プロックに入れて実行\n",
    "- `**inputs`として渡すと「ディクショナリのキー・値」が「キーワード引数・引数」に展開される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f1a8017-2d25-4ece-a25f-38990dad9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_disable()  # checkpointing をオフにする\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.05,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749c90b-0844-4226-a390-781cf974e71b",
   "metadata": {},
   "source": [
    "### 推論結果を表示\n",
    "推論結果をデトークン化して表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "914bda34-91a2-4d3a-bdcf-3a24fe3f04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ゼノリア星に住む主な種族は何ですか？\n",
      "ゼノリア星に住む主な種族はゼノス族です。ゼノス族はゼノリア星の最も重要なものです。ゼノス族はゼノリア星の最も重要なものです。ゼノス族はゼノリア星の最\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bf39d-4b2a-4cd9-ba8a-28a778b6f4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
