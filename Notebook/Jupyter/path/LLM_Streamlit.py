from openai import OpenAI
import streamlit as st

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Ollama-Chatbot",
    page_icon="ğŸ¤–",
    layout="wide",
)

# ã‚¿ã‚¤ãƒˆãƒ«ã®è¡¨ç¤º
st.title("Chat with OllamağŸ¤–")
st.caption("ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ãŸã„ã¨ãã¯ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã­ã€‚")

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
client = OpenAI(
    base_url='http://localhost:11434/v1/', # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ
    # base_url='http://***.***.***.***:11434/v1/', # åˆ¥ã®PCã‹ã‚‰æ¥ç¶šã™ã‚‹å ´åˆï¼ˆå®Ÿéš›ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å…¥åŠ›ã™ã‚‹ï¼‰
    api_key='dummy' # ãƒ€ãƒŸãƒ¼ã§OK
    )

# LLMãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®š
chat_model = "llama3"

# åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¨­å®š
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        # systemã«å½¹å‰²ã‚’ä»˜ä¸
        {"role": "system", "content": "You are an excellent AI Assistant. You must provide every answer in Japanese. ã‚ˆã‚ã—ãã­ï¼"},
        # assistantã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        {"role": "assistant", "content": f"ã“ã‚“ã«ã¡ã¯ã€‚ç§ã¯{chat_model}ã§ã™ã€‚ **ä½•ã§ã‚‚èã„ã¦ãã ã•ã„ã€‚** "}
    ]

# ä»¥å‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    # roleã«ã‚ˆã£ã¦ã‚¢ãƒã‚¿ãƒ¼ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
    if message["role"] == "system":
        st.chat_message(message["role"], avatar='ğŸ’»').write(message['content'])
    elif message["role"] == "assistant":
        st.chat_message(message["role"], avatar='ğŸ¤–').write(message["content"])
    elif message["role"] == "user":
        st.chat_message(message["role"], avatar='ğŸ‘¦').write(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›å¾Œã®å‡¦ç†
if prompt := st.chat_input("What is up?"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    with st.chat_message("user", avatar='ğŸ‘¦'):
        st.markdown(prompt)

    # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®è¿”ç­”ã‚’å–å¾—ï¼†è¡¨ç¤º
    with st.chat_message("assistant", avatar='ğŸ¤–'):
        # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®è¿”ç­”ã‚’å–å¾—
        stream = client.chat.completions.create(
            model=chat_model,
            messages=st.session_state.messages,
            stream=True,
        )
        # è¿”ä¿¡ã‚’streamingå‡ºåŠ›
        response = st.write_stream(stream)

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿”ç­”ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "assistant", "content": response})
