{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a588b2f-aa6c-44dc-9ef4-fbd6061051c6",
   "metadata": {},
   "source": [
    "# LlamaIndexでGraph RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a79c5e-15d5-465c-b9f5-6283775d97de",
   "metadata": {},
   "source": [
    "## 目次\n",
    "- [概要](#概要)\n",
    "- [参考](#参考)\n",
    "- [チェック](#チェック)\n",
    "- [チュートリアル](#チュートリアル)\n",
    "  - [準備](#準備)\n",
    "    - [使用する変数](#使用する変数)\n",
    "    - [インストレーション](#インストレーション)\n",
    "    - [ライブラリ読み込み](#ライブラリ読み込み)\n",
    "  - [OpenAI](#OpenAI)\n",
    "    - [追加のインストレーション](#追加のインストレーション)\n",
    "    - [追加のライブラリ読み込み](#追加のライブラリ読み込み)\n",
    "    - [API Keyの確認](#API_Keyの確認)\n",
    "  - [KnowledgeGraphIndex](#KnowledgeGraphIndex)\n",
    "    - [LLMの設定](#LLMの設定)\n",
    "    - [インデックス作成](#インデックス作成)\n",
    "    - [RAGのRetrieval部](#RAGのRetrieval部)\n",
    "  - [PropertyGraphIndex](#PropertyGraphIndex)\n",
    "    - [準備](#準備)\n",
    "    - [インデックス作成](#インデックス作成)\n",
    "    - [RAGのRetrieval部](#RAGのRetrieval部)\n",
    "    - [永続化して実行](#永続化して実行)\n",
    "    - [StoringでChromaDBを使用](#StoringでChromaDBを使用)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d019bec2-7b0b-41bb-95c3-f735a91fe213",
   "metadata": {},
   "source": [
    "## 概要\n",
    "- LlamaIndex（公式）をトレースして基本的な利用方法を確認する。\n",
    "- 破壊的に変更が発生するまで使えるでしょう。\n",
    "- 破壊的に変更が発生後は、公式サイトの当該バージョンの情報（≒一次情報）をあたって。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab5958-4219-4f63-a243-b5590119a676",
   "metadata": {},
   "source": [
    "## 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58e6cb-cad7-4f43-af45-5d04219952c7",
   "metadata": {},
   "source": [
    "LLMのRAG - .NET 開発基盤部会 Wiki  \n",
    "https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?LLM%E3%81%AERAG\n",
    "- 知識情報の分割\n",
    "- 知識情報の埋め込み\n",
    "- 質問の入力（Query Input）\n",
    "- 質問の埋め込み（Query Embedding）\n",
    "- 情報の検索（Information Retrieval）\n",
    "- 情報の生成（Information Generation）\n",
    "- 回答の提供（Answer Delivery）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915e0c1-5cba-4407-bae8-6481179a3f69",
   "metadata": {},
   "source": [
    "LlamaIndex - .NET 開発基盤部会 Wiki  \n",
    "https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?LlamaIndex\n",
    "- Loading\n",
    "- Indexing\n",
    "- Storing\n",
    "- Querying\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0387006-4f25-4817-a3b1-d05e56305c57",
   "metadata": {},
   "source": [
    "## チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729cb641-a9ac-4b7c-ac1f-9b69d031bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c57768c-0bc1-4cc8-95a2-9cd89443fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3c041-3b69-4045-9fea-dc9422515527",
   "metadata": {},
   "source": [
    "## チュートリアル\n",
    "OpenAIが前提、Ollamaは別途。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a092e-a3a8-44b2-86e4-73576b7a5c10",
   "metadata": {},
   "source": [
    "### 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550afdc8-f737-4426-83a6-10be1d75fece",
   "metadata": {},
   "source": [
    "#### 使用する変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63013ab-97bf-49c9-ad27-b6d28deadac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./llamaindex/data/paul_graham_essay\"\n",
    "PERSIST_DIR = \"./llamaindex/storage/paul_graham_essay_pgi\"\n",
    "CHROMA_DIR = \"./llamaindex/chroma_db/paul_graham_essay_pgi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c5bd2-e782-4418-9e29-21d80e344d7e",
   "metadata": {},
   "source": [
    "#### インストレーション"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae9b29b-de06-4195-85bb-23f6c89d0b76",
   "metadata": {},
   "source": [
    "##### 新規インストール\n",
    "Graph可視化用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a6ed8-a1db-4dd7-a800-ed99b1f39223",
   "metadata": {},
   "source": [
    "```bash\n",
    "!pip install pyvis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110f189-d281-4a84-8840-6c1e2e646a48",
   "metadata": {},
   "source": [
    "#### ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e35c6b69-695b-49db-8871-70acc0e8849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Settings, StorageContext\n",
    "from llama_index.core.graph_stores import SimpleGraphStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d889f94-d4b9-43e3-8713-c3e3e1c9abf7",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba669365-3663-47d2-906b-3839f85b3bc1",
   "metadata": {},
   "source": [
    "#### 追加のインストレーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "befedc74-e9e4-4160-a5bf-d21b2da868c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要（OpenAIは依存関係パッケージらしい）\n",
    "# !pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3bf94-916f-4e1a-906d-67e58c68f67d",
   "metadata": {},
   "source": [
    "#### 追加のライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e6d089-334e-49f8-8c97-a61f2399c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d0f81-1a72-468b-8684-3446cd1fc02c",
   "metadata": {},
   "source": [
    "#### API_Keyの確認\n",
    "準備は、OpenAIにログインしてAPIからKeyを取得、カード登録してチャージするだけ。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c6053-20bb-404e-8d77-2c9019af2065",
   "metadata": {},
   "source": [
    "```Python\n",
    "import os\n",
    "print(os.environ['OPENAI_API_KEY'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9f9bc-43a0-4563-a1fa-f52c0ad109fb",
   "metadata": {},
   "source": [
    "### KnowledgeGraphIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d309b0-7206-422b-a264-95c288df1765",
   "metadata": {},
   "source": [
    "#### LLMの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed8b157-dc07-42bf-821e-91f267ed0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LLM\n",
    "# NOTE: at the time of demo, text-davinci-002 did not have rate-limit errors\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143f648-d3c5-40e8-b748-a272fafcf1ef",
   "metadata": {},
   "source": [
    "#### インデックス作成\n",
    "Graph検索のインデックス。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa86da-f8ad-4192-b602-9ed2a1a6ff16",
   "metadata": {},
   "source": [
    "##### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f1625f-1c79-45ab-82b3-abf22bd89d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(DATA_DIR).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956547c7-0c3f-42e4-a691-544155865ebd",
   "metadata": {},
   "source": [
    "##### Indexing & Storing\n",
    "- 以下では、KnowledgeGraphIndexを使用している。\n",
    "- SimpleGraphStoreはメモリなのか？ディスクなのか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16070c37-5f39-4fa9-b910-c4aac63b18e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seigi/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 22.76it/s]\n",
      "Processing nodes: 100%|██████████████████████████████████████████████████████████████████████████████| 64/64 [00:45<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import KnowledgeGraphIndex\n",
    "\n",
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "# NOTE: can take a while!\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    max_triplets_per_chunk=2,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eab513-0888-47f3-8c83-6fb31b6f5aa8",
   "metadata": {},
   "source": [
    "#### RAGのRetrieval部"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39165cc2-50f1-4eb2-ae9d-8d38f4ca1628",
   "metadata": {},
   "source": [
    "##### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50d344b-2dad-4208-b1cf-3ee59d594f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaf was a software that made use of a scripting language and was inspired by Emacs. It taught useful things and had smart people working on it. However, it eventually got crushed by Moore's law.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=False, response_mode=\"tree_summarize\"\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"Tell me more about Interleaf\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db857f30-a3e7-49d9-ba20-1c31c8dfc6a1",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94353f96-570a-46b8-b5ec-f6bdc9028c2f",
   "metadata": {},
   "source": [
    "###### nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8fd750-1115-49ef-8e3a-ee04110a820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score  1000.0\n",
      "id_ 572a0574-26ec-4668-9b37-9136375cc8b5\n",
      "text The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "['Interleaf', 'Made', 'Software']\n",
      "['Software', 'Mention in', 'Footnotes']\n",
      "['Software', 'Was', 'One of the best general-purpose site builders']\n",
      "['Software', 'Was', \"Raison d'etre\"]\n",
      "['Interleaf', 'Added', 'Scripting language']\n",
      "['Interleaf', 'Added', 'Scripting language']\n",
      "['Interleaf', 'Inspired by', 'Emacs']\n",
      "['Interleaf', 'Taught', 'Useful things']\n",
      "['Interleaf', 'Got crushed by', \"Moore's law\"]\n",
      "['Interleaf', 'Had', 'Smart people']\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(\"score \", node.score)\n",
    "    print(\"id_\", node.id_)\n",
    "    #print(\"file_name\", node.metadata[\"file_name\"])\n",
    "    print(\"text\", node.text)\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebc430-b99a-47ad-b992-850210bc5e89",
   "metadata": {},
   "source": [
    "###### networkx_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f339ad-0211-48a0-8db5-893772c1e27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./llamaindex/KnowledgeGraphIndex.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"./llamaindex/KnowledgeGraphIndex.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9e88b9f880>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "g = index.get_networkx_graph()\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "net.show(\"./llamaindex/KnowledgeGraphIndex.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd4e17a-80df-4e42-ba11-3af91a3cb856",
   "metadata": {},
   "source": [
    "### PropertyGraphIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78ea127-2b09-47bd-a98a-d4b944842f7c",
   "metadata": {},
   "source": [
    "#### 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a12bf-dc75-4ccb-a32c-00a8425bfbf2",
   "metadata": {},
   "source": [
    "##### おまじない\n",
    "イベントループのネストを許可？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0c27da-68d0-4773-8320-9fbe1bc66ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03e38d-33b7-4925-af3d-531f6a25a384",
   "metadata": {},
   "source": [
    "##### モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2a9bae-7bbe-4c1b-a3fd-fb5a42277712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4572853a-9b88-4a54-96f8-4a151e8a89a3",
   "metadata": {},
   "source": [
    "#### インデックス作成\n",
    "Graph検索のインデックス。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4adb66-59a9-4c43-a567-3fd0c691cf60",
   "metadata": {},
   "source": [
    "##### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd1316d-f736-4613-b5ae-fb661bc9de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(DATA_DIR).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf144bd9-c9ca-49bf-89a5-2de9c2da9c82",
   "metadata": {},
   "source": [
    "##### Indexing & Storing\n",
    "- 以下では、PropertyGraphIndexを使用している。\n",
    "- Embedding用のモデルを別で作る必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3e7274-c334-443d-926b-f04a67274da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.11it/s]\n",
      "Extracting paths from text: 100%|████████████████████████████████████████████████████████████████████| 64/64 [00:23<00:00,  2.74it/s]\n",
      "Extracting implicit paths: 100%|██████████████████████████████████████████████████████████████████| 64/64 [00:00<00:00, 26319.78it/s]\n",
      "Generating embeddings: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Generating embeddings: 100%|█████████████████████████████████████████████████████████████████████████| 14/14 [00:03<00:00,  4.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fdf3c-5260-4834-86d6-ab793f706723",
   "metadata": {},
   "source": [
    "#### RAGのRetrieval部"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c995c-194f-43bd-a44e-f64fa0305502",
   "metadata": {},
   "source": [
    "##### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2208493c-ca40-429c-808f-464e84802a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaf had smart people and built impressive technology but got crushed by Moore's Law. Viaweb started because the founder needed money, had negative net worth, and became a model company that worked via the web. They needed founders, called themselves a company, and made consulting services.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=True,\n",
    ")\n",
    "response = query_engine.query(\"What happened at Interleaf and Viaweb?\")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556cb4b-d761-4d00-a657-b71a1caa4856",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc043b9d-b79d-44f6-b429-8241418af750",
   "metadata": {},
   "source": [
    "###### retriever\n",
    "ソーステキストを含めないで、retrieverしてnodesを表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3752d73-73ba-44ca-b3f6-5cb36640ac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viaweb -> Needed -> Something\n",
      "Interleaf -> Was -> On the way down\n",
      "Viaweb -> Owed -> Government\n",
      "Viaweb -> Had -> Negative net worth\n",
      "Viaweb -> Became -> Model\n",
      "Viaweb -> Worked via -> Web\n",
      "Postscript file -> Created by -> Viaweb\n",
      "Interleaf -> Wanted -> Lisp hacker\n",
      "Viaweb -> Needed -> Ourselves\n",
      "Viaweb -> Called -> Company\n",
      "Viaweb -> Gave -> 10%\n",
      "Interleaf -> Added -> Dialect of lisp\n",
      "Interleaf -> Built -> Impressive technology\n",
      "Interleaf -> Was on -> Way down\n",
      "Interleaf -> Added -> Scripting language\n",
      "Viaweb -> Started -> Because i needed the money\n",
      "Interleaf -> Got crushed by -> Moore's law\n",
      "Viaweb -> Called -> New company\n",
      "Dan giffin -> Worked for -> Viaweb\n",
      "Viaweb -> Seemed -> Lame\n",
      "Viaweb -> Needed -> Founders\n",
      "Interleaf -> Had -> Smart people\n",
      "Interleaf -> Made -> Software\n",
      "Interleaf -> Made -> Scripting language\n",
      "Code editor -> Was in -> Viaweb\n",
      "Viaweb -> Made -> Consulting\n",
      "Interleaf -> Had -> Added\n",
      "Viaweb logo -> Had been -> White v on red circle\n",
      "Viaweb stock -> Was -> Valuable\n",
      "I -> Learned -> Useful things at interleaf\n"
     ]
    }
   ],
   "source": [
    "retriever = index.as_retriever(\n",
    "    include_text=False,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"What happened at Interleaf and Viaweb?\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73a5f7-6628-4732-8417-f9a07b996ca7",
   "metadata": {},
   "source": [
    "###### networkx_graph\n",
    "PropertyGraphIndexには、networkx_graphプロパティがないらしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39866e92-70dc-4e60-8b4f-e3f68e70fbdb",
   "metadata": {},
   "source": [
    "###### query\n",
    "ソーステキストを含めた、queryで使用したnodesを表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb5e1de-6879-429d-8453-d8cffb42f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Viaweb -> Needed -> Something\n",
      "Interleaf -> Was -> On the way down\n",
      "Viaweb -> Owed -> Government\n",
      "Viaweb -> Had -> Negative net worth\n",
      "Viaweb -> Became -> Model\n",
      "Viaweb -> Worked via -> Web\n",
      "Interleaf -> Wanted -> Lisp hacker\n",
      "Viaweb -> Needed -> Ourselves\n",
      "Viaweb -> Called -> Company\n",
      "Viaweb -> Gave -> 10%\n",
      "Interleaf -> Added -> Dialect of lisp\n",
      "Interleaf -> Built -> Impressive technology\n",
      "Interleaf -> Was on -> Way down\n",
      "Interleaf -> Added -> Scripting language\n",
      "Viaweb -> Started -> Because i needed the money\n",
      "Interleaf -> Got crushed by -> Moore's law\n",
      "Viaweb -> Called -> New company\n",
      "Viaweb -> Seemed -> Lame\n",
      "Viaweb -> Needed -> Founders\n",
      "Interleaf -> Had -> Smart people\n",
      "Interleaf -> Made -> Software\n",
      "Interleaf -> Made -> Scripting language\n",
      "Code editor -> Was in -> Viaweb\n",
      "Viaweb -> Made -> Consulting\n",
      "Interleaf -> Had -> Added\n",
      "\n",
      "[5] Interleaf was one of many companies that had smart people and built impressive technology, and yet got crushed by Moore's Law. In the 1990s the exponential growth in the power of commodity (i.e. Intel) processors rolled up high-end, special-purpose hardware and software companies like a bulldozer.\n",
      "\n",
      "[6] The signature style seekers at RISD weren't specifically mercenary. In the art world, money and coolness are tightly coupled. Anything expensive comes to be seen as cool, and anything seen as cool will soon become equally expensive.\n",
      "\n",
      "[7] Technically the apartment wasn't rent-controlled but rent-stabilized, but this is a refinement only New Yorkers would know or care about. The point is that it was really cheap, less than half market price.\n",
      "\n",
      "[8] Most software you can launch as soon as it's done. But when the software is an online store builder and you're hosting the stores, if you don't have any users yet, that fact will be painfully obvious. So before we could launch publicly we had to launch privately, in the sense of recruiting an initial set of users and making sure they had decent-looking stores.\n",
      "\n",
      "[9] We'd had a code editor in Viaweb for users to define their own page styles. They didn't know it, but they were editing Lisp expressions underneath. But this wasn't an app editor, because the code ran when the merchants' sites were generated, not when shoppers visited them.\n",
      "\n",
      "[10] This was the first instance of what is now a familiar experience, and so was what happened next, when I read the comments and found they were full of angry people. How could I claim that Lisp was better than other languages? Weren't they all Turing complete? People who see the responses to essays I write sometimes tell me how sorry they feel for me, but I'm not exaggerating when I reply that it has always been like this, since the very beginning. It comes with the territory. An essay must tell readers things they don't already know, and some people dislike being told such things.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Postscript file -> Created by -> Viaweb\n",
      "\n",
      "The following spring, lightning struck. I was invited to give a talk at a Lisp conference, so I gave one about how we'd used Lisp at Viaweb. Afterward I put a postscript file of this talk online, on paulgraham.com, which I'd created years before using Viaweb but had never used for anything. In one day it got 30,000 page views. What on earth had happened? The referring urls showed that someone had posted it on Slashdot. [10]\n",
      "\n",
      "Wow, I thought, there's an audience. If I write something and put it on the web, anyone can read it. That may seem obvious now, but it was surprising then. In the print era there was a narrow channel to readers, guarded by fierce monsters known as editors. The only way to get an audience for anything you wrote was to get it published as a book, or in a newspaper or magazine. Now anyone could publish anything.\n",
      "\n",
      "This had been possible in principle since 1993, but not many people had realized it yet. I had been intimately involved with building the infrastructure of the web for most of that time, and a writer as well, and it had taken me 8 years to realize it. Even then it took me several years to understand the implications. It meant there would be a whole new generation of essays. [11]\n",
      "\n",
      "In the print era, the channel for publishing essays had been vanishingly small. Except for a few officially anointed thinkers who went to the right parties in New York, the only people allowed to publish essays were specialists writing about their specialties. There were so many essays that had never been written, because there had been no way to publish them. Now they could be, and I was going to write them. [12]\n",
      "\n",
      "I've worked on several different things, but to the extent there was a turning point where I figured out what to work on, it was when I started publishing essays online. From then on I knew that whatever else I did, I'd always write essays too.\n",
      "\n",
      "I knew that online essays would be a marginal medium at first.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Dan giffin -> Worked for -> Viaweb\n",
      "\n",
      "Robert was now a postdoc at MIT, and though he'd made a lot of money the last time I'd lured him into working on one of my schemes, it had also been a huge time sink. So while he agreed that it sounded like a plausible idea, he firmly refused to work on it.\n",
      "\n",
      "Hmph. Well, I'd do it myself then. I recruited Dan Giffin, who had worked for Viaweb, and two undergrads who wanted summer jobs, and we got to work trying to build what it's now clear is about twenty companies and several open source projects worth of software. The language for defining applications would of course be a dialect of Lisp. But I wasn't so naive as to assume I could spring an overt Lisp on a general audience; we'd hide the parentheses, like Dylan did.\n",
      "\n",
      "By then there was a name for the kind of company Viaweb was, an \"application service provider,\" or ASP. This name didn't last long before it was replaced by \"software as a service,\" but it was current for long enough that I named this new company after it: it was going to be called Aspra.\n",
      "\n",
      "I started working on the application builder, Dan worked on network infrastructure, and the two undergrads worked on the first two services (images and phone calls). But about halfway through the summer I realized I really didn't want to run a company — especially not a big one, which it was looking like this would have to be. I'd only started Viaweb because I needed the money. Now that I didn't need money anymore, why was I doing this? If this vision had to be realized as a company, then screw the vision. I'd build a subset that could be done as an open source project.\n",
      "\n",
      "Much to my surprise, the time I spent working on this stuff was not wasted after all. After we started Y Combinator, I would often encounter startups working on parts of this new architecture, and it was very useful to have spent so much time thinking about it and even trying to write some of it.\n",
      "\n",
      "The subset I would build as an open source project was the new Lisp, whose parentheses I now wouldn't even have to hide.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Viaweb logo -> Had been -> White v on red circle\n",
      "\n",
      "In 2005 all the VCs used staid colors like maroon, navy blue, and forest green, because they were trying to appeal to LPs, not founders. The YC logo itself is an inside joke: the Viaweb logo had been a white V on a red circle, so I made the YC logo a white Y on an orange square.\n",
      "\n",
      "[14] YC did become a fund for a couple years starting in 2009, because it was getting so big I could no longer afford to fund it personally. But after Heroku got bought we had enough money to go back to being self-funded.\n",
      "\n",
      "[15] I've never liked the term \"deal flow,\" because it implies that the number of new startups at any given time is fixed. This is not only false, but it's the purpose of YC to falsify it, by causing startups to be founded that would not otherwise have existed.\n",
      "\n",
      "[16] She reports that they were all different shapes and sizes, because there was a run on air conditioners and she had to get whatever she could, but that they were all heavier than she could carry now.\n",
      "\n",
      "[17] Another problem with HN was a bizarre edge case that occurs when you both write essays and run a forum. When you run a forum, you're assumed to see if not every conversation, at least every conversation involving you. And when you write essays, people post highly imaginative misinterpretations of them on forums. Individually these two phenomena are tedious but bearable, but the combination is disastrous. You actually have to respond to the misinterpretations, because the assumption that you're present in the conversation means that not responding to any sufficiently upvoted misinterpretation reads as a tacit admission that it's correct. But that in turn encourages more; anyone who wants to pick a fight with you senses that now is their chance.\n",
      "\n",
      "[18] The worst thing about leaving YC was not working with Jessica anymore. We'd been working on YC almost the whole time we'd known each other, and we'd neither tried nor wanted to separate it from our personal lives, so leaving was like pulling up a deeply rooted tree.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Viaweb stock -> Was -> Valuable\n",
      "\n",
      "Another thing I didn't get at the time is that growth rate is the ultimate test of a startup. Our growth rate was fine. We had about 70 stores at the end of 1996 and about 500 at the end of 1997. I mistakenly thought the thing that mattered was the absolute number of users. And that is the thing that matters in the sense that that's how much money you're making, and if you're not making enough, you might go out of business. But in the long term the growth rate takes care of the absolute number. If we'd been a startup I was advising at Y Combinator, I would have said: Stop being so stressed out, because you're doing fine. You're growing 7x a year. Just don't hire too many more people and you'll soon be profitable, and then you'll control your own destiny.\n",
      "\n",
      "Alas I hired lots more people, partly because our investors wanted me to, and partly because that's what startups did during the Internet Bubble. A company with just a handful of employees would have seemed amateurish. So we didn't reach breakeven until about when Yahoo bought us in the summer of 1998. Which in turn meant we were at the mercy of investors for the entire life of the company. And since both we and our investors were noobs at startups, the result was a mess even by startup standards.\n",
      "\n",
      "It was a huge relief when Yahoo bought us. In principle our Viaweb stock was valuable. It was a share in a business that was profitable and growing rapidly. But it didn't feel very valuable to me; I had no idea how to value a business, but I was all too keenly aware of the near-death experiences we seemed to have every few months. Nor had I changed my grad student lifestyle significantly since we started. So when Yahoo bought us it felt like going from rags to riches. Since we were going to California, I bought a car, a yellow 1998 VW GTI. I remember thinking that its leather seats alone were by far the most luxurious thing I owned.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Viaweb -> Needed -> Something\n",
      "Viaweb -> Owed -> Government\n",
      "Viaweb -> Had -> Negative net worth\n",
      "Viaweb -> Became -> Model\n",
      "Viaweb -> Worked via -> Web\n",
      "Viaweb -> Needed -> Ourselves\n",
      "Viaweb -> Called -> Company\n",
      "Viaweb -> Gave -> 10%\n",
      "Viaweb -> Started -> Because i needed the money\n",
      "Viaweb -> Called -> New company\n",
      "Viaweb -> Seemed -> Lame\n",
      "Viaweb -> Needed -> Founders\n",
      "Code editor -> Was in -> Viaweb\n",
      "Viaweb -> Made -> Consulting\n",
      "\n",
      "[5] Interleaf was one of many companies that had smart people and built impressive technology, and yet got crushed by Moore's Law. In the 1990s the exponential growth in the power of commodity (i.e. Intel) processors rolled up high-end, special-purpose hardware and software companies like a bulldozer.\n",
      "\n",
      "[6] The signature style seekers at RISD weren't specifically mercenary. In the art world, money and coolness are tightly coupled. Anything expensive comes to be seen as cool, and anything seen as cool will soon become equally expensive.\n",
      "\n",
      "[7] Technically the apartment wasn't rent-controlled but rent-stabilized, but this is a refinement only New Yorkers would know or care about. The point is that it was really cheap, less than half market price.\n",
      "\n",
      "[8] Most software you can launch as soon as it's done. But when the software is an online store builder and you're hosting the stores, if you don't have any users yet, that fact will be painfully obvious. So before we could launch publicly we had to launch privately, in the sense of recruiting an initial set of users and making sure they had decent-looking stores.\n",
      "\n",
      "[9] We'd had a code editor in Viaweb for users to define their own page styles. They didn't know it, but they were editing Lisp expressions underneath. But this wasn't an app editor, because the code ran when the merchants' sites were generated, not when shoppers visited them.\n",
      "\n",
      "[10] This was the first instance of what is now a familiar experience, and so was what happened next, when I read the comments and found they were full of angry people. How could I claim that Lisp was better than other languages? Weren't they all Turing complete? People who see the responses to essays I write sometimes tell me how sorry they feel for me, but I'm not exaggerating when I reply that it has always been like this, since the very beginning. It comes with the territory. An essay must tell readers things they don't already know, and some people dislike being told such things.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "I -> Learned -> Useful things at interleaf\n",
      "\n",
      "Notes\n",
      "\n",
      "[1] My experience skipped a step in the evolution of computers: time-sharing machines with interactive OSes. I went straight from batch processing to microcomputers, which made microcomputers seem all the more exciting.\n",
      "\n",
      "[2] Italian words for abstract concepts can nearly always be predicted from their English cognates (except for occasional traps like polluzione). It's the everyday words that differ. So if you string together a lot of abstract concepts with a few simple verbs, you can make a little Italian go a long way.\n",
      "\n",
      "[3] I lived at Piazza San Felice 4, so my walk to the Accademia went straight down the spine of old Florence: past the Pitti, across the bridge, past Orsanmichele, between the Duomo and the Baptistery, and then up Via Ricasoli to Piazza San Marco. I saw Florence at street level in every possible condition, from empty dark winter evenings to sweltering summer days when the streets were packed with tourists.\n",
      "\n",
      "[4] You can of course paint people like still lives if you want to, and they're willing. That sort of portrait is arguably the apex of still life painting, though the long sitting does tend to produce pained expressions in the sitters.\n",
      "\n",
      "[5] Interleaf was one of many companies that had smart people and built impressive technology, and yet got crushed by Moore's Law. In the 1990s the exponential growth in the power of commodity (i.e. Intel) processors rolled up high-end, special-purpose hardware and software companies like a bulldozer.\n",
      "\n",
      "[6] The signature style seekers at RISD weren't specifically mercenary. In the art world, money and coolness are tightly coupled. Anything expensive comes to be seen as cool, and anything seen as cool will soon become equally expensive.\n",
      "\n",
      "[7] Technically the apartment wasn't rent-controlled but rent-stabilized, but this is a refinement only New Yorkers would know or care about. The point is that it was really cheap, less than half market price.\n",
      "\n",
      "[8] Most software you can launch as soon as it's done.\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5a82e-dd2f-4a46-8621-1215132a2091",
   "metadata": {},
   "source": [
    "#### 永続化して実行\n",
    "永続化はオプショナルでVectorStoreIndexと同じだがKnowledgeGraphIndexと作法が違う？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b8ac3a3-3dec-488d-9803-774bd72b4a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author skipped a step in the evolution of computers, going straight from batch processing to microcomputers, which made microcomputers seem all the more exciting.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# check if storage already exists\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(DATA_DIR).load_data()\n",
    "    index = PropertyGraphIndex.from_documents(\n",
    "        documents,\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc64edb-b541-4026-812e-cb03043db3ac",
   "metadata": {},
   "source": [
    "#### StoringでChromaDBを使用\n",
    "以下のコードは現状、動かない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba841d6a-1f97-49cb-beeb-9517e4ed68ab",
   "metadata": {},
   "source": [
    "##### 追加のインストレーション"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877516f-130d-4bdf-9db4-e1ff7e638daa",
   "metadata": {},
   "source": [
    "```bash\n",
    "!pip install chromadb\n",
    "!pip install llama-index-vector-stores-chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b3690-15cd-4a4c-870f-ec888c7c77ac",
   "metadata": {},
   "source": [
    "##### 追加のライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6148bdf-c1eb-49fd-9e70-9f2bcbffc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.graph_stores import SimplePropertyGraphStore\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac3bc3-59be-4813-a43b-70c4ab8c3c66",
   "metadata": {},
   "source": [
    "##### パーツ毎に分解して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbdae2-fe03-4b80-9544-780619fc41a5",
   "metadata": {},
   "source": [
    "###### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66f0c0fd-bf05-4d48-8e93-50bce4ffa407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some documents\n",
    "documents = SimpleDirectoryReader(DATA_DIR).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31cc10-ace3-498f-b673-50837af5f251",
   "metadata": {},
   "source": [
    "###### Settings\n",
    "Vector Store の Storage Context に Chroma DB を使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c55dbf-6403-43d6-b9d4-aed73455524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize client, setting path to save data\n",
    "db = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "\n",
    "# create collection\n",
    "collection = db.get_or_create_collection(\"property_graph_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703bfcd9-7423-4d3e-bb98-7d932282b70d",
   "metadata": {},
   "source": [
    "###### Indexing & Storing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bd3b3-95e6-40cc-af53-e8a1165858fb",
   "metadata": {},
   "source": [
    "```Python\n",
    "# 初回\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    "    graph_store=SimplePropertyGraphStore(),\n",
    "    vector_store=ChromaVectorStore(collection=collection),\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "index.storage_context.persist(PERSIST_DIR)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05833f83-68be-40a7-8273-7c5bd8c1ead8",
   "metadata": {},
   "source": [
    "```Python\n",
    "\n",
    "# 2回目以降\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    llm=llm,\n",
    "    graph_store=SimplePropertyGraphStore.from_persist_dir(PERSIST_DIR),\n",
    "    vector_store=ChromaVectorStore(chroma_collection=collection),\n",
    "    show_progress=True,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230a4f2-7b3c-4854-b67b-b306c22ba95b",
   "metadata": {},
   "source": [
    "###### Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a618d-19d8-4647-80b5-a9db40251887",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
