{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a588b2f-aa6c-44dc-9ef4-fbd6061051c6",
   "metadata": {},
   "source": [
    "# LlamaIndexでRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a79c5e-15d5-465c-b9f5-6283775d97de",
   "metadata": {},
   "source": [
    "## 目次\n",
    "- [概要](#概要)\n",
    "- [参考](#参考)\n",
    "- [チェック](#チェック)\n",
    "- [エージェントにRAGを追加する](#エージェントにRAGを追加する)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d019bec2-7b0b-41bb-95c3-f735a91fe213",
   "metadata": {},
   "source": [
    "## 概要\n",
    "- LlamaIndex（公式）をトレースして基本的な利用方法を確認する。\n",
    "- 破壊的に変更が発生するまで使えるでしょう。\n",
    "- 破壊的に変更が発生後は、公式サイトの当該バージョンの情報（≒一次情報）をあたって。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab5958-4219-4f63-a243-b5590119a676",
   "metadata": {},
   "source": [
    "## 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58e6cb-cad7-4f43-af45-5d04219952c7",
   "metadata": {},
   "source": [
    "LLMのRAG - .NET 開発基盤部会 Wiki  \n",
    "https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?LLM%E3%81%AERAG\n",
    "- 知識情報の分割\n",
    "- 知識情報の埋め込み\n",
    "- 質問の入力（Query Input）\n",
    "- 質問の埋め込み（Query Embedding）\n",
    "- 情報の検索（Information Retrieval）\n",
    "- 情報の生成（Information Generation）\n",
    "- 回答の提供（Answer Delivery）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915e0c1-5cba-4407-bae8-6481179a3f69",
   "metadata": {},
   "source": [
    "LlamaIndex - .NET 開発基盤部会 Wiki  \n",
    "https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?LlamaIndex\n",
    "- Loading\n",
    "- Indexing\n",
    "- Storing\n",
    "- Querying\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0387006-4f25-4817-a3b1-d05e56305c57",
   "metadata": {},
   "source": [
    "## チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cb641-a9ac-4b7c-ac1f-9b69d031bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57768c-0bc1-4cc8-95a2-9cd89443fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2edb3-9da5-4da5-8394-09d722c39632",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61aa29-3f93-4d47-8a85-d9d125d893ad",
   "metadata": {},
   "source": [
    "### ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc4e79-53bb-4d2c-97df-3e80238f9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f674f-765a-4ed1-94cb-c80dd9d15502",
   "metadata": {},
   "source": [
    "## エージェント"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413baeb-c61c-4b16-b4b1-675bff5cb461",
   "metadata": {},
   "source": [
    "### 最も簡単なエージェント"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9198c-36bf-46ea-9b69-144cea522cd8",
   "metadata": {},
   "source": [
    "#### ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0308de6-d0c4-4eba-ad9c-49cca3323202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e4da5-9563-48be-8366-b8e4a9b93154",
   "metadata": {},
   "source": [
    "#### LLMの定義\n",
    "エージェントでは揺らぐと困るので、temperature=0 に設定している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2b1f1-dd73-430b-aaba-c28dc57ab2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama\n",
    "llm = Ollama(model=\"Llama3\", temperature=0, request_timeout=360.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fc77d-0e5a-449e-bfea-5589190b09b1",
   "metadata": {},
   "source": [
    "#### ファンクションツールのエージェント"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bec70-bb4f-4d47-9a4b-1e84f548c631",
   "metadata": {},
   "source": [
    "##### ファンクションツールの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bbabd-8377-416f-a490-e12299475d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24e83f-aeb9-47fc-8bd2-e92f6031e6d3",
   "metadata": {},
   "source": [
    "##### エージェントの構成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855faf55-788e-4e9d-8b93-fec61ccff733",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b78160-0c8d-487d-80c2-57ecfebc0514",
   "metadata": {},
   "source": [
    "##### エージェントの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa0a77-906d-4a8d-942d-23b195c2c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"What is 20 + (2 * 4) ? Use a tool to calculate every step.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae4645-2329-4021-b246-8829c66c9704",
   "metadata": {},
   "source": [
    "### エージェントにRAGを追加する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843178f-8682-4226-89b0-066767f955fd",
   "metadata": {},
   "source": [
    "#### 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550afdc8-f737-4426-83a6-10be1d75fece",
   "metadata": {},
   "source": [
    "##### 使用する変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63013ab-97bf-49c9-ad27-b6d28deadac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./llamaindex/data/2023_canadian_budget\"\n",
    "PERSIST_DIR = \"./llamaindex/storage/2023_canadian_budget\"\n",
    "CHROMA_DIR = \"./llamaindex/chroma_db/2023_canadian_budget\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110f189-d281-4a84-8840-6c1e2e646a48",
   "metadata": {},
   "source": [
    "##### ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c6b69-695b-49db-8871-70acc0e8849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a1eea-81be-435c-a75b-9951a263caa1",
   "metadata": {},
   "source": [
    "#### 簡単なテスト（永続化付き）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ff8e2-5690-4d1d-9093-096e90b7df33",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ccfff-885c-4eba-a81e-5b14253bed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "Settings.llm = llm # 複数箇所で使うのでグローバルに設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3157d6b-db67-4dee-84b2-40e43b4c3bd8",
   "metadata": {},
   "source": [
    "##### Indexing & Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e72d5-2826-48cd-96a4-9a84f0aa1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# check if storage already exists\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(DATA_DIR).load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb3c8c-1418-4039-ae0c-982094ab7b8b",
   "metadata": {},
   "source": [
    "##### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d047c-160d-4e5d-92fa-5c6b0a057ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\n",
    "    \"What was the total amount of the 2023 Canadian federal budget?\"\n",
    "    \"\\n Please answer with one number.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59938a52-eff4-4968-ba2f-444f26a322a9",
   "metadata": {},
   "source": [
    "#### ツール作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae23aba-02ef-4b45-b06f-7ee065bd9de0",
   "metadata": {},
   "source": [
    "##### ファンクション・ツール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e92e5b-190f-4e1d-a89b-9b7854543d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9db99-0d49-4b7e-bbc9-2ae39779c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function tools\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266cb53c-6ffa-428f-b43d-8eccdb38c97c",
   "metadata": {},
   "source": [
    "##### クエリエンジンツール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876db4e-f6e0-4285-9fe7-c8484efd3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a3b86-ebec-4f76-9a7b-8fc638b1a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine,\n",
    "    name=\"canadian_budget_2023\",\n",
    "    description=\"A RAG engine with some basic facts about the 2023 Canadian federal budget.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b053119-e808-4634-9b55-e6ec4bdc6197",
   "metadata": {},
   "source": [
    "#### エージェントにツールを実行させる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11e68b-4a48-400e-84d8-dfec0802eed2",
   "metadata": {},
   "source": [
    "##### ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7779d7-aa50-431e-82cd-394e11c4d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26727f3-35c8-454b-8cdc-3c4083410dba",
   "metadata": {},
   "source": [
    "##### RAG込エージェント定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4641b1-50fb-41b1-9d13-212564e09816",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools([multiply_tool, add_tool, budget_tool], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc24f93-e82d-46c8-bf54-384683bdb626",
   "metadata": {},
   "source": [
    "##### RAG込エージェント実行\n",
    "- SLMだと上手く動作しない問題。\n",
    "- そしてデバッグと対策も不明（笑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7a826-2296-42c8-8134-8c0e3635a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"What is the total amount of the 2023 Canadian federal budget multiplied by 3?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba669365-3663-47d2-906b-3839f85b3bc1",
   "metadata": {},
   "source": [
    "#### 追加のインストレーション1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befedc74-e9e4-4160-a5bf-d21b2da868c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要（OpenAIは依存関係パッケージらしい）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3bf94-916f-4e1a-906d-67e58c68f67d",
   "metadata": {},
   "source": [
    "#### 追加のライブラリ読み込み1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6d089-334e-49f8-8c97-a61f2399c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# なし"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e159b24-3b40-450e-b490-ce9ad719a42b",
   "metadata": {},
   "source": [
    "#### ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9453ebc-d6a2-4bd6-bb84-aa833ef54302",
   "metadata": {},
   "source": [
    "#### 追加のインストレーション2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64235616-cf96-449d-bebd-7bff7a523fdc",
   "metadata": {},
   "source": [
    "```bash\n",
    "!pip install llama-index-llms-ollama\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a7303-3110-4536-a8a4-868d61f931d6",
   "metadata": {},
   "source": [
    "#### 追加のライブラリ読み込み2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff2148-c623-46de-8e6c-cc9fd52e8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143f648-d3c5-40e8-b748-a272fafcf1ef",
   "metadata": {},
   "source": [
    "#### インデックス作成\n",
    "最も基礎的で、オンメモリのセマンティック検索のインデックス。\n",
    "- RAGで言うと：知識情報の分割、知識情報の埋め込み\n",
    "- LlamaIndexで言うと：Loading、Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa86da-f8ad-4192-b602-9ed2a1a6ff16",
   "metadata": {},
   "source": [
    "##### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1625f-1c79-45ab-82b3-abf22bd89d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(DATA_DIR1).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956547c7-0c3f-42e4-a691-544155865ebd",
   "metadata": {},
   "source": [
    "##### Indexing\n",
    "- 以下では、VectorStoreIndexを使用している。\n",
    "- SummaryIndexやKnowledgeGraphIndexなどのindexもある。\n",
    "- 質問内容によって最適なIndexが異なる可能性がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16070c37-5f39-4fa9-b910-c4aac63b18e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# ollama\n",
    "Settings.llm = Ollama(model=\"Llama3\", request_timeout=360.0)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eab513-0888-47f3-8c83-6fb31b6f5aa8",
   "metadata": {},
   "source": [
    "#### RAGのRetrieval部\n",
    "- RAGで言うと：Query Input、Query Embedding、Information Retrieval\n",
    "- LlamaIndexで言うと：Querying、Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39165cc2-50f1-4eb2-ae9d-8d38f4ca1628",
   "metadata": {},
   "source": [
    "##### Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d344b-2dad-4208-b1cf-3ee59d594f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db857f30-a3e7-49d9-ba20-1c31c8dfc6a1",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c5a0d-73d0-421e-b521-efb2140bcd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b871eb-5235-4659-a932-9b7a1d862eb6",
   "metadata": {},
   "source": [
    "#### ログの有効化\n",
    "抽象化度が高いので、ログの有効化をしても良いが、結局、欲しい所が出きってない感もある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2aa20-2dcb-45a1-b097-b5a3a6e88613",
   "metadata": {},
   "source": [
    "```Python\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a4374-4291-4d11-b177-e82b0375d936",
   "metadata": {},
   "source": [
    "#### 永続化して実行\n",
    "前述のコードに、LlamaIndexで言うStoringの概念を追加したもの。\n",
    "- 永続化は、Document Store、Vector Store、Index Storeに、Storage Contextを設定する。\n",
    "- 既出の、Loadingの所で、Document Storeから読み出している。\n",
    "- Indexingでは、Vector Store、Index Storeに書き出し（永続化し）す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ddce5-e376-4dc3-8d61-6e81f3237c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# check if storage already exists\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(DATA_DIR1).load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e89db-360f-443a-9178-37ada161fd48",
   "metadata": {},
   "source": [
    "#### 使用する変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06823271-3906-4f38-a1f1-f565bd701f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR2 = \"./llamaindex/data/2023_canadian_budget\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764781b9-32a5-4cc4-b723-f0592faa9d6e",
   "metadata": {},
   "source": [
    "#### ライブラリ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13d4af-bf01-4114-8a83-90fe8c13a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcecce-0ae5-4952-8997-565f0b4c8058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a56b19-ceef-47d9-9835-af4f396ff82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(DATA_DIR2).load_data()\n",
    "\n",
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# ollama\n",
    "Settings.llm = Ollama(model=\"Llama3\", temperature=0)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\n",
    "    \"What was the total amount of the 2023 Canadian federal budget?\"\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
