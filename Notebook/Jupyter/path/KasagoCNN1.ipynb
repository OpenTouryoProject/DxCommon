{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3df4459-b70f-432f-b772-676ed4fa6be8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# o'reillyのカサゴ深層学習の本\n",
    "\n",
    "## ニューラルネットワークの構成要素\n",
    "\n",
    "## [目次](TableOfContents.ipynb)\n",
    "- [環境準備](#環境準備)\n",
    "  - [インポート](#インポート)\n",
    "  - [共通関数](#共通関数)\n",
    "- 単純なCNN\n",
    "  - [単純なCNNの実装](#単純なCNNの実装)\n",
    "  - [CNNの勾配計算チェック](#CNNの勾配計算チェック)\n",
    "  - [単純なCNNを訓練してセーブ](#単純なCNNを訓練してセーブ)\n",
    "  - [単純なCNNをロードして推論](#単純なCNNをロードして推論)\n",
    "  - [学習結果（フィルタ）の確認](#学習結果（フィルタ）の確認)\n",
    "\n",
    "## 参考\n",
    "- https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/notebooks/\n",
    "- [深層学習（deep learning） - 開発基盤部会 Wiki](https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%EF%BC%88deep%20learning%EF%BC%89) > [ニューラルネットワーク\n",
    "](https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?plugin=related&page=%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF) > [畳み込みニューラルネットワーク（CNN）\n",
    "](https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%EF%BC%88CNN%EF%BC%89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab256dd-c180-4767-983b-9b07561ee7e2",
   "metadata": {},
   "source": [
    "## 環境準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344608e2-352b-4412-a078-4c6b7bf9dc58",
   "metadata": {},
   "source": [
    "### インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5516c3b4-3cc4-4bc2-b127-f42850c5efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from matplotlib.image import imread\n",
    "from kasago.common.layers import *\n",
    "from kasago.common.gradient import numerical_gradient\n",
    "from kasago.dataset.mnist import load_mnist\n",
    "from kasago.common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e5f60-b94f-4a30-a88b-c6b9b596734d",
   "metadata": {},
   "source": [
    "### 共通関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d303864-9133-4cac-b422-cc8763f18718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show1(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e6e97-98cd-4211-a54a-1f2611f1961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show2(filters, nx=4, show_num=16):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(show_num / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(show_num):\n",
    "        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed18d8-8556-4c0b-b2c7-2a2ec05f1edb",
   "metadata": {},
   "source": [
    "## 単純なCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fedb81-7d2e-430d-bea9-4d37f58d5387",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 単純なCNNの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c6135-bf0c-47e3-b412-faf26b0547e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単純なConvNet\n",
    "# conv - relu - pool - affine - relu - affine - softmax\n",
    "class SimpleConvNet:\n",
    "    #----------------------------------------------------\n",
    "    # Parameters\n",
    "    #   input_size : 入力サイズ（MNISTの場合は784）\n",
    "    #   output_size : 出力サイズ（MNISTの場合は10）\n",
    "    #   activation : 'relu' or 'sigmoid'\n",
    "    #   weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "    #                    'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "    #                    'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    #----------------------------------------------------\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "\n",
    "        # 重みの初期化、畳み込み層の出力サイズの計算\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1] # ※ 一辺の長さ\n",
    "        conv_output_size = (input_size - filter_size + 2 * filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    # 推論を行う\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # 損失関数を求める\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "        引数のxは入力データ、tは教師ラベル\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866e59e-2a70-4e3f-b545-f11c5df70534",
   "metadata": {},
   "source": [
    "### CNNの勾配計算チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c7c1e-3f0d-474f-a720-78b6701620d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNを生成\n",
    "network = SimpleConvNet(input_dim=(1,10, 10), \n",
    "                        conv_param = {'filter_num':10, 'filter_size':3, 'pad':0, 'stride':1},\n",
    "                        hidden_size=10,\n",
    "                        output_size=10,\n",
    "                        weight_init_std=0.01)\n",
    "\n",
    "# 入力データ\n",
    "X = np.random.rand(100).reshape((1, 1, 10, 10))\n",
    "# 教師ラベル\n",
    "T = np.array([1]).reshape((1,1))\n",
    "\n",
    "# 勾配を求める\n",
    "## 数値微分\n",
    "grad_num = network.numerical_gradient(X, T)\n",
    "## 誤差逆伝搬法\n",
    "grad = network.gradient(X, T)\n",
    "\n",
    "# 比較（近似できていればOK）\n",
    "for key, val in grad_num.items():\n",
    "    print(key, np.abs(grad_num[key] - grad[key]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605214b-c3ec-4c29-8ba3-18ac3529ba9d",
   "metadata": {},
   "source": [
    "### 単純なCNNを訓練してセーブ\n",
    "処理が重いので既定でコメントアウト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d67ac5-1de4-492c-9c0f-d1adde7a139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"../work/params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9d161-ec3a-4c24-9491-ebe3c140dbb1",
   "metadata": {},
   "source": [
    "### 単純なCNNをロードして推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee1f7f-0018-45ba-9b8c-9ceac5a09a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# CNNのロード\n",
    "network = SimpleConvNet()\n",
    "network.load_params(\"../work/params.pkl\")\n",
    "\n",
    "# CNNで推論\n",
    "yy_pred=network.predict(x_test)\n",
    "#print(yy_pred[:10])\n",
    "y_pred = np.array(yy_pred.argmax(axis=1), dtype=np.int64)\n",
    "#print(y_pred[:10])\n",
    "ret = (t_test == y_pred)\n",
    "(len(np.where(ret==True)[0]) / ret.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48234ec5-24c8-440c-918f-c5d0fdd5f8f8",
   "metadata": {},
   "source": [
    "### 学習結果（フィルタ）の確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a8c390-b000-4981-9e35-2e842f0787e6",
   "metadata": {},
   "source": [
    "#### SimpleConvNetの学習前後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ff048-43bf-4330-b768-c79415948b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = SimpleConvNet()\n",
    "# ランダム初期化後の重み（フィルタ）でfilter_show\n",
    "filter_show1(network.params['W1'])\n",
    "\n",
    "network.load_params(\"../work/params.pkl\")\n",
    "# 学習後の重み（フィルタ）でfilter_show\n",
    "filter_show1(network.params['W1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d73b5-8993-49e1-a292-4a20820b8aef",
   "metadata": {},
   "source": [
    "#### 学習したフィルタによる特徴マップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312ee86-1505-4168-8c57-50d687403ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "# 学習後の重み（フィルタ）でfilter_show\n",
    "network.load_params(\"../work/params.pkl\")\n",
    "filter_show2(network.params['W1'], 16)\n",
    "\n",
    "# lena_gray.png\n",
    "img = imread('./kasago/dataset/lena_gray.png')\n",
    "img = img.reshape(1, 1, *img.shape)\n",
    "fig = plt.figure()\n",
    "\n",
    "w_idx = 1\n",
    "for i in range(16):\n",
    "    # 学習後の重み（フィルタ）\n",
    "    w = network.params['W1'][i]\n",
    "    b = 0  # network.params['b1'][i]\n",
    "    w = w.reshape(1, *w.shape)\n",
    "    #b = b.reshape(1, *b.shape)\n",
    "    \n",
    "    # 学習後の重み（フィルタ）で\n",
    "    # lena_gray.pngの特徴マップを生成\n",
    "    conv_layer = Convolution(w, b) \n",
    "    out = conv_layer.forward(img)\n",
    "    out = out.reshape(out.shape[2], out.shape[3])\n",
    "    \n",
    "    # 特徴マップをsubplot\n",
    "    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
