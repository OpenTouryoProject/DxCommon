{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4d063a-309e-471e-9f37-c662ab4a0330",
   "metadata": {},
   "source": [
    "# 環境準備\n",
    "- 以下の手順で環境を構築する。  \n",
    "https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?OSS%E3%81%AELLM\n",
    "  - WSL2にOllamaをインストールし\n",
    "  - Ollamaを起動してLlama3を実行させておく。\n",
    "  - WSL2のNotebookからWebAPI経由でLLMを呼び出す。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076d25f-1ace-432f-a144-f4d433e2dec2",
   "metadata": {},
   "source": [
    "# 疎通確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01f39e-24b9-4e88-9369-28b297ad460b",
   "metadata": {},
   "source": [
    "## HTTPClient\n",
    "最も単純な、HTTPClient系ライブラリを使用した呼び出し。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73631f-c0ef-4c52-b98e-4e73de3bf7cc",
   "metadata": {},
   "source": [
    "### Generate\n",
    "次単語予測モード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77bff5-70ac-4cbb-ac45-777db95e03fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "payload = {\n",
    "    \"model\": \"llama3\",\n",
    "    \"prompt\": \"why is the sky blue?\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.text) # print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20675e-ba0a-4fbd-bec2-62663b10ae3e",
   "metadata": {},
   "source": [
    "### Chat\n",
    "チャット・モード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fa355-9d88-47ee-882b-aac2c06c3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "payload = {\n",
    "    \"model\": \"llama3\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"why is the sky blue?\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.text) # print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d7160-b915-4e27-bd3a-d8e42559f54f",
   "metadata": {},
   "source": [
    "## Ollama\n",
    "Ollamaライブラリを使用した呼び出し。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045f29a-f4df-40f1-b1da-1ca6fc388c72",
   "metadata": {},
   "source": [
    "### ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db2891-03fc-48ad-9bf0-dddc0d192434",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61050d7-8158-454f-ac71-1c157e5d0ab5",
   "metadata": {},
   "source": [
    "### ライブラリで呼び出し"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ddd0c-c166-4489-ba5a-e79dca0d92c1",
   "metadata": {},
   "source": [
    "#### Generate\n",
    "次単語予測モード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f39fd6-f9b4-4777-9aaa-b39820f90603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "response = ollama.generate(\n",
    "    model='llama3',\n",
    "    prompt='Why is the sky blue?',\n",
    ")\n",
    "\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e786e3f-5888-447c-828b-73a88565d338",
   "metadata": {},
   "source": [
    "#### Chat\n",
    "チャット・モード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72dd9ed-b48c-443d-8e9f-badce5f9fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "response = ollama.chat(model='llama3', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c977894-7619-40df-8477-69aa539ab5c3",
   "metadata": {},
   "source": [
    "# OpenAI\n",
    "OpenAIライブラリを使用した呼び出し。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc8b1e-75f9-477f-a301-a4b90b3e4477",
   "metadata": {},
   "source": [
    "### ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eebb45a-8a74-447d-aaf0-b73c733a76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e92a8d-f17e-4f64-b4d4-6d065e18874a",
   "metadata": {},
   "source": [
    "### ライブラリで呼び出し"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b66cc7-5e80-4b64-92b8-0096f3c58cbc",
   "metadata": {},
   "source": [
    "#### Generate\n",
    "次単語予測モード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee2e77-7e96-47ef-8070-24c3f51fedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ASCII code', #ダミーでOK\n",
    ")\n",
    "\n",
    "completion = client.completions.create(\n",
    "    prompt='Why is the sky blue?',\n",
    "    model='llama3',\n",
    ")\n",
    "\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7744e25-a406-4660-b53d-fc52ebd806bd",
   "metadata": {},
   "source": [
    "#### Chat\n",
    "チャット・モード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff751dd-c04b-4b23-8743-b146891b72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ASCII code', #ダミーでOK\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Why is the sky blue?',\n",
    "        }\n",
    "    ],\n",
    "    model='llama3',\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6458d-729d-4c1e-92a4-e651beae6186",
   "metadata": {},
   "source": [
    "# langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45628fd0-8bd2-4bc7-a2e7-f172e75feabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_core langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdb961-8475-4216-b133-02ec6eb85c10",
   "metadata": {},
   "source": [
    "# Chatアプリ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b59c6-23ba-4cc7-b7b0-87885b591c3f",
   "metadata": {},
   "source": [
    "## Console & HTTPClient\n",
    "- 最も単純な、HTTPClient系ライブラリを使用したConsoleChatアプリ\n",
    "- 以下のコードを修正したもの。  \n",
    "https://github.com/ollama/ollama/tree/main/examples/python-simplechat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99918e4-9c6a-4e88-b295-6c2e4561c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "model = \"llama3\"  \n",
    "\n",
    "def chat(messages):\n",
    "    r = requests.post(\n",
    "        \"http://localhost:11434/api/chat\",\n",
    "        json={\"model\": model, \"messages\": messages, \"stream\": True},\n",
    "        # proxies={\"http\": None, \"https\": None} #プロキシを無効にするときは必要\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    output = \"\"\n",
    "\n",
    "    for line in r.iter_lines():\n",
    "        \n",
    "        body = json.loads(line)\n",
    "        \n",
    "        if \"error\" in body:\n",
    "            raise Exception(body[\"error\"])\n",
    "            \n",
    "        if body.get(\"done\") is False:\n",
    "            message = body.get(\"message\", \"\")\n",
    "            content = message.get(\"content\", \"\")\n",
    "            output += content\n",
    "            # the response streams one token at a time, print that as we receive it\n",
    "            print(content, end=\"\", flush=True)\n",
    "\n",
    "        if body.get(\"done\", False):\n",
    "            message[\"content\"] = output\n",
    "            return message\n",
    "\n",
    "def main():\n",
    "    messages = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Enter a prompt: \")\n",
    "        if not user_input:\n",
    "            exit()\n",
    "        print()\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        message = chat(messages)\n",
    "        messages.append(message)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ef46d-b3ad-4381-b8f6-9923e173ae21",
   "metadata": {},
   "source": [
    "## Streamlit & OpenAI\n",
    "最も単純な、OpenAIライブラリを使用したConsoleChatアプリ\n",
    "- Streamlitを使用してWeb化（サーバーサイド実装）\n",
    "- Stlite（クライアントサイド実装）ではOpenAIが動かないらしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c265235-fd83-4172-a2f7-ba1af957f73e",
   "metadata": {},
   "source": [
    "### Consoleから以下を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240e1b8-f415-4cc4-a7bb-30d7b5ed096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7875c-0c39-463f-a6e2-418c7e5b35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run LLM_Streamlit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f8c281-4d31-4509-bd83-46d61f652774",
   "metadata": {},
   "source": [
    "## ブラウザからアクセスする。  \n",
    "http://localhost:8501/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
