{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe59fb7-e68d-4e4b-8901-5902d5343ed8",
   "metadata": {},
   "source": [
    "# TensorFlow・Kerasのトレーニング♨\n",
    "\n",
    "## CNN - 画像の前処理 編\n",
    "\n",
    "## [目次](TableOfContents.ipynb)\n",
    "- [環境準備](#環境準備)\n",
    "  - [インポート](#インポート)\n",
    "  - [共通関数](#共通関数)\n",
    "- [画像の前処理](#画像の前処理)\n",
    "  - [画像の取得](#画像の取得)\n",
    "  - [様々な変換処理](#様々な変換処理)\n",
    "\n",
    "## 参考\n",
    "開発基盤部会 Wiki\n",
    "- データマイニング（DM）- Python - DL  \n",
    "https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?%E3%83%87%E3%83%BC%E3%82%BF%E3%83%9E%E3%82%A4%E3%83%8B%E3%83%B3%E3%82%B0%EF%BC%88DM%EF%BC%89-%20Python%20-%20DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48958bb-e085-40a2-a6e1-f00c80080d20",
   "metadata": {},
   "source": [
    "## [環境準備](TensorFlowAndKeras0.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b356459b-3ba0-425e-89f7-947e2dac1e46",
   "metadata": {},
   "source": [
    "### インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99bd442-2c0f-4337-901e-c3a2c51fb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# モデル定義\n",
    "from keras.models import Model, Sequential, model_from_json, load_model\n",
    "from keras.layers import Dense, Input, Activation, Flatten, Dropout, LSTM\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam\n",
    "# その他\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15a318-0509-4715-918d-39f2363650dd",
   "metadata": {},
   "source": [
    "### 共通関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc210de-bf63-46a4-963f-4cac89923911",
   "metadata": {},
   "source": [
    "#### 画像比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76630b-d480-4f60-a969-87730c32973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_image_info(img1, img2, cmap1=None, cmap2=None):\n",
    "    print(img1.shape)\n",
    "    print(img2.shape)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img1, cmap1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2, cmap2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c617e0-5c75-4c9f-8534-3ca7e5034d45",
   "metadata": {},
   "source": [
    "#### 画像回転"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c637f-fdb3-4db2-ac0d-19759785ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_rotate(img, angle=30):\n",
    "    size = (img.shape[0], img.shape[1])\n",
    "    center = (int(size[0]/2), int(size[1]/2))\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(img, rotation_matrix, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285398c-8784-494b-818b-c9de28a049ed",
   "metadata": {},
   "source": [
    "#### 画像並進"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829dedd-e2b8-422b-814a-6c609aa08f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_move(img, h=100, v=50):\n",
    "    rows, cols, channnels = img.shape\n",
    "    M = np.float32([[1,0,h],[0,1,v]])\n",
    "    return cv2.warpAffine(img, M, (cols, rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567d6b9-743a-4000-b317-aab78fd54176",
   "metadata": {},
   "source": [
    "#### 画像拡大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc08f96-7931-43df-90d2-a4fe7545084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_zoomin(img, h=2.0, v=2.0):\n",
    "    zoomed = cv2.resize(img, None, fx=h, fy=v)\n",
    "    height_1, width_1, channel_1 = img.shape\n",
    "    height_2, width_2, channel_2 = zoomed.shape\n",
    "    x =  int((width_2 - width_1) / 2)\n",
    "    y =  int((height_2 - height_1) / 2)\n",
    "    return zoomed[y:y+height_1, x:x+width_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7351e-7bc3-45e0-91e0-2ddbc93dc774",
   "metadata": {},
   "source": [
    "#### ヒストグラム平坦化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4a0e5-1c43-4398-8bd7-19c8a80c5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_clahe(img, clipLimit=2.0, tileGridSize=(8,8)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e54d9-9332-45d6-9015-d72b57de9a9e",
   "metadata": {},
   "source": [
    "#### Mean Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510df76d-c934-45c6-bfd5-9c9078993fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_meansubtraction(img):\n",
    "    img2 = img.astype('f')\n",
    "    \n",
    "    # スケーリング処理\n",
    "    img2 /= 255 # 0～1正規化\n",
    "    img2 -= np.mean(img2) # Mean Subtraction\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e49d22-a825-461b-8f30-86ff7afad4dc",
   "metadata": {},
   "source": [
    "#### 画像のピクセル値の正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6352d9b-05fa-4c92-897f-d6781b453f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_min_max(img):\n",
    "    img_min = img.min()\n",
    "    img_max = img.max()\n",
    "    return (img - img_min) / (img_max - img_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27e1fa-fa25-4ed1-adf6-b2848b310d2c",
   "metadata": {},
   "source": [
    "#### ガンマ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b20883-960b-4cb6-922d-a6dae9c7663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_gamma(img, gamma=0.5):\n",
    "    look_up_table = np.zeros((256, 1), dtype='uint8')\n",
    "    for i in range(256):\n",
    "        look_up_table[i][0] = 255 * pow(float(i) / 255, 1.0 / gamma)\n",
    "    return cv2.LUT(img, look_up_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d093d5-625f-49a2-8bbd-01eb9ea4c784",
   "metadata": {},
   "source": [
    "#### ガウシアンノイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3734a-4b16-4c26-83a4-0c1984753741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_gaussian_noise(img, loc=0.0, scale=5.0):\n",
    "    row, col, ch = img.shape\n",
    "    noise = np.random.normal(loc, scale, (row, col, ch))\n",
    "    noise = noise.reshape(row, col, ch)\n",
    "    noised = img + noise\n",
    "    noised /= 255\n",
    "    return noised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30782575-1e5f-488a-a935-ee539603f060",
   "metadata": {},
   "source": [
    "#### その他、ワンライナー系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c0756-ddef-484e-b9d0-91df88e3043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リサイズ\n",
    "def opencv_resize(img, h, w):\n",
    "    return cv2.resize(img, (h, w))\n",
    "\n",
    "# クロップ\n",
    "def img_cropping(img, h, w):\n",
    "    return img[h[0]:h[1], w[0]:w[1], :]\n",
    "\n",
    "# クロップ（％\n",
    "def img_cropping_p(img, hp, wp):\n",
    "    h, w, c = img.shape\n",
    "    return img[int(h * hp[0]): int(h * hp[1]):, int(w * wp[0]): int(w * wp[1]), :]\n",
    "\n",
    "# bgr -> rgb\n",
    "def opencv_bgr2rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# グレースケール化\n",
    "def opencv_rgb2gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# 2値化\n",
    "def opencv_binary(img, threshold=125):\n",
    "    # 二値化(閾値を超えた画素を255にする。)\n",
    "    return cv2.threshold(grayed, threshold=125, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# 左右反転\n",
    "def opencv_flip_horizontal(img):\n",
    "    return cv2.flip(img, 1)\n",
    "\n",
    "# 上下反転\n",
    "def opencv_flip_vertical(img):\n",
    "    return cv2.flip(img, 0)\n",
    "\n",
    "# 平滑化\n",
    "def opencv_gaussian_blur(img, ksize=(10, 10), sigma=0):\n",
    "    return cv2.GaussianBlur(img, ksize, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fdcdf7-6606-497e-a1a6-659d22a81811",
   "metadata": {},
   "source": [
    "## 画像の前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6524928-ab29-45f4-a4f8-acb60bf4b1da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 画像の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df074e-87a2-4c6e-945e-fcac9eba89e9",
   "metadata": {},
   "source": [
    "#### ダウンロード\n",
    "プロキシの書き方がよく判らんので環境変数で。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50be44-3863-481c-8854-1d32c2e59d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url = 'https://dotnetdevelopmentinfrastructure.osscons.jp/index.php?plugin=attach&pcmd=open&file=Lenna.png&refer=FrontPage'\n",
    "data = urllib.request.urlopen(url).read()\n",
    "with open(\"lenna.png\", mode=\"wb\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48d6bb-86fe-4428-9e51-b86de805423f",
   "metadata": {},
   "source": [
    "#### 読込・確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74514cff-27da-4c35-a985-ea601f1ca7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lenna.png')\n",
    "print(type(img))\n",
    "print(img.shape)\n",
    "\n",
    "# 既定の色空間がBGRなので青みがかる。\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a8fc7-7b39-4deb-9b9b-e32146be4a37",
   "metadata": {},
   "source": [
    "#### 変換して保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0be45a-0784-4760-a1e5-d15e9e5556dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 色空間をRGBに変更。\n",
    "img = opencv_bgr2rgb(img)\n",
    "# 元のRGB解釈の色合いで表示される。\n",
    "plt.imshow(img)\n",
    "# RGB解釈で保存\n",
    "cv2.imwrite('new_lenna.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ee7b5-4fe2-4636-be1a-32f86fd44656",
   "metadata": {},
   "source": [
    "### 様々な変換処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5165452-38ad-4e94-bdab-f2947b20488f",
   "metadata": {},
   "source": [
    "#### リサイズ\n",
    "学習に画像データを入力するときは画像のサイズを揃える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691fee41-72ff-473d-902c-1362f1ea990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = opencv_resize(img, 224, 224)\n",
    "diff_image_info(img, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74098e1-9a82-47aa-87fb-afe3d3b14296",
   "metadata": {},
   "source": [
    "#### クロップ\n",
    "画像の一部を切り抜く処理はarrayのスライシングで実装。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3007c2-572c-437e-84c9-a96d0f485950",
   "metadata": {},
   "source": [
    "##### ピクセル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7a24b-3df3-4c74-9602-bcc53d494421",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img_cropping(img, [100, 400], [100, 400])\n",
    "diff_image_info(img, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8a455-9fb5-4b5d-8dbd-e60a04c8fafa",
   "metadata": {},
   "source": [
    "##### 比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e294f-c60b-4905-adb5-f4e30f92af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img_cropping_p(img, [(1/5), (4/5)], [(1/5), (4/5)])\n",
    "diff_image_info(img, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e2920-1bf7-46cf-b875-ca0b14b5e7cf",
   "metadata": {},
   "source": [
    "#### 明るさ調整"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63208be9-ef80-48ca-aad1-6ed02475df76",
   "metadata": {},
   "source": [
    "##### グレースケール化\n",
    "色の意味合いが低い場合、モノクロ画像に変換し計算量を減らす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0bb92c-370d-4d72-8fd9-e19d662055c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayed = opencv_rgb2gray(img)\n",
    "diff_image_info(img, grayed, cmap2='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8c34a-73a6-45c5-9d2d-0b8bcd73ceb3",
   "metadata": {},
   "source": [
    "##### 2値化\n",
    "- グレーを使わない白と黒の2色に変換。\n",
    "- スクリーン・トーンと同様の表現で、更に計算量を減らす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec080f5c-8e6c-455a-bd99-a1bc3128c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "th, binary = opencv_binary(img)\n",
    "diff_image_info(grayed, binary, cmap1='gray', cmap2='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89734f-bbc7-4c6a-add4-cd96277243ef",
   "metadata": {},
   "source": [
    "##### 平滑化\n",
    "画像をぼやかしノイズ（ガサつきなど）を取り除く。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7ece1-3d8c-49d3-8aba-029c142c9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = opencv_gaussian_blur(img)\n",
    "diff_image_info(binary, blurred, cmap1='gray', cmap2='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c8da5-5484-4c42-9b76-c5c7c4e6fc0f",
   "metadata": {},
   "source": [
    "##### ヒストグラム平坦化\n",
    "画像の明るさの範囲を引き伸ばすと明暗部分でも輪郭線が認識し易くなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eda9e-c5b9-4c11-8700-7131a58e010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahed = opencv_clahe(grayed)\n",
    "diff_image_info(grayed, clahed, cmap1='gray', cmap2='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736984a3-5a78-44a0-974f-6b5e3694d5c5",
   "metadata": {},
   "source": [
    "##### Mean Subtraction\n",
    "- 0 ～ 1正規化と合わせた標準化のようなスケーリング処理\n",
    "- BatchNormalizationのように共変量シフトを抑制できる｡\n",
    "\n",
    "※ img単位ではなくxに対して適用できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7349f-6701-472a-89cc-bec786f77319",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img_meansubtraction(clahed)\n",
    "diff_image_info(clahed, img2, cmap1='gray', cmap2='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1871fef-61a9-4af2-9b34-9bb0bcce47cf",
   "metadata": {},
   "source": [
    "##### 画像のピクセル値の正規化\n",
    "※ img単位ではなくxに対して適用できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf46cb-521e-44e9-8730-bdd64e420f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = img_min_max(clahed)\n",
    "diff_image_info(clahed, img3, cmap1='gray', cmap2='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1381466-e58a-481d-9d24-747462dd550b",
   "metadata": {},
   "source": [
    "#### データ拡張（data augmentation）\n",
    "データ拡張は過学習を防ぐ方法の一つ。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179b139-521b-4df7-82cc-8fbb3a03da82",
   "metadata": {},
   "source": [
    "##### 左右反転"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c71dc7-b052-4baa-af65-875d2d8c22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = opencv_flip_horizontal(img)\n",
    "diff_image_info(img, flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57677c0-b0a0-4516-b2b5-b89a355c1765",
   "metadata": {},
   "source": [
    "##### 上下反転\n",
    "学習データとして成立する場合  \n",
    "（回転するモノや上や下から見た場合など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8b4e8-f7df-4e25-98f7-ea0a0337d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = opencv_flip_vertical(img)\n",
    "diff_image_info(img, flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bce718-a884-44cc-b203-b22f8ad97de1",
   "metadata": {},
   "source": [
    "##### 回転実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc7380-526c-485e-ac57-bfd75638f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = opencv_rotate(img, 30)\n",
    "diff_image_info(img, rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e960a334-448f-4d75-9f0f-b6a161da7aff",
   "metadata": {},
   "source": [
    "##### 並進実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08cfc9-d4d9-4933-8de1-630e801e2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "moved = opencv_move(img, 200, 100)\n",
    "diff_image_info(img, moved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0df47-c27f-42a1-a4d1-120a34d77dfd",
   "metadata": {},
   "source": [
    "##### 拡大実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12bf3d6-6110-4a44-b67b-855d8e59547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoomed = opencv_zoomin(img, 3, 3)\n",
    "diff_image_info(img, zoomed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce653e84-83e3-4909-936f-287775b11b91",
   "metadata": {},
   "source": [
    "##### ガンマ変換\n",
    "画像の明るさを全体的に明るく or 暗くする処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6670bd-dce8-4965-802d-14899c6236ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gamma = opencv_gamma(img, 0.3)\n",
    "diff_image_info(img, img_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55625a-a75b-4142-818b-7bdfff99bba9",
   "metadata": {},
   "source": [
    "##### ガウシアンノイズ\n",
    "画像の加工過程で発生する粒が散らばったようなノイズを加える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241d524-5369-4892-a3fe-dae85b092e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gn = img_gaussian_noise(img, 50, 100)\n",
    "diff_image_info(img, img_gn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
